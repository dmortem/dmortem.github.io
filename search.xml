<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning]]></title>
      <url>/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/</url>
      <content type="html"><![CDATA[<p>CVPR 2018：<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.pdf" target="_blank" rel="noopener">2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning</a></p>
<ul>
<li>第一篇 end-to-end pose based action recognition</li>
</ul>
<a id="more"></a>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>使用 multitask 的框架同时做 2d 和 3d 人体姿态估计以及 action recognition，都能达到 state-of-the-art 的结果，而且是 end-to-end 训练</li>
<li>用的数据集有 MPII、Human3.6M、Penn Action、NTU</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>目前已经有人用 pose 来提升行为识别的准确率，但还没有人用一个网络同时解决这几个任务</li>
<li>一般的姿态估计都是得到 heatmap，但是从 heatmap 到关节坐标是不可导的，没法 end2end 训练。为此，这篇文章使用 Soft-argmax 来解决 heatmap-&gt;joints 不可导的问题</li>
<li>文章贡献：<blockquote>
<ol>
<li>the proposed pose estimation method achieves state-of-the-art results on 3D pose estimation and the most accurate results among regression methods for 2D pose estimation</li>
<li>the proposed pose estimation method is based on still images, so it benefits from images “in the wild” for both 2D and 3D predictions. This have been proven a very efficient way to learn visual features, which is also very important for action recognition</li>
<li>our action recognition approach is based only on RGB images, from which we extract pose and visual information. Despite that, we reached state-of-the-art results on both 2D and 3D scenarios, even when compared with methods using ground-truth poses</li>
<li>the pose estimation method can be trained with multiple types of datasets simultaneously, which makes it able to generalize 3D predictions from 2D annotated data</li>
</ol>
</blockquote>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>两篇分别关于 <a href="https://www.sciencedirect.com/science/article/pii/S0262885617300343" target="_blank" rel="noopener">action recognition</a> 和 <a href="https://www.sciencedirect.com/science/article/pii/S1077314216301369" target="_blank" rel="noopener">pose estimation</a> 的综述。其中，action recognition 的综述见<a href="https://dmortem.github.io/2018/03/09/Action-Recognition-Survey/#more">博文</a></li>
</ul>
<h3 id="Human-pose-estimation"><a href="#Human-pose-estimation" class="headerlink" title="Human pose estimation"></a>Human pose estimation</h3><h4 id="2D-pose-estimation"><a href="#2D-pose-estimation" class="headerlink" title="2D pose estimation"></a>2D pose estimation</h4><ul>
<li><p>Detection based：预测 heatmap。[7, 18] 最早用这个方法，后来 [33] 提出的 stack hourglasses 网络效果超级好，再后来出现了各种 stack hourglass 的变种 [16, 56]，现在还有用 GAN 的 [15, 13]</p>
<blockquote>
<p>这种方法用的比较多，但是 heatmap-&gt;joints 这一步用 argmax，不可导</p>
</blockquote>
</li>
<li><p>Regression based：直接回归关节坐标。最早是14年的工作 [52]，后来是16年的 [9]。直接回归是 sub-optimal 的，所以 [28] 提出 Soft-argmax 来把 heatmap 可导地转成 joints 坐标，这就意味着 pose estimation 的输出可以直接作为下一个网络的输入并端到端训练了</p>
</li>
</ul>
<h4 id="3D-pose-estimation"><a href="#3D-pose-estimation" class="headerlink" title="3D pose estimation"></a>3D pose estimation</h4><ul>
<li>介绍了一堆方法，其中17年那篇 coarse-to-fine 的问题在于参数太多了</li>
<li>在本文的方法中，主要也是借鉴了 coarse-to-fine 那篇文章的做法，也使用了 an intermediate volumetric representation for 3D poses，但 resolution 要低不少（为了减轻参数过多的问题）。最后结果也能达到 state-of-the-art，因为它们的方法是 based on a continuous regression function</li>
</ul>
<h3 id="Action-Recognition"><a href="#Action-Recognition" class="headerlink" title="Action Recognition"></a>Action Recognition</h3><h4 id="2D-action-recognition（video-based）"><a href="#2D-action-recognition（video-based）" class="headerlink" title="2D action recognition（video based）"></a>2D action recognition（video based）</h4><ul>
<li>一种方法是使用 3d cnn，比如 i3D，但是参数太多了，所以就 cannot benefit from the abundant still images for training，相比较于参数来说，数据量显得不够多了；一种方法是用 attention model；剩下一种是双流模型</li>
<li>现在的 2d action recognition 都只是使用 joint 信息来做 attention 机制。他们都只是用关节信息，所以必须依赖有骨架信息的数据集。本文的方法自己就可以产生关节坐标，对数据集没有额外要求</li>
</ul>
<h4 id="3D-action-recognition-skeleton-based"><a href="#3D-action-recognition-skeleton-based" class="headerlink" title="3D action recognition (skeleton based)"></a>3D action recognition (skeleton based)</h4><ul>
<li>由于 depth 传感器的出现，3d 骨架信息获取变得容易，但是大多局限于室内。而且 have a low range precision and not robust to occlusions，骨架信息并不是很准确。因此，很多文章都会处理这种 noisy skeleton 的问题</li>
<li>除了单纯使用骨架的方法，有些方法是同时用 RGB-D 信息，即同时使用关节坐标和原始图像的信息</li>
</ul>
<h3 id="Human-pose-estimation-1"><a href="#Human-pose-estimation-1" class="headerlink" title="Human pose estimation"></a>Human pose estimation</h3><h4 id="Regression-based-approach"><a href="#Regression-based-approach" class="headerlink" title="Regression-based approach"></a>Regression-based approach</h4><ul>
<li>使用 regression method 来估计 pose，输入 W*H*3，输出N<sub>j</sub>*D</li>
</ul>
<h5 id="Network-architecture"><a href="#Network-architecture" class="headerlink" title="Network architecture"></a>Network architecture</h5><ul>
<li>先用 Inception-v4 来获取 visual features，随后用了 K 个 prediction blocks 来反复估计 pose<img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/1.png">
</li>
</ul>
<h5 id="The-Soft-argmax-layer"><a href="#The-Soft-argmax-layer" class="headerlink" title="The Soft-argmax layer"></a>The Soft-argmax layer</h5> <img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/2.png">
<h5 id="Joint-visibility"><a href="#Joint-visibility" class="headerlink" title="Joint visibility"></a>Joint visibility</h5><ul>
<li>图片中某个关节是否可见的概率可以通过在 heatmap 上用 sigmoid 函数计算得到，然后就可以得到一个 N<sub>j</sub>*1 的 joint visibility 向量</li>
</ul>
<h4 id="Unified-2D-3D-pose-estimation"><a href="#Unified-2D-3D-pose-estimation" class="headerlink" title="Unified 2D/3D pose estimation"></a>Unified 2D/3D pose estimation</h4><ul>
<li>对 3d pose 的提取用了类似那篇 coarse-to-fine 的结构，定义了 N<sub>d</sub> 张 2D heatmap，N<sub>d</sub> 就表示深度。对于 3d pose，(x, y) 就是在所有heatmap平均上用 2d soft-argmax，而 (z) 就是把每张 heatmap 平均成一个值后，用 1d soft-argmax。（他这里是把 (x, y) 和 z 分开来做了，也可以一起做，文章说分开来做可以 maintain 2D heatmap as a byproduct，那我觉得一起做也可以维持吧）<img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/3.png">
</li>
</ul>
<h3 id="Human-action-recognition"><a href="#Human-action-recognition" class="headerlink" title="Human action recognition"></a>Human action recognition</h3> <img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/6.png">
<h4 id="Pose-based-recognition"><a href="#Pose-based-recognition" class="headerlink" title="Pose-based recognition"></a>Pose-based recognition</h4><ul>
<li>把时间维度作为纵轴，关节数作为横轴，关节坐标维度作为 channel，然后使用 FCN 来提取特征，并生成 action 的 heatmap。作者认为，action 只依赖于极少量的关节，而用全连接的话会对很多不相关的关节之间也进行建模，增加了难度</li>
<li>在 heatmap 后加 max+min pooling-&gt;softmax 来获取概率图。整个 pose-based recognition 还借鉴了姿态估计网络的思想，用了 stacked 的结构<img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/4.png">
</li>
</ul>
<h4 id="Appearance-based-recognition"><a href="#Appearance-based-recognition" class="headerlink" title="Appearance-based recognition"></a>Appearance-based recognition</h4><ul>
<li>appearance-based recognition 的网络结构和 pose-based 是一样，区别在于输入不同（但也非常相似）</li>
<li>输入：把 visual feature F<sub>t</sub> 和 M<sub>t</sub> 相乘，结果维度为 W<sub>f</sub>*H<sub>f</sub>*N<sub>j</sub>*N<sub>f</sub>，把空间维度通过 sum 压缩，得到对于每个时间 t，尺度为 N<sub>j</sub>*N<sub>f</sub><img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/7.png"> 
</li>
</ul>
<h4 id="Action-aggregation"><a href="#Action-aggregation" class="headerlink" title="Action aggregation"></a>Action aggregation</h4><ul>
<li>最后是把 feature map 合并，使用全连接进行分类</li>
</ul>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><ul>
<li>在 MPII 和 Human3.6M 上分别评估 2D 和 3D pose estimation，在 Penn Action 和 NTU RGB+D 上评估 action recognition</li>
</ul>
<h4 id="Implementation-details"><a href="#Implementation-details" class="headerlink" title="Implementation details"></a>Implementation details</h4><ul>
<li><p>对于 pose estimation 任务，loss function 定义如下，由一范数和二范数相加：</p>
<img src="/2018/07/29/2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning/5.png">  
<blockquote>
<p>在训练时，作者 crop bounding boxes centered on the target person，如果某个 joint 在 bounding box 以外，那么这个关节的 visibility flag 就设置为0。而在评估效果（测试）时，分别使用了 single-crop 和 multi-crop，single-crop 就是只使用一张 centered 图像来做预测，multi-crop 就是对那一张 centered 图像进一步做平移、翻转，把这些图片都作为输入，最后取平均</p>
</blockquote>
</li>
<li><p>对于 action recognition 任务，使用交叉熵作为损失函数</p>
<blockquote>
<p>在训练时，从一个 video 里随机选择长度为 T 帧的固定片段；在测试时，分别使用了 single-clip 和 multi-clip：single-clip 就是从视频中间 crop 了一个片段；multi-crop 就是每隔 T/2 帧 crop 一个片段，最后把这些片段的结果取个平均</p>
</blockquote>
</li>
<li><p>此外，训练时可以根据 label 确定 bounding box 需要多大，但测试时一个人在图像中占比多少是不知道的，需要想办法估计。文中是先对 clip 的 第一帧、中间帧、最后一帧的 full image 做了 pose estimation，最后选取了能够包围这些 pose 最大的 bounding box</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 人体姿态估计 </tag>
            
            <tag> Action Recognition </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields]]></title>
      <url>/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/</url>
      <content type="html"><![CDATA[<p>CVPR 2017 oral：<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Realtime_Multi-Person_2D_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></p>
<ul>
<li>开源框架 Openpose 的参考论文，文章作者也是 Openpose 作者</li>
<li>最大的特点就是实时，但在速度快的条件下，准确度也是当时的 state-of-the-art</li>
</ul>
<a id="more"></a>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>提出一种多人实时 2d 姿态估计的方法</li>
<li>通过两个branch的网络，分别学习关节位置，和使用 Parts Affinity Fields 来学习关节之间的联系</li>
<li>再使用贪婪的 bottom-top 的做法实现姿态估计，复杂度与人数无关</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>目前多人实时姿态估计有三个难点<blockquote>
<ol>
<li>人数未知、位置未知、大小未知</li>
<li>人们之间存在交互，如交流、遮挡</li>
<li>随着人数增多，运行时间也会增大，难以做到 realtime</li>
</ol>
</blockquote>
</li>
</ul>
<ul>
<li>目前常用的方法是 top-down 做法：先检测人，再在单人上估计 pose。但这种方法有两个问题<blockquote>
<ol>
<li>当检测人失败时，算法就失效了</li>
<li>算法复杂度随着人数增长而增长</li>
</ol>
</blockquote>
</li>
</ul>
<ul>
<li><p>因此，<strong>bottom-top</strong> 算法开始受到更多关注，这个算法正好能够解决top-down算法的两个问题</p>
</li>
<li><p>但事实上，由于 final parse 需要复杂的 global inference，所以之前使用 bottom-top 的算法并没有提升效率</p>
</li>
<li><p>本文提出了一种多人实时2d姿态估计的方法</p>
<blockquote>
<p>We present the first bottom-up representation of association scores via Part Affinity Fields (PAFs), a set of 2D vector fields that encode the location and orientation of limbs over the image domain. We demonstrate that simultaneously inferring these bottom-up representations of detection and association encode global context sufficiently well to allow a greedy parse to achieve high-quality results, at a fraction of the computational cost. </p>
</blockquote>
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/1.png">
</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ul>
<li>输入是一张 w*h 的彩色图像 (a)，输出是图中每个人的2d关节点坐标 (e)<blockquote>
<ol>
<li>前馈网络根据一张输入图像，同时预测关节2D位置的 <strong>Confidence Map S</strong> (b) 和表示关节关联度的 <strong>2D vector fields L</strong> (c) </li>
<li><strong>S = (S<sub>1</sub>, S<sub>2</sub>, …, S<sub>J</sub>)，S<sub>j</sub> 表示所有关节 j 的 heatmap 图，大小为 w*h</strong>（一个关节一张 heatmap，所以有 J 张 heatmap）</li>
<li><strong>L = (L<sub>1</sub>, L<sub>2</sub>, …, L<sub>C</sub>)，L<sub>c</sub> 表示所有 limb 的矢量图，大小为 w*h*2</strong>（因为 L 存的是一条向量，所以每个点都有2个值 x 和 y）</li>
<li>最后，<strong>贪婪解析</strong> Confidence Map 和 Affinity Fields (d) ，输出图片中所有人的2D关节点 (e)<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/2.png"> 
</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="Simultaneous-Detection-and-Association（整体网络框架）"><a href="#Simultaneous-Detection-and-Association（整体网络框架）" class="headerlink" title="Simultaneous Detection and Association（整体网络框架）"></a>Simultaneous Detection and Association（整体网络框架）</h3><ul>
<li>网络分为2个 branch，<strong>上侧的 branch 预测 confidence map，下侧的 branch 预测 affinity field</strong>。每个 branch 都反复<strong>迭代预测</strong>，且在每个 stage 使用<strong>中间监督 (intermediate supervision)</strong></li>
<li>输入图像先经过一个 <strong>fine-tuned 的10层 vgg-19</strong>，得到 <strong>feature map F</strong>，作为两个 branch 的输入</li>
<li>在第一个 stage 和第 t 个 stage，confidence map 和 part affinity fields 的计算如下，ρ 和 φ 表示两个CNN网络：<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/4.png">
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/3.png"></li>
<li>从下图可以看到，随着迭代的进行，在后面的stage可以很好地分辨出“左右”关系，误判的情况也好了很多<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/5.png"> </li>
<li>使用预测的 confidence map 和 groundtruth map 之间的 <strong>L2 loss</strong> 来计算损失函数<blockquote>
<ol>
<li>由于部分数据集并没有把图片上所有人都标注出来，因此在计算 loss 的时候，加了一个权重 <strong>W(p)</strong><img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/6.png"> </li>
<li>其中，W 是一个 binary mask，若在 p 位置没有标注时，W(p)=0。所以，从上面的 loss function 可以看出，stage t 的损失函数值为：对于每一个 joint 对应的 heatmap，逐像素计算预测值与标签值的差距（heatmap 只有关节处附近为正值，其余都为0），在缺乏标签处设置 W=0</li>
<li>使用 intermediate supervision 来防止梯度消失</li>
<li><strong>Overall objective:</strong><img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/7.png"> 
</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="Confidence-Maps-for-Part-Detection（branch-1介绍）"><a href="#Confidence-Maps-for-Part-Detection（branch-1介绍）" class="headerlink" title="Confidence Maps for Part Detection（branch 1介绍）"></a>Confidence Maps for Part Detection（branch 1介绍）</h3><ul>
<li><p>数据集给出的是关节点的坐标，因此要<strong>把这些 annotated 2D keypoints 转化为 heatmap</strong>，对每个人 k，其关节 j 的 heatmap 如下：</p>
 <img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/8.png"> 
<blockquote>
<p>其中，x<sub>j,k</sub> 是坐标标签，S<sub>j,k</sub> 表示关节 j，人 k 在位置 p 的响应值</p>
</blockquote>
</li>
<li><p>由于不同人之间可能存在遮挡，所以对于关节 j 的 heatmap，<strong>对不同人的响应取 max</strong>：</p>
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/10.png">
<blockquote>
<p>若是取 average，那么就不能很好地反应关节点的位置，如下图，使用 average 的话就找不到两个峰值了，也就无法找到关节点了（注：后面的 PAF 用平均）</p>
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/9.png">
</blockquote>
</li>
<li><p>在<strong>测试</strong>时，在获得 heatmap 后，使用<strong>非极大值抑制（non-maximum suppression）</strong>来得到具体位置</p>
</li>
</ul>
<h3 id="Part-Affinity-Fields-for-Part-Association（branch-2介绍）"><a href="#Part-Affinity-Fields-for-Part-Association（branch-2介绍）" class="headerlink" title="Part Affinity Fields for Part Association（branch 2介绍）"></a>Part Affinity Fields for Part Association（branch 2介绍）</h3><ul>
<li>当把所有关节点位置都确定了以后，就需要确定哪些关节点属于同一个人</li>
<li>一种测量关节间关联度的方法是检测关节间的 <strong>midpoint</strong>，如下图 b 所示<blockquote>
<ol>
<li>但当不同人之间挨的比较近的时候，可能就会发生错误（如下图 b 中的绿线）</li>
<li>这是因为这种 representation 只编码了位置，那么位置近的自然而然就会有较大的关联度，这在上述情况下就会发生错误</li>
<li>另一个原因就是这种 representation 把整个 limb 简化为了一个点</li>
</ol>
</blockquote>
</li>
</ul>
<ul>
<li><p>为了解决上述问题，文章提出使用一种新的特征表示：<strong>Part Affinity Fields</strong>，这种表示同时保留了 <strong>location</strong> 和 <strong>orientation</strong> 的信息，见下图 c</p>
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/11.png">
</li>
<li><p>Part Affinity 是一种对于每个 limb 的 2D vector field，见图 1。对于每个在 limb 范围内的像素点，其都有一个 2d vector 来表示 limb 的方向</p>
</li>
<li>如下图，如果点 p 在第 k 个人的 limb c 上，那么这个点的<strong>标签值 L*</strong> 如下定义<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/12.png">  
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/13.png">
<blockquote>
<ol>
<li>其中，v 的定义如下，是一个<strong>单位向量</strong>：<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/14.png"> </li>
<li>满足如下条件的<strong>点 p 是被定义在 limb c 上</strong>的（第一个条件保证了点 p 投影到 limb c 上时，是在关节点中间的，不会超出外面；第二个条件则是限定了点 p 距离 limb c 的最大距离）：<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/15.png">  </li>
</ol>
</blockquote>
</li>
<li>因此，Part Affinity Field 的 <strong>groundtruth</strong> 就是把所有人的 L <strong>平均</strong>，具体如下，其中 n<sub>c</sub>(p) 是 p 点非零向量数，为了求平均<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/16.png">  </li>
<li>在<strong>测试</strong>时，通过沿着 candidate limb 做<strong>线性积分</strong>来得到该 candidate limb 两端关节的<strong>相关性</strong>（为了从一大堆 candidate 中获得正确 limb 的位置，在关节处是使用非极大值抑制来获取最终预测的关节点位置），具体如下：<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/17.png">  
<blockquote>
<p>其中，点积后面一项<strong>（d<sub>j2</sub> - d<sub>j1</sub>）</strong>表示关节 j1 - j2 的 <strong>limb 所在直线</strong>，<strong>p(u) 为该直线上的某一点</strong>，通过<strong>插值</strong>得到（<strong>实际上就直接等间隔加</strong>），L<sub>c</sub>(p(u)) 表示点 p(u) 位置的 Part Affinity（对于正确的 limb，L<sub>c</sub>(p(u)) 的方向应该和该 limb 所在直线基本吻合，所以点积的值也就最大。具体怎么选取 candidate limb 是在解析阶段完成，这是一个 K-dimensional matching 问题，NP-Hard）</p>
</blockquote>
</li>
</ul>
<h3 id="Multi-Person-Parsing-using-PAFs（从-joints-和-PAF-的-confidence-map-还原得到最终的多人骨架）"><a href="#Multi-Person-Parsing-using-PAFs（从-joints-和-PAF-的-confidence-map-还原得到最终的多人骨架）" class="headerlink" title="Multi-Person Parsing using PAFs（从 joints 和 PAF 的 confidence map 还原得到最终的多人骨架）"></a>Multi-Person Parsing using PAFs（从 joints 和 PAF 的 confidence map 还原得到最终的多人骨架）</h3><ul>
<li>在使用非极大值抑制得到一些 candidate joint 以后，这些 joint 又可以组成一大堆 candidate limb。通过 PAF 得到了这些 limb 的 score，但是根据 score 判断哪些 limb 正确需要保留，哪些不需要的这个问题是K分图匹配问题，NP-Hard</li>
<li>下面用正式的符号来表述上面的想法： <img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/19.png">  </li>
<li>如果只考虑如何找到其中一个 limb，那么这个问题就是<strong>二分图最大匹配问题（maximum weight bipartite graph matching problem）</strong>。其中，D<sub>j<sub>1</sub></sub> 和 D<sub>j<sub>2</sub></sub> 就是二分图问题中的节点，边就是 limb。二分图中的<strong>匹配（matching）</strong>就是指没有任何两条边共享同一个节点</li>
<li><p>所以，该问题可以定义如下，可以使用<strong>匈牙利算法（Hungarian Algorithm）</strong>来获得这个最大匹配：<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/20.png">  <img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/21.png">   </p>
<blockquote>
<p>其中，前面就是要找到对于 limb c 最大的 E<sub>c</sub> 所对应的 Z<sub>c</sub>；后面两个式子则是保证没有两条边分享同一个节点</p>
</blockquote>
</li>
<li><p>但若是要找所有的 limb，这个问题就变成了 <strong>K 维匹配问题（如图 6 的 b）</strong>，是一个 <strong>NP-Hard</strong> 问题，但是有一系列的<strong>松弛法（relaxaion）</strong></p>
<blockquote>
<p>如下图 b，原问题就是需要从这一堆连线中判定哪些线最终需要保留；但由于某些关节之间是不会有 limb 的，因此根据这个性质可以去掉一部分线，仅保留一棵生成树，即下图 c；而且，根据问题的性质，每种 limb 可以独立考虑，因此可以进一步划分为一堆二分图匹配问题</p>
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/18.png">  
</blockquote>
</li>
<li><p>因此，这整个问题可以由下式表示：</p>
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/22.png">   
</li>
</ul>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><ul>
<li>在 MPII human multi-person dataset 和 COCO 2016 keypoints challenge dataset 上做评估<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/23.png"> 
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/24.png">  
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/25.png"> 
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/26.png"> 
<img src="/2018/07/27/Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/27.png"> 
 
 </li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 人体姿态估计 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习及应用]]></title>
      <url>/2018/07/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>ZJU 机器学习及应用课程</p>
<a id="more"></a>
<h2 id="深度学习简介"><a href="#深度学习简介" class="headerlink" title="深度学习简介"></a>深度学习简介</h2><ul>
<li>深度学习是由在计算机上模拟人类神经回路的“神经元网络”技术发展而来</li>
<li>神经元网络是在计算机上把虚拟的神经元排列成层状，模拟真正的神经细胞之间的电信号。借此实现大脑从各式各样的数据中提取本质概念的功能</li>
<li>人工神经网络通过模拟生物神经网络（大脑）的结构和功能，由大量的节点（或称“神经元”，或“单元”）和之间相互联接构成，可以用来对数据之间的复杂关系进行建模</li>
<li>所谓“深度”是指网络层数大于1。通常是把神经元“深化”到4-9层，实现接近于大脑的性能</li>
</ul>
<h3 id="深度学习革命"><a href="#深度学习革命" class="headerlink" title="深度学习革命"></a>深度学习革命</h3><ul>
<li>语音识别：可以使得词错误率从 1/4下降到1/8</li>
<li>计算机视觉：目标识别、图像分类等</li>
<li>自然语言处理：分布式表示、机器翻译、问题回答等</li>
</ul>
<h3 id="深度学习难点"><a href="#深度学习难点" class="headerlink" title="深度学习难点"></a>深度学习难点</h3><ul>
<li>参数过多，影响训练</li>
<li>非凸优化问题：即存在局部最优而非全局最优解，影响迭代下层参数比较难调</li>
<li>参数解释起来比较困难</li>
</ul>
<h3 id="深度学习需求"><a href="#深度学习需求" class="headerlink" title="深度学习需求"></a>深度学习需求</h3><ul>
<li>计算资源要大</li>
<li>数据要多</li>
<li>算法效率要好：即收敛快</li>
</ul>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><ul>
<li><p>机器学习主要是研究如何使计算机从给定的数据中学习规律，即从观测数据（样本）中寻找规律，并利用学习到的规律（模型）对未知或无法观测的数据进行预测。目前，主流的机器学习算法是基于统计的方法，也叫<strong>统计机器学习</strong></p>
<img src="/2018/07/17/机器学习及应用/3.png">
</li>
<li><p>狭义地讲，机器学习是给定一些训练样本 (xi, yi), 1&lt;=i&lt;=N（其中 xi 是输入，yi 是需要预测的目标），让计算机自动寻找一个<strong>决策函数 f (.) </strong>来建立 x 和 y 之间的关系:</p>
<img src="/2018/07/17/机器学习及应用/4.png">
</li>
<li><p>这里，ŷ 是模型输出，θ 为决策函数的参数，ϕ(x) 表示样本 x 对应的特征表示。因为 x 不一定都是数值型的输入，因此需要通过 ϕ(x) 将 x 转换为数值型的输入。如果我们假设 x 是已经处理好的标量或向量，公式也可以直接写为:</p>
<img src="/2018/07/17/机器学习及应用/5.png">
</li>
</ul>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><ul>
<li><p>我们还要建立一些准则来衡量决策函数的好坏。在很多机器学习算法中，一般是定义一个损失函数 L(y,f(x,θ))，然后在所有的训练样本上来评价决策函数的风险:</p>
<img src="/2018/07/17/机器学习及应用/6.png">
</li>
<li><p>这里，风险函数 R(θ)        是在已知的训练样本（经验数据）上计算得来的，因此被称之为经验风险。用对参数求经验风险来逐渐逼近理想的期望风险的最小值，就是我们常说的<strong>经验风险最小化原则（Empirical Risk Minimization）</strong>。这样，我们的目标就是变成了找到一个参数 θ* 使得经验风险最小:</p>
<img src="/2018/07/17/机器学习及应用/7.png">
</li>
</ul>
<h4 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h4><ul>
<li>因为用来训练的样本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地反映全部数据的真实分布</li>
<li>经验风险最小化原则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高。这就是所谓的过拟合。过拟合问题往往是由于训练数据少和噪声等原因造成的</li>
<li>和过拟合相对应的一个概念是泛化错误</li>
</ul>
<h4 id="结构风险最小化原则"><a href="#结构风险最小化原则" class="headerlink" title="结构风险最小化原则"></a>结构风险最小化原则</h4><ul>
<li><p>为了解决过拟合问题，一般在经验风险最小化的原则上上加<strong>参数的正则化（Regularization）</strong>，也叫结构风险最小化原则（Structure Risk Minimization）</p>
<img src="/2018/07/17/机器学习及应用/8.png"> 
</li>
<li><p>这里，||θ||2 是L2 范数的正则化项，用来<strong>减少参数空间，避免过拟合</strong>。用来控制正则化的强度。正则化项也可以使用其它函数，比如 L1 范数。L1 范数的引入通常会使得参数有一定稀疏性，因此在很多算法中也经常使用。在Bayes 估计的角度来讲，<strong>正则化是假设了参数的先验分布，不完全依赖训练数据</strong></p>
</li>
</ul>
<h4 id="损失函数实例"><a href="#损失函数实例" class="headerlink" title="损失函数实例"></a>损失函数实例</h4><ul>
<li>0-1 损失函数（0-1 loss function）：<img src="/2018/07/17/机器学习及应用/9.png"> </li>
<li>平方损失函数（quadratic loss function）：<img src="/2018/07/17/机器学习及应用/10.png"> </li>
<li><p>交叉熵损失函数：</p>
<blockquote>
<p>对于分类问题，预测目标 y 为离散的类别，模型输出 f(x,θ) 为每个类的条件概率。假设 y ∈ {1, ···, C}，模型预测的第 i 个类的条件概率 P(y=i|x)=fi(x,θ)，则 f(x,θ) 满足 </p>
<img src="/2018/07/17/机器学习及应用/11.png"> 
<p>fy(x,θ) 可以看作真实类别 y 的似然函数。参数可以直接用最大似然估计来优化。考虑到计算问题，我们经常使用最小化负对数似然，也就是负对数似然损失函数（Negative Log Likelihood function）:</p>
<img src="/2018/07/17/机器学习及应用/12.png"> 
<p>如果我们用one-hot向量 y 来表示目标类别c，其中只有yc = 1，其余的向量元素都为0。负对数似然函数也可以写为：</p>
<img src="/2018/07/17/机器学习及应用/13.png"> 
<p>yi 也可以看成是真实类别的分布，这样上式恰好是交叉熵的形式。因此，负对数似然损失函数也常叫做交叉熵损失函数（Cross Entropy Loss function）</p>
</blockquote>
</li>
<li><p>Hinge 损失函数：对于两类分类问题，y 的取值为{-1, +1}，f(x,θ) 的取值为[-1, 1]</p>
<img src="/2018/07/17/机器学习及应用/14.png"> 
</li>
</ul>
<h3 id="机器学习算法类型"><a href="#机器学习算法类型" class="headerlink" title="机器学习算法类型"></a>机器学习算法类型</h3><h4 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h4><ul>
<li>有监督学习是利用一组已知输入 x 和输出 y 的数据来学习模型的参数，使得模型预测的输出标记和真实标记尽可能的一致。有监督学习根据输出类型又可以分为回归和分类两类。</li>
<li>回归（Regression） 如果输出 y 是连续值（实数或连续整数），f (x) 的输出也是连续值。这种类型的问题就是回归问题。对于所有已知或未知的 (x,y)，使得 f(x,θ) 和 y 尽可能地一致。损失函数通常定义为平方误差。</li>
<li>分类（Classification） 如果输出 y 是离散的类别标记（符号），就是分类问题。损失函数有一般用 0-1 损失函数或负对数似然函数等。在分类问题中，通过学习得到的决策函数 f(x,θ) 也叫分类器。</li>
</ul>
<h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><ul>
<li>无监督学习是用来学习的数据不包含输出目标，需要学习算法自动学习到一些有价值的信息。一个典型的无监督学习问题就是聚类（Clustering）</li>
</ul>
<h4 id="增强学习"><a href="#增强学习" class="headerlink" title="增强学习"></a>增强学习</h4><ul>
<li>增强学习也叫强化学习，强调如何基于环境做出一系列的动作，以取得最大化的<strong>累积收益</strong>。每做出一个动作，并不一定立刻得到收益。增强学习和有监督学习的不同在于增强学习不需要显式地以输入/输出对的方式给出训练样本，是一种在线的学习机制</li>
</ul>
<h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3> <img src="/2018/07/17/机器学习及应用/15.png"> 
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><ul>
<li>梯度下降是求得所有样本上的风险函数最小值，叫做批量梯度下降法。若样本个数 N 很大，输入 x 的维数也很大时，那么批量梯度下降法每次迭代要处理所有的样本，效率会较低。为此，有一种改进的方法即随机梯度下降法。</li>
<li>随机梯度下降法（Stochastic Gradient Descent，SGD）也叫增量梯度下降，每个样本都进行更新<img src="/2018/07/17/机器学习及应用/16.png"> </li>
<li>x(t), y(t) 是第 t 次迭代选取的样本</li>
</ul>
<h4 id="Early-Stop"><a href="#Early-Stop" class="headerlink" title="Early-Stop"></a>Early-Stop</h4><ul>
<li>在梯度下降训练的过程中，由于过拟合的原因，在训练样本上收敛的参数，并不一定在测试集上最优。因此，我们使用一个验证集（Validation Dataset）（也叫开发集（Development Dataset））来测试每一次迭代的参数在验证集上是否最优。如果在验证集上的错误率不再下降，就停止迭代。这种策略叫Early-Stop。如果没有验证集，可以在训练集上进行交叉验证</li>
</ul>
<h4 id="学习率设置"><a href="#学习率设置" class="headerlink" title="学习率设置"></a>学习率设置</h4><ul>
<li><p>动量法（Momentum Method）[Rumelhart et al., 1988]：</p>
<blockquote>
<p>对当前迭代的更新中加入上一次迭代的更新。在第 t 次迭代时， </p>
<img src="/2018/07/17/机器学习及应用/17.png"> 
<img src="/2018/07/17/机器学习及应用/18.png"> 
<p>其中，ρ 为动量因子，通常设为0.9。这样，在迭代初期，使用前一次的梯度进行加速。在迭代后期的收敛值附近，因为两次更新方向基本相反，增加稳定性</p>
</blockquote>
</li>
<li><p>AdaGrad（Adaptive Gradient）算法 [Duchi et al., 2011]：</p>
<blockquote>
<p>借鉴 L2 正则化的思想。在第 t 次迭代时， </p>
<img src="/2018/07/17/机器学习及应用/19.png"> 
<p>其中，ρ 是初始的学习率，gτ 是第 τ 次迭代时的梯度。随着迭代次数的增加，梯度逐渐缩小</p>
</blockquote>
</li>
<li><p>AdaDelta 算法 [Zeiler, 2012]：</p>
<blockquote>
<p>用指数衰减的移动平均来累积历史的梯度信息。第 t 次迭代的梯度的期望 E 为 </p>
<img src="/2018/07/17/机器学习及应用/20.png">
<p>本次迭代的更新为</p>
<img src="/2018/07/17/机器学习及应用/21.png">
<p>其中，E(∇θ^2) 为前一次迭代时 ∇θ^2 的移动平均，ɛ 为常数<br>累计更新本次迭代 ∇θ^2 的移动平均</p>
<img src="/2018/07/17/机器学习及应用/22.png">
<p>最后更新参数</p>
<img src="/2018/07/17/机器学习及应用/23.png">
</blockquote>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> ZJU课程 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Daily Reading]]></title>
      <url>/2018/07/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Daily-Reading/</url>
      <content type="html"><![CDATA[<p>记录一下每天看的公众号和知乎相关内容</p>
<a id="more"></a>
<hr>
<h3 id="2017-12-26"><a href="#2017-12-26" class="headerlink" title="2017-12-26"></a>2017-12-26</h3><h4 id="1-十大机器学习Python库-机器之心"><a href="#1-十大机器学习Python库-机器之心" class="headerlink" title="1. 十大机器学习Python库(机器之心)"></a>1. 十大机器学习Python库(机器之心)</h4><blockquote>
<p>大部分都没见过，可以看看</p>
</blockquote>
<hr>
<h3 id="2017-12-27"><a href="#2017-12-27" class="headerlink" title="2017-12-27"></a>2017-12-27</h3><h4 id="1-如何在NLP领域干成第一件事-AI科技评论"><a href="#1-如何在NLP领域干成第一件事-AI科技评论" class="headerlink" title="1. 如何在NLP领域干成第一件事(AI科技评论)"></a>1. 如何在NLP领域干成第一件事(AI科技评论)</h4><blockquote>
<p>找开源项目并重现，争取进一步改善；<br>找如ACL会议论文集，找感兴趣的方向8，了解该方向的方法/数据/团队；</p>
</blockquote>
<h4 id="2-Python相关文章-AI科技评论"><a href="#2-Python相关文章-AI科技评论" class="headerlink" title="2. Python相关文章(AI科技评论)*"></a>2. <strong>Python相关文章(AI科技评论)*</strong></h4><blockquote>
<p>静态代码检查工具Flake；<br>视频合成器；<br>从零开始用遗传算法和深度学习演化有机体的生长过程；<br>破解验证码；<br>Chutes&amp;Ladders游戏模拟；<br>创建Chatbot；<br>图像散列；<br>介绍BP；<br>Memorization技术，加速Python；<br>分享Python学习技巧</p>
</blockquote>
<h4 id="3-Attention模型-机器学习算法与自然语言处理"><a href="#3-Attention模型-机器学习算法与自然语言处理" class="headerlink" title="3. Attention模型(机器学习算法与自然语言处理)"></a>3. Attention模型(机器学习算法与自然语言处理)</h4><blockquote>
<p>各种Attention机制的综述 </p>
</blockquote>
<h4 id="4-神经进化策略-机器之心"><a href="#4-神经进化策略-机器之心" class="headerlink" title="4. 神经进化策略(机器之心)*"></a>4. <strong>神经进化策略(机器之心)*</strong></h4><blockquote>
<p>可能未来使用神经进化策略替代反向传播，了解一下</p>
</blockquote>
<hr>
<h3 id="2017-12-28"><a href="#2017-12-28" class="headerlink" title="2017-12-28"></a>2017-12-28</h3><h4 id="1-CS中的线代-机器之心"><a href="#1-CS中的线代-机器之心" class="headerlink" title="1. CS中的线代(机器之心)*"></a>1. <strong>CS中的线代(机器之心)*</strong></h4><blockquote>
<p>一篇普渡的论文，45页</p>
</blockquote>
<h4 id="2-2018AI研究趋势-机器之心"><a href="#2-2018AI研究趋势-机器之心" class="headerlink" title="2. 2018AI研究趋势(机器之心)**"></a>2. <strong>2018AI研究趋势(机器之心)**</strong></h4><blockquote>
<p>汇总资源：开放资源(介绍了DeepMind/OpenAI等的博客，着重推荐Distill)；<br>机器翻译；<br>理解视频(预测下一帧等+数据集介绍)；<br>多任务/多模式学习；<br>强化学习(游戏Dota/星际争霸)；<br>解释人工智能(可视化/InterpretNet)；<br>保护人工智能被对抗样本愚弄；<br>超越梯度(合成梯度/进化策略/SGD改进/学习优化/不同空间的优化)；<br>3D和图形的几何深度学习</p>
</blockquote>
<h4 id="3-FoolNLTK：一个便捷的中文处理工具-机器之心"><a href="#3-FoolNLTK：一个便捷的中文处理工具-机器之心" class="headerlink" title="3. FoolNLTK：一个便捷的中文处理工具(机器之心)"></a>3. FoolNLTK：一个便捷的中文处理工具(机器之心)</h4><blockquote>
<p>基于BiLSTM的开源中文分词模型</p>
</blockquote>
<h4 id="4-NIPS-2017的收获与思考-AI科技评论"><a href="#4-NIPS-2017的收获与思考-AI科技评论" class="headerlink" title="4. NIPS 2017的收获与思考(AI科技评论)"></a>4. NIPS 2017的收获与思考(AI科技评论)</h4><blockquote>
<p>3篇Best paper：博弈论相关，打败德州扑克顶级玩家；随机优化风险最小化问题；提出全新的拟合优度算法。都好高端，不知道讲的是什么<br>这篇文章作者主要关注了强化学习；<br> *还介绍了4篇MSRA的paper：有一篇关于机器翻译的论文可能可以用在LipNet项目中？</p>
</blockquote>
<h4 id="5-如何理解hekaiming的Focal-Loss-PaperWeekly"><a href="#5-如何理解hekaiming的Focal-Loss-PaperWeekly" class="headerlink" title="5. 如何理解hekaiming的Focal Loss(PaperWeekly)"></a>5. 如何理解hekaiming的Focal Loss(PaperWeekly)</h4><blockquote>
<p>解决分类问题中类别不平衡、分类难度差异的一个loss</p>
</blockquote>
<h4 id="6-草根学Python-机器学习研究会"><a href="#6-草根学Python-机器学习研究会" class="headerlink" title="6. 草根学Python(机器学习研究会)**"></a>6. <strong>草根学Python(机器学习研究会)**</strong></h4><blockquote>
<p>寒假和笨方法学Python一起看</p>
</blockquote>
<hr>
<h3 id="2017-12-29"><a href="#2017-12-29" class="headerlink" title="2017-12-29"></a>2017-12-29</h3><h4 id="1-2017最火的五篇深度学习论文-专知"><a href="#1-2017最火的五篇深度学习论文-专知" class="headerlink" title="1. 2017最火的五篇深度学习论文(专知)"></a>1. 2017最火的五篇深度学习论文(专知)</h4><blockquote>
<p>CycleGAN-图像迁移；<br>Wasserstein GAN-提出更好的用于训练GAN的目标函数；<br>simGAN-产生模拟数据，使用未标记的真实数据来改进模拟数据(无监督的)<br>AlphaGo zero-无人类知识先验的情况下学会下围棋<br>深度图像先验-理解神经网络模型中先验的作用(没搞懂)</p>
</blockquote>
<h4 id="2-机器学习、NLP、Python和Math最好的150余个教程-AI科技大本营"><a href="#2-机器学习、NLP、Python和Math最好的150余个教程-AI科技大本营" class="headerlink" title="2. 机器学习、NLP、Python和Math最好的150余个教程(AI科技大本营)**"></a>2. <strong>机器学习、NLP、Python和Math最好的150余个教程(AI科技大本营)**</strong></h4><blockquote>
<p>资源汇总</p>
</blockquote>
<hr>
<h3 id="2017-12-30"><a href="#2017-12-30" class="headerlink" title="2017-12-30"></a>2017-12-30</h3><h4 id="1-ICCV2017-基于检测和跟踪的视频中人体姿态估计-专知"><a href="#1-ICCV2017-基于检测和跟踪的视频中人体姿态估计-专知" class="headerlink" title="1. ICCV2017: 基于检测和跟踪的视频中人体姿态估计(专知)*"></a>1. <strong>ICCV2017: 基于检测和跟踪的视频中人体姿态估计(专知)*</strong></h4><blockquote>
<p>人体姿态估计相关</p>
</blockquote>
<h4 id="2-如何与深度学习服务器优雅的交互-夕小瑶"><a href="#2-如何与深度学习服务器优雅的交互-夕小瑶" class="headerlink" title="2. 如何与深度学习服务器优雅的交互(夕小瑶)**"></a>2. <strong>如何与深度学习服务器优雅的交互(夕小瑶)**</strong></h4><blockquote>
<p>服务器相关操作</p>
</blockquote>
<h4 id="3-机器之心年度盘点：2017年人工智能领域备受关注的科研成果-机器之心"><a href="#3-机器之心年度盘点：2017年人工智能领域备受关注的科研成果-机器之心" class="headerlink" title="3. 机器之心年度盘点：2017年人工智能领域备受关注的科研成果(机器之心)"></a>3. 机器之心年度盘点：2017年人工智能领域备受关注的科研成果(机器之心)</h4><blockquote>
<p>AlphaGo-无须人类知识标注，自我对抗<br>德州扑克击败人类-深度学习/纳什均衡的博弈求解<br>自归一化-比BN更好的归一化<br>GAN和各种变体<br>深度神经网络碰上语音合成-WaveNet<br>大批量数据并行训练ImageNet-分布式同步SGD训练(将ResNet-50在ImageNet上的训练时间缩短到48分钟)<br>Capsule-抛弃反向传播<br>递归皮质网络-新型概率生成模型，旨在超越神经网络<br>从TPU到NPU-NPU是华为麒麟970手机端的芯片</p>
</blockquote>
<h4 id="4-机器学习非凸优化技术-机器之心"><a href="#4-机器学习非凸优化技术-机器之心" class="headerlink" title="4. 机器学习非凸优化技术(机器之心)"></a>4. 机器学习非凸优化技术(机器之心)</h4><h4 id="5-在线深度学习：在数据流中实时学习深度神经网络-机器之心"><a href="#5-在线深度学习：在数据流中实时学习深度神经网络-机器之心" class="headerlink" title="5. 在线深度学习：在数据流中实时学习深度神经网络(机器之心)"></a>5. 在线深度学习：在数据流中实时学习深度神经网络(机器之心)</h4><hr>
<h3 id="2018-02-10"><a href="#2018-02-10" class="headerlink" title="2018-02-10"></a>2018-02-10</h3><h4 id="1-想要实现深度神经网络？一张-Excel-表格就够了-机器之心-链接"><a href="#1-想要实现深度神经网络？一张-Excel-表格就够了-机器之心-链接" class="headerlink" title="1. 想要实现深度神经网络？一张 Excel 表格就够了(机器之心) 链接"></a>1. 想要实现深度神经网络？一张 Excel 表格就够了(机器之心) <a href="https://mp.weixin.qq.com/s/Gdqo4XKkq6UG0aS4KF2MXg" target="_blank" rel="noopener">链接</a></h4><ul>
<li>有一个比较完整的CNN流程，关于CNN的一些理解：<a href="https://docs.google.com/spreadsheets/d/1SwfVctd4TjdN2S8BL09ktpQN_41sARYzD3NEHyr-8Z0/edit?usp=sharing" target="_blank" rel="noopener">链接</a>    </li>
</ul>
<h4 id="2-Facebook提出DensePose数据集和网络架构：可实现实时的人体姿态估计-机器之心-链接"><a href="#2-Facebook提出DensePose数据集和网络架构：可实现实时的人体姿态估计-机器之心-链接" class="headerlink" title="2. Facebook提出DensePose数据集和网络架构：可实现实时的人体姿态估计(机器之心)* 链接"></a>2. <strong>Facebook提出DensePose数据集和网络架构：可实现实时的人体姿态估计(机器之心)*</strong> <a href="https://mp.weixin.qq.com/s/sFd9hrMrKDl5UJwlY6N7mw" target="_blank" rel="noopener">链接</a></h4><ul>
<li>人体姿态估计相关</li>
</ul>
<hr>
<h3 id="2018-02-11"><a href="#2018-02-11" class="headerlink" title="2018-02-11"></a>2018-02-11</h3><h4 id="1-从语义上理解卷积核行为，UCLA朱松纯等人使用决策树量化解释CNN-机器之心-链接"><a href="#1-从语义上理解卷积核行为，UCLA朱松纯等人使用决策树量化解释CNN-机器之心-链接" class="headerlink" title="1. 从语义上理解卷积核行为，UCLA朱松纯等人使用决策树量化解释CNN(机器之心)* 链接"></a>1. <strong>从语义上理解卷积核行为，UCLA朱松纯等人使用决策树量化解释CNN(机器之心)*</strong> <a href="https://mp.weixin.qq.com/s/t9ZHW8fkWtnvpM7ynJOTDw" target="_blank" rel="noopener">链接</a></h4><ul>
<li><strong>解释CNN模型</strong>：借助<strong>决策树</strong>在语义层面上解释 CNN 做出的每一个特定预测，即哪个卷积核（或物体部位）被用于预测最终的类别，以及其在预测中贡献了多少。<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735975&amp;idx=1&amp;sn=af91c24d8b0d058f35ac8b1ea65a0ea9&amp;chksm=871ac119b06d480f573675a7a60c6653fe8bcd09e2e5627b15ce1a2c704acecb8d857cde60fe&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福也有类似的工作</a>。</li>
</ul>
<h4 id="2-李沐《动手学深度学习》课程视频汇总-机器之心-链接"><a href="#2-李沐《动手学深度学习》课程视频汇总-机器之心-链接" class="headerlink" title="2. 李沐《动手学深度学习》课程视频汇总(机器之心) 链接"></a>2. 李沐《动手学深度学习》课程视频汇总(机器之心) <a href="https://mp.weixin.qq.com/s/_6ewS7kzUC5TK71rjGOSAA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>使用Apache MXNet的最新前端Gluon作为开发工具。<a href="https://discuss.gluon.ai/t/topic/753" target="_blank" rel="noopener">视频链接</a>；<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">中文文档</a></li>
</ul>
<h4 id="3-一文读懂什么是变分自编码器-专知-链接"><a href="#3-一文读懂什么是变分自编码器-专知-链接" class="headerlink" title="3. 一文读懂什么是变分自编码器(专知) 链接"></a>3. 一文读懂什么是变分自编码器(专知) <a href="https://mp.weixin.qq.com/s/mtZ4_pwl8_GhitgImAU0VA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>AE到VAE</li>
</ul>
<hr>
<h3 id="2018-02-12"><a href="#2018-02-12" class="headerlink" title="2018-02-12"></a>2018-02-12</h3><h4 id="1-机器学习的经典算法-链接"><a href="#1-机器学习的经典算法-链接" class="headerlink" title="1. 机器学习的经典算法 链接"></a>1. 机器学习的经典算法 <a href="https://mp.weixin.qq.com/s/CxSG9l_dxA4G-SZKOGI1ng" target="_blank" rel="noopener">链接</a></h4><ul>
<li>回归算法：线性回归(数值问题，最小二乘法，使用梯度下降逼近求解函数极值问题) &amp; 逻辑回归(分类问题，结果中加一个Sigmoid函数)<blockquote>
<p>用于拟合逻辑回归中非线性分类线的两种算法：神经网络(ANN) &amp; SVM*(和高斯“核”结合，表达复杂的分类界限。核最典型的特征就是可以将低维的空间映射到高维空间，低维空间的非线性分类线就相当于高维空间的线性分类线)</p>
</blockquote>
</li>
<li>聚类算法：无监督的一种，K-Means。<strong>见3</strong></li>
<li>降维算法：无监督的一种，<strong>PCA*</strong></li>
<li>推荐算法：基于物品内容的推荐（将与用户购买的内容近似的物品推荐给用户） &amp; 基于用户相似度的推荐（将与目标用户兴趣相同的其他用户购买的东西推荐给目标用户），<strong>协同过滤算法*</strong></li>
<li>其他：高斯判别、朴素贝叶斯、决策树</li>
</ul>
<h4 id="2-​爬虫与反爬虫-链接"><a href="#2-​爬虫与反爬虫-链接" class="headerlink" title="2. ​爬虫与反爬虫 链接"></a>2. ​爬虫与反爬虫 <a href="https://mp.weixin.qq.com/s/tO0ArSJK4AFx5E49v7RBqw" target="_blank" rel="noopener">链接</a></h4><ul>
<li>有趣的爬虫与反爬虫工作介绍</li>
</ul>
<h4 id="3-六大聚类算法-链接"><a href="#3-六大聚类算法-链接" class="headerlink" title="3. 六大聚类算法 链接"></a>3. <strong>六大聚类算法</strong> <a href="https://mp.weixin.qq.com/s/_5A3DuVyN6aE9n5OEc19kA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>参看博文<a href="https://dmortem.github.io/2018/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%85%AD%E5%A4%A7%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/#more">六大聚类算法</a></li>
</ul>
<h4 id="4-最新云端-amp-单机GPU横评-链接"><a href="#4-最新云端-amp-单机GPU横评-链接" class="headerlink" title="4. 最新云端&amp;单机GPU横评 链接"></a>4. 最新云端&amp;单机GPU横评 <a href="https://mp.weixin.qq.com/s/gdDKw-nHdilpB3JfoLAuaA" target="_blank" rel="noopener">链接</a></h4><ul>
<li><strong>性能</strong>：Volta性能优于Nvidia 1080Ti（约1.1-1.3倍）和P100（约1.2-1.5倍）</li>
<li><strong>成本</strong>：Paperspace Volta性价比高。Google P100比Paperspace Volta贵10%，Amazon Volta比Paperspace Volta贵40%</li>
<li>Paperspace Volta适合只需要1个GPU的用户，性能好</li>
<li>Google P100最为灵活，它允许用户在任意实例上使用1、2、4个P100 GPU（或最多 8个K80 GPU），允许用户自定义CPU和GPU配置来满足计算需求。尽管由于架构所限，Tesla P100的性能略显落后，但从成本角度考虑，其性价比很有优势</li>
<li>Amazon Volta性能优于Google P100，也可以连接1、4或8个GPU。但用户无法自定义基础实例类型。性价比比较低。如果迫切需要用8个GPU或在EC2上搭建模型，那么目前仍推荐使用Amazon Volta</li>
</ul>
<h4 id="5-理解深度学习中的矩阵运算-链接"><a href="#5-理解深度学习中的矩阵运算-链接" class="headerlink" title="5. 理解深度学习中的矩阵运算* 链接"></a>5. <strong>理解深度学习中的矩阵运算*</strong> <a href="https://mp.weixin.qq.com/s/703Lb9jO0r7biA91ddV2Bg" target="_blank" rel="noopener">链接</a></h4><ul>
<li><a href="http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html" target="_blank" rel="noopener">论文链接</a></li>
</ul>
<h4 id="6-最新7篇VAE相关论文-链接"><a href="#6-最新7篇VAE相关论文-链接" class="headerlink" title="6. 最新7篇VAE相关论文 链接"></a>6. 最新7篇VAE相关论文 <a href="https://mp.weixin.qq.com/s/oTF8xiLoKpPm_n-iF2rXIQ" target="_blank" rel="noopener">链接</a></h4><p> -利用带混合解码器的条件变分自编码器生成主题汉语诗歌</p>
<ul>
<li>一种使用条件变分自编码器的Zero Shot Learning的生成模型</li>
<li>变分自编码器在不同模态之间的双向生成</li>
<li>使用深度密度先验的MR图像重建</li>
<li>变分递归神经机器翻译</li>
<li>变分自编码器的推断次优性</li>
<li>使用条件VAEs和GANs从视觉属性中合成人脸</li>
</ul>
<h4 id="7-UC-Berkeley提出特征选择新方法：条件协方差最小化-链接"><a href="#7-UC-Berkeley提出特征选择新方法：条件协方差最小化-链接" class="headerlink" title="7. UC Berkeley提出特征选择新方法：条件协方差最小化* 链接"></a>7. <strong>UC Berkeley提出特征选择新方法：条件协方差最小化*</strong> <a href="https://mp.weixin.qq.com/s/LbXHpnC19euqriCtSHeg1Q" target="_blank" rel="noopener">链接</a></h4><ul>
<li><strong>模型解释性。</strong>这篇<a href="https://papers.nips.cc/paper/7270-kernel-feature-selection-via-conditional-covariance-minimization.pdf" target="_blank" rel="noopener">论文</a>的综述部分可以看一下，论文本身数学性比较强，<a href="https://github.com/Jianbo-Lab/CCM" target="_blank" rel="noopener">Github</a></li>
<li><strong>降维可以增强模型的可解释性，特征选择则是常用的降维方法。</strong>特征选择算法通常可分为：滤波器（filter）、封装（wrapper）以及嵌入（embedded）。</li>
<li><strong>滤波器</strong>方法基于数据的本质属性选择特征，与所用的学习算法无关。如可以计算每个特征和响应变量之间的相关性，然后选择相关性最高的变量</li>
<li><strong>封装</strong>方法的目标是寻找能够使某个预测器的性能最优化的特征。如可以训练多个支持向量机，每个支持向量机使用不同的特征子集，然后选择在训练数据上损失最小的特征子集。因为特征子集的数量是指数规模的，所以封装方法通常会使用贪心算法</li>
<li><strong>嵌入</strong>方法将特征选择和预测结合成一个问题。它通常会优化一个目标函数，这个目标函数结合了拟合优度和对参数数量的惩罚。一个例子就是构建线性模型的LASSO方法，它用L1 penalty来表征对参数数目的惩罚</li>
<li><strong>本文</strong>提出了条件协方差最小化（CCM）方法，这是一个统一前两个观点的特征选择方法。这个方法基于最小化条件协方差算子的迹来进行特征选择。思想是选择能够最大化预测基于协变量响应依赖的特征。</li>
</ul>
<h4 id="8-深度学习的7大实用技巧-链接"><a href="#8-深度学习的7大实用技巧-链接" class="headerlink" title="8. 深度学习的7大实用技巧* 链接"></a>8. <strong>深度学习的7大实用技巧*</strong> <a href="https://mp.weixin.qq.com/s/geCFcJDvOAw2Jaf2_nWsrg" target="_blank" rel="noopener">链接</a></h4><ul>
<li>参看博文<a href="https://dmortem.github.io/2018/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E5%B7%A7/">深度学习技巧</a></li>
</ul>
<hr>
<h3 id="2018-02-13"><a href="#2018-02-13" class="headerlink" title="2018-02-13"></a>2018-02-13</h3><h4 id="1-机器学习中的模型评价、模型选择及算法选择-链接"><a href="#1-机器学习中的模型评价、模型选择及算法选择-链接" class="headerlink" title="1. 机器学习中的模型评价、模型选择及算法选择* 链接"></a>1. <strong>机器学习中的模型评价、模型选择及算法选择*</strong> <a href="https://mp.weixin.qq.com/s/zs9ihUFI-ixP4EgMTvnFBg" target="_blank" rel="noopener">链接</a></h4><ul>
<li>参看博文<a href="https://dmortem.github.io/2018/02/16/深度学习/机器学习中的模型评价与选择/">机器学习中的模型评价与选择</a></li>
</ul>
<h4 id="2-波士顿动力的机器人会开门了，中国尚需奋力追赶-链接"><a href="#2-波士顿动力的机器人会开门了，中国尚需奋力追赶-链接" class="headerlink" title="2. 波士顿动力的机器人会开门了，中国尚需奋力追赶 链接"></a>2. 波士顿动力的机器人会开门了，中国尚需奋力追赶 <a href="https://mp.weixin.qq.com/s/mEd0sClnv8bFuYZ7_A0r5Q" target="_blank" rel="noopener">链接</a></h4><ul>
<li>里面的几个视频非常有趣</li>
</ul>
<h4 id="3-R语言入门指导-链接"><a href="#3-R语言入门指导-链接" class="headerlink" title="3. R语言入门指导 链接"></a>3. R语言入门指导 <a href="https://mp.weixin.qq.com/s/-e7sE71OCs86c9H-8mkT7Q" target="_blank" rel="noopener">链接</a></h4><ul>
<li>比较细比较初级的教程</li>
</ul>
<h4 id="4-谷歌云TPU服务正式全面开放-链接"><a href="#4-谷歌云TPU服务正式全面开放-链接" class="headerlink" title="4. 谷歌云TPU服务正式全面开放 链接"></a>4. 谷歌云TPU服务正式全面开放 <a href="https://mp.weixin.qq.com/s/CPmSTWhnrCMAokt-nCh9nA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>张量处理器（Tensor Processing Unit，TPU）是机器学习专属芯片，去年又推出了第二代产品（Cloud TPU）。<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725188&amp;idx=1&amp;sn=98b6e447704a5797989f3200c47a5f6e&amp;chksm=871b1f3ab06c962c4087eff5fc8e35cb32e6a7964d086b377314f0373d08d4c8adad766183e3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">TPU论文</a></li>
<li>谷歌云平台（GCP）提供Cloud TPU beta版自2018年2月12日起用，旨在帮助机器学习专家更快地训练和运行ML模型</li>
<li>云TPU如今在数量受限的情况下可用，价格以秒计费，大约为每云TPU每小时6.50美元</li>
</ul>
<hr>
<h3 id="2018-02-14"><a href="#2018-02-14" class="headerlink" title="2018-02-14"></a>2018-02-14</h3><h4 id="1-多维-1-6-数据可视化策略-链接"><a href="#1-多维-1-6-数据可视化策略-链接" class="headerlink" title="1. 多维(1-6)数据可视化策略* 链接"></a>1. <strong>多维(1-6)数据可视化策略*</strong> <a href="https://mp.weixin.qq.com/s/mD732PqDtqYdFZSxZWtvvg" target="_blank" rel="noopener">链接</a></h4><p> -可视化资源：pandas、matplotlib、seaborn、plotly、bokeh库；<a href="https://d3js.org/" target="_blank" rel="noopener">D3.js</a>；The Visual Display of Quantitative Information.pdf<br> -教程的<a href="https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/effective%20data%20visualization/Bonus%20-%20Effective%20Multi-dimensional%20Data%20Visualization.ipynb" target="_blank" rel="noopener">Github资源</a></p>
<ul>
<li><strong>数据集</strong>：<a href="https://archive.ics.uci.edu/ml/index.php" target="_blank" rel="noopener">UCI机器学习库</a>中的Wine Quality Data Set，分为葡萄酒中红色和白色酒</li>
<li><strong>框架</strong>：matplotlib和seaborn</li>
<li><strong>一维数据</strong>：利用pandas画直方图、核密度图等</li>
<li><strong>二维数据</strong>：配对相关性矩阵（pair-wise correlation matrix）并将其可视化为热力图；在感兴趣的属性之间使用配对散点图；平行坐标图；散点图；联合分布图等等</li>
<li><strong>多维数据</strong>：高于3维的最好方法是使用图分面、颜色、形状、大小、深度等。还可以使用时间作为维度，为随时间变化的属性制作一段动画。每多一个维度，就使用一种新的表征，如色调、深度、大小等</li>
</ul>
<hr>
<h3 id="2018-02-15"><a href="#2018-02-15" class="headerlink" title="2018-02-15"></a>2018-02-15</h3><h4 id="1-从LeNet到SENet——卷积神经网络回顾-链接"><a href="#1-从LeNet到SENet——卷积神经网络回顾-链接" class="headerlink" title="1. 从LeNet到SENet——卷积神经网络回顾** 链接"></a>1. <strong>从LeNet到SENet——卷积神经网络回顾**</strong> <a href="https://mp.weixin.qq.com/s/2wfwe_d0_moKYDjV-WM7Jw" target="_blank" rel="noopener">链接</a></h4><hr>
<h3 id="2018-02-16"><a href="#2018-02-16" class="headerlink" title="2018-02-16"></a>2018-02-16</h3><h4 id="1-2017年机器之心AI高分概述文章全集-链接"><a href="#1-2017年机器之心AI高分概述文章全集-链接" class="headerlink" title="1. 2017年机器之心AI高分概述文章全集** 链接"></a>1. <strong>2017年机器之心AI高分概述文章全集**</strong> <a href="https://mp.weixin.qq.com/s/wDWF1RFaW9EOEoctyJvopQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li>去年机器之心的盘点：<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722778&amp;idx=1&amp;sn=941eb40c57654222b3e883affa3d08b0&amp;chksm=871b15a4b06c9cb27521a6d22fa1546947c16cd1d620a8816ec37ea3e61bc7f9331ef648f600&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">链接</a></li>
<li><strong>非常好的一份教程全集，有时间多看看</strong></li>
</ul>
<h4 id="2-谷歌大脑Wasserstein自编码器：新一代生成模型算法-链接"><a href="#2-谷歌大脑Wasserstein自编码器：新一代生成模型算法-链接" class="headerlink" title="2. 谷歌大脑Wasserstein自编码器：新一代生成模型算法 链接"></a>2. 谷歌大脑Wasserstein自编码器：新一代生成模型算法 <a href="https://mp.weixin.qq.com/s/Ci0HPy3ENz1ZooB784aMcA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>ICLR 2018. 具有VAE的一些优点，也结合了GAN结构的特性，可以实现更好的性能</li>
</ul>
<h4 id="3-机器学习研究的12个宝贵经验-链接"><a href="#3-机器学习研究的12个宝贵经验-链接" class="headerlink" title="3. 机器学习研究的12个宝贵经验 链接"></a>3. 机器学习研究的12个宝贵经验 <a href="https://mp.weixin.qq.com/s/HnJ2GfslrMcLc04eJ35qHQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li>关于机器学习的一些经验分享，非调参经验</li>
</ul>
<hr>
<h3 id="2018-02-17"><a href="#2018-02-17" class="headerlink" title="2018-02-17"></a>2018-02-17</h3><h4 id="1-区块链vs传统数据库：分布式运行有何优势-链接"><a href="#1-区块链vs传统数据库：分布式运行有何优势-链接" class="headerlink" title="1. 区块链vs传统数据库：分布式运行有何优势 链接"></a>1. 区块链vs传统数据库：分布式运行有何优势 <a href="https://mp.weixin.qq.com/s/fvrTBr7lvuXOhgyL2BRUuw" target="_blank" rel="noopener">链接</a></h4><ul>
<li>区块链是一种容错率很高的分布式数据存储模式</li>
<li><strong>去中心化控制</strong>消除了中心化控制的风险。任何能够充分访问中心化数据库的人都可以摧毁或破坏其中的数据，因此用户依赖于数据库管理员的安全基础架构。区块链技术使用去中心化数据存储来避开这一问题，从而在自己的结构中建立安全性。区块链技术很适合记录某些种类的信息，传统数据库更适合记录另外一些种类的信息。对于每个组织而言，理解它想从数据库中获得什么非常关键，我们需要在选择数据库之前，判断每种数据库的优缺点</li>
</ul>
<hr>
<h3 id="2018-02-18"><a href="#2018-02-18" class="headerlink" title="2018-02-18"></a>2018-02-18</h3><h4 id="1-胶囊网络为何如此热门-链接"><a href="#1-胶囊网络为何如此热门-链接" class="headerlink" title="1. 胶囊网络为何如此热门 链接"></a>1. 胶囊网络为何如此热门 <a href="https://mp.weixin.qq.com/s/Eyc4n-QIX3JTgBaFgC9d9w" target="_blank" rel="noopener">链接</a></h4><ul>
<li>CapsNets需要的训练数据少；</li>
<li>CapsNets能更好地处理图像多义性表达</li>
<li>CapsNets具有“同变性”，输入的微小变化会导致输出的细微变化。即详细的姿态信息在整个网络中都被保留</li>
<li>CNNs需要额外的组件来实现自动识别一个部件归属于哪一个对象（如，这条腿属于这只羊）。而CapsNets则免费提供部件的层次结构</li>
<li>CapsNets在如CIFAR10或ImageNet大规模图像测试集上的表现不如CNNs好；需要大量计算，不能检测出相互靠近的同类型的两个对象（这被称为“拥挤问题”，且已被证明人类也存在这个问题）</li>
<li>CapsNets的主要思想还是非常有前途的，似乎只需要一些调整就可以发挥全部潜力</li>
</ul>
<h3 id="2018-02-19"><a href="#2018-02-19" class="headerlink" title="2018-02-19"></a>2018-02-19</h3><h4 id="1-神经网络“剪枝”的两个方法-链接"><a href="#1-神经网络“剪枝”的两个方法-链接" class="headerlink" title="1. 神经网络“剪枝”的两个方法 链接"></a>1. 神经网络“剪枝”的两个方法 <a href="https://mp.weixin.qq.com/s/f1SCK0J5oTWNJvtld3UAHQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li>一般用于减少网络非零参数数量的方法有三种：<blockquote>
<p>(1) 正则化(regularization)：修改目标函数，如使用L0范数 <a href="https://arxiv.org/pdf/1712.01312.pdf" target="_blank" rel="noopener">论文</a><br>(2) 修剪(pruning)：面向大规模神经网络，并删除某些意义上冗余的特征或参数 <a href="https://arxiv.org/pdf/1801.05787.pdf" target="_blank" rel="noopener">论文</a><br>(3) 增长(growing)：从小型网络开始，按某种增长标准逐步增加新的单元</p>
</blockquote>
</li>
<li>减少非零参数的目的如下：<blockquote>
<p>(1) 保持相同性能的前提下降低计算成本，加速推断和训练<br>(2) 减少参数数量可以减少参数空间的冗余，从而提高泛化能力</p>
</blockquote>
</li>
<li>这篇文章介绍了两篇近期关于神经网络修剪的论文，分别是 L_0 正则化方法和 Fisher 修剪方法</li>
</ul>
<h3 id="2018-02-20"><a href="#2018-02-20" class="headerlink" title="2018-02-20"></a>2018-02-20</h3><h4 id="1-从1400篇机器学习文章中精选出Top-10-链接"><a href="#1-从1400篇机器学习文章中精选出Top-10-链接" class="headerlink" title="1. 从1400篇机器学习文章中精选出Top 10 链接"></a>1. 从1400篇机器学习文章中精选出Top 10 <a href="https://mp.weixin.qq.com/s/-5jt5lvZIiJaamfCVb4OqQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247492492&amp;idx=3&amp;sn=ed0f600a84adfa7a4c3c39ad3890a71f&amp;chksm=e99ed075dee95963ae5a2c81c54f439a19b14405febd1685d2a194e1fecb1d599a4dcba530b0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Google Brain去年干了太多事，Jeff Dean一篇长文都没回顾完</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247492791&amp;idx=3&amp;sn=495f428dc27b8fb4e4ce3e2a7fbf0ece&amp;chksm=e99ed74edee95e58f68d62a2863cf2079d5fc01557dabcb46bdf03a089c70e79d714d25f47ff&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文详解如何使用Python和Keras构建属于你的 AlphaZero AI</a></li>
<li><a href="https://arxiv.org/pdf/1801.10198.pdf" target="_blank" rel="noopener">通过概况长序列来生成维基百科</a></li>
<li><a href="http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html" target="_blank" rel="noopener">深度学习必备的矩阵微积分知识</a></li>
<li><a href="http://blog.dlib.net/2017/12/a-global-optimization-algorithm-worth.html" target="_blank" rel="noopener">一种值得采纳的全局优化算法</a></li>
<li><a href="https://github.com/MrGemy95/Tensorflow-Project-Template" target="_blank" rel="noopener">Tensorflow-Project-Template：tensorflow项目模板架构的最佳实践</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736777&amp;idx=1&amp;sn=d837a23210743031688380e4596558ee&amp;chksm=871accf7b06d45e189adbc7eb4e9d9fc518446e9aeb9a07b79a4a6ca08bdab21b926b3484a3a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何解决90％的自然语言处理问题：分步指南奉上</a></li>
<li><a href="https://lukeoakdenrayner.wordpress.com/2018/01/24/chexnet-an-in-depth-review/" target="_blank" rel="noopener">CheXNet：一次深入的回顾</a></li>
<li><a href="https://towardsdatascience.com/a-tour-of-the-top-10-algorithms-for-machine-learning-newbies-dde4edffae11" target="_blank" rel="noopener">机器学习新手顶级算法之旅</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247492507&amp;idx=2&amp;sn=0eba361a729d7b7bc79cd541513183a0&amp;chksm=e99ed062dee9597456586ec07bbefe5cb1deb795ad52e222f5402f958c71380379433f103244&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">学习数据科学、机器学习与AI没有多大交集，一文告诉你三者最大区别</a></li>
</ul>
<h4 id="2-区块链技术综述-链接"><a href="#2-区块链技术综述-链接" class="headerlink" title="2. 区块链技术综述* 链接"></a>2. 区块链技术综述* <a href="https://mp.weixin.qq.com/s/_RCFI2ijo0VtjAAqGck1xg" target="_blank" rel="noopener">链接</a></h4><ul>
<li>文章通过解构区块链的核心要素，提出了区块链系统的基础架构模型，详细阐述了区块链及与之相关的比特币的基本原理、技术、方法与应用现状，讨论了智能合约的理念、应用和意义</li>
</ul>
<h4 id="3-超越Adam，从适应性学习率家族出发解读ICLR-2018高分论文-链接"><a href="#3-超越Adam，从适应性学习率家族出发解读ICLR-2018高分论文-链接" class="headerlink" title="3. 超越Adam，从适应性学习率家族出发解读ICLR 2018高分论文 链接"></a>3. 超越Adam，从适应性学习率家族出发解读ICLR 2018高分论文 <a href="https://mp.weixin.qq.com/s/jVjemfcLzIWOdWdxMgoxsA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>讨论了 Adam 等适应性学习率算法的收敛性缺点，并提出了一种新的 Adam 变体</li>
<li>SGD 的一类变体通过使用历史梯度某种形式的范数而调整学习率取得了很大的成功，因为它们能针对不同的参数采用不同的学习率。一般来说，适应性学习率算法的基本思想是若损失函数对于某个给定模型参数的偏导保持相同的符号，那么学习率应该增加</li>
</ul>
<h4 id="4-Git-的4个阶段的撤销更改-链接"><a href="#4-Git-的4个阶段的撤销更改-链接" class="headerlink" title="4. Git 的4个阶段的撤销更改 链接"></a>4. Git 的4个阶段的撤销更改 <a href="https://mp.weixin.qq.com/s/szBy4m_ZPxnssb0xOO0MWQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li>工作流分为工作区、暂存区、本地仓库、远程仓库</li>
<li>git add . 把所有文件放入暂存区；git commit 把所有文件从暂存区提交进本地仓库；git push把所有文件从本地仓库推送进远程仓库</li>
<li>git diff / git diff –cached /  git diff master origin/master查看目前在工作流的哪个状态</li>
<li>撤销<blockquote>
<p>(1) 编辑器中修改了文件，还未执行git add .：git checkout .或git reset –hard<br>(2) 执行了git add .，但还没有执行git commit：git reset-&gt;git checkout .或直接git reset –hard<br>(3) git commit也执行了，但还没有push：git reset –hard origin/master(既然污染了本地仓库，那就从远程仓库复制到本地)<br>(4) push也执行了：git reset –hard HEAD^ -&gt; git push -f(先恢复本地仓库，再push到远程仓库)</p>
</blockquote>
</li>
</ul>
<h4 id="5-最流行的神经网络变体综述-链接"><a href="#5-最流行的神经网络变体综述-链接" class="headerlink" title="5. 最流行的神经网络变体综述* 链接"></a>5. 最流行的神经网络变体综述* <a href="http://www.asimovinstitute.org/neural-network-zoo/" target="_blank" rel="noopener">链接</a></h4><ul>
<li>最流行的神经网络变体综述</li>
</ul>
<hr>
<h3 id="2018-02-21"><a href="#2018-02-21" class="headerlink" title="2018-02-21"></a>2018-02-21</h3><h4 id="1-如何用人工智能帮你找论文-链接"><a href="#1-如何用人工智能帮你找论文-链接" class="headerlink" title="1. 如何用人工智能帮你找论文 链接"></a>1. 如何用人工智能帮你找论文 <a href="https://mp.weixin.qq.com/s/8PnWWpFlyXSvZRt5kHKORQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li>介绍了一款论文检索引擎arXiv-sanity，作者Andrej Karpathy</li>
</ul>
<h3 id="2018-02-22"><a href="#2018-02-22" class="headerlink" title="2018-02-22"></a>2018-02-22</h3><h4 id="1-ICLR-2018-阿姆斯特丹大学论文提出球面CNN：可用于3D模型识别和雾化能量回归"><a href="#1-ICLR-2018-阿姆斯特丹大学论文提出球面CNN：可用于3D模型识别和雾化能量回归" class="headerlink" title="1. ICLR 2018 | 阿姆斯特丹大学论文提出球面CNN：可用于3D模型识别和雾化能量回归"></a>1. ICLR 2018 | 阿姆斯特丹大学论文提出球面CNN：可用于3D模型识别和雾化能量回归</h4><ul>
<li>提出<strong>球面CNN</strong>的神经网络，用于检测球面图像上任意旋转的局部模式</li>
</ul>
<h3 id="2018-02-23"><a href="#2018-02-23" class="headerlink" title="2018-02-23"></a>2018-02-23</h3><h4 id="1-像玩乐高一样拆解Faster-R-CNN：详解目标检测的实现过程-链接"><a href="#1-像玩乐高一样拆解Faster-R-CNN：详解目标检测的实现过程-链接" class="headerlink" title="1. 像玩乐高一样拆解Faster R-CNN：详解目标检测的实现过程 链接"></a>1. 像玩乐高一样拆解Faster R-CNN：详解目标检测的实现过程 <a href="https://mp.weixin.qq.com/s/M_i38L2brq69BYzmaPeJ9w" target="_blank" rel="noopener">链接</a></h4><h4 id="2-深度学习实验流程及-PyTorch-提供的解决方案-链接"><a href="#2-深度学习实验流程及-PyTorch-提供的解决方案-链接" class="headerlink" title="2. 深度学习实验流程及 PyTorch 提供的解决方案 链接"></a>2. 深度学习实验流程及 PyTorch 提供的解决方案 <a href="https://mp.weixin.qq.com/s/Gel_DjEJygpBdquCkaeGHw" target="_blank" rel="noopener">链接</a></h4><h4 id="3-CVPR2018-DiracNets：无需跳层连接，训练更深神经网络，结构参数化与Dirac参数化的ResNet-链接"><a href="#3-CVPR2018-DiracNets：无需跳层连接，训练更深神经网络，结构参数化与Dirac参数化的ResNet-链接" class="headerlink" title="3. CVPR2018|DiracNets：无需跳层连接，训练更深神经网络，结构参数化与Dirac参数化的ResNet 链接"></a>3. CVPR2018|DiracNets：无需跳层连接，训练更深神经网络，结构参数化与Dirac参数化的ResNet <a href="https://mp.weixin.qq.com/s/mYNS3uqVYu6tGYl0bu-DKA" target="_blank" rel="noopener">链接</a></h4><h4 id="4-如何在手机上使用TensorFlow-链接"><a href="#4-如何在手机上使用TensorFlow-链接" class="headerlink" title="4. 如何在手机上使用TensorFlow 链接"></a>4. 如何在手机上使用TensorFlow <a href="https://mp.weixin.qq.com/s/WFIH0lBTEky8ZHBoA6oWqA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>一篇关于手机上训练DL模型的教程</li>
</ul>
<hr>
<h3 id="2018-03-01"><a href="#2018-03-01" class="headerlink" title="2018-03-01"></a>2018-03-01</h3><h4 id="1-谷歌机器学习课程-链接"><a href="#1-谷歌机器学习课程-链接" class="headerlink" title="1. 谷歌机器学习课程 链接"></a>1. 谷歌机器学习课程 <a href="https://mp.weixin.qq.com/s/hAPQtgFIHl8q0KyKP_X1_A" target="_blank" rel="noopener">链接</a></h4><ul>
<li><a href="https://developers.google.com/machine-learning/crash-course/ml-intro" target="_blank" rel="noopener">课程链接</a></li>
</ul>
<hr>
<h3 id="2018-03-05"><a href="#2018-03-05" class="headerlink" title="2018-03-05"></a>2018-03-05</h3><h4 id="1-弱监督学习综述-链接"><a href="#1-弱监督学习综述-链接" class="headerlink" title="1. 弱监督学习综述 链接"></a>1. 弱监督学习综述 <a href="https://mp.weixin.qq.com/s/2FenpCl5PpRnMSk_ZILIew" target="_blank" rel="noopener">链接</a></h4><ul>
<li>三种弱监督：<strong>不完全监督</strong>：只有一部分训练数据具备标签；<strong>不确切监督</strong>：训练数据只具备粗粒度标签；<strong>不准确监督</strong>：给出的标签并不总是真值</li>
</ul>
<hr>
<h3 id="2018-03-20"><a href="#2018-03-20" class="headerlink" title="2018-03-20"></a>2018-03-20</h3><h4 id="1-AAAI-2018-行为识别论文概览-链接"><a href="#1-AAAI-2018-行为识别论文概览-链接" class="headerlink" title="1. AAAI 2018 行为识别论文概览 链接"></a>1. AAAI 2018 行为识别论文概览 <a href="https://mp.weixin.qq.com/s/JAANpKU8DBCPqHJWkndE8Q" target="_blank" rel="noopener">链接</a></h4><ul>
<li>AAAI 2018的Action Recognition</li>
</ul>
<hr>
<h3 id="2018-03-21"><a href="#2018-03-21" class="headerlink" title="2018-03-21"></a>2018-03-21</h3><h4 id="1-腾讯AI-Lab的21篇CVPR-2018-链接"><a href="#1-腾讯AI-Lab的21篇CVPR-2018-链接" class="headerlink" title="1. 腾讯AI Lab的21篇CVPR 2018 链接"></a>1. 腾讯AI Lab的21篇CVPR 2018 <a href="https://mp.weixin.qq.com/s/eFRy_gfAKALmIYSJJ5aeUA" target="_blank" rel="noopener">链接</a></h4><ul>
<li>End-to-End Learning of Motion Representation for Video Understanding (面向视频理解的端到端动作表示学习)</li>
</ul>
<hr>
<h3 id="2018-04-24"><a href="#2018-04-24" class="headerlink" title="2018-04-24"></a>2018-04-24</h3><h4 id="1-深度神经网络模型压缩和加速-链接"><a href="#1-深度神经网络模型压缩和加速-链接" class="headerlink" title="1. 深度神经网络模型压缩和加速 链接"></a>1. 深度神经网络模型压缩和加速 <a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247488630&amp;idx=1&amp;sn=894b06c31b37ccdad3e9bfdd7323a33f&amp;chksm=96e9cbf6a19e42e0c666d6727430a39fe4e09db047c3cfc0465a34923b87a36dfbe7585fe339&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li>深度神经网络的压缩方法，主要可分为参数修剪与共享、低秩分解、迁移/压缩卷积滤波器和知识精炼</li>
</ul>
<hr>
<h3 id="2018-04-25"><a href="#2018-04-25" class="headerlink" title="2018-04-25"></a>2018-04-25</h3><h4 id="1-汉字书法识别挑战赛入门与经验分享-链接"><a href="#1-汉字书法识别挑战赛入门与经验分享-链接" class="headerlink" title="1. 汉字书法识别挑战赛入门与经验分享 链接"></a>1. 汉字书法识别挑战赛入门与经验分享 <a href="https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247494701&amp;idx=4&amp;sn=42875d33a5a915d87eaf73b6b79b6099&amp;chksm=e99edfd4dee956c226693c671b8cb9b2e36271b70f3e53f26bc5895f7bca72f759e132e867f6&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li><p>数据增强：汉字有笔画顺序，所以做翻转不合适，只用宽度与高度的平移来做data augmentation</p>
</li>
<li><p>提升模型效果方法：</p>
<blockquote>
<p>数据增强，如使用GAN来生成近似于真实图片的数据（但是怎么用？）<br>衰减学习率<br>模型融合。<a href="https://dmortem.github.io/2018/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E5%B7%A7/">博文</a>有相关介绍</p>
</blockquote>
</li>
<li><p>资源</p>
<blockquote>
<p>数学：李航的统计学习方法<br>图像处理：冈萨雷斯的图像处理<br>机器学习：西瓜书<br>深度学习：圣经</p>
</blockquote>
</li>
<li><p>从零介绍了使用pytorch搭建这个网络的全过程</p>
</li>
</ul>
<h4 id="2-PyTorch更新-链接1；链接2"><a href="#2-PyTorch更新-链接1；链接2" class="headerlink" title="2. PyTorch更新 链接1；链接2"></a>2. PyTorch更新 <a href="https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247494701&amp;idx=2&amp;sn=ea8411d66038f172a2f553770adccbec&amp;chksm=e99edfd4dee956c23c47c7bb97a31ee816eb3a0404466c1a57c12948d807c975053e38b18097&amp;scene=0#rd" target="_blank" rel="noopener">链接1</a>；<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741377&amp;idx=1&amp;sn=3115999abcfa6c744cec334e636072f3&amp;chksm=871adeffb06d57e9155c373255ad38c30fd06f82ba7d31105b77e810b0cc0632de9c58419628&amp;scene=0#rd" target="_blank" rel="noopener">链接2</a></h4><ul>
<li>介绍了PyTorch的一些主要变化、新特性</li>
</ul>
<hr>
<h3 id="2018-04-26"><a href="#2018-04-26" class="headerlink" title="2018-04-26"></a>2018-04-26</h3><h4 id="1-CVPR-2018值得一看的25篇论文-链接"><a href="#1-CVPR-2018值得一看的25篇论文-链接" class="headerlink" title="1. CVPR 2018值得一看的25篇论文 链接"></a>1. CVPR 2018值得一看的25篇论文 <a href="https://mp.weixin.qq.com/s/T8tLhFXuB1DATerDmAK0Dg" target="_blank" rel="noopener">链接</a></h4><ul>
<li>Im2Flow: Motion Hallucination from Static Images for Action Recognition</li>
<li>What have we learned from deep representations for action recognition?</li>
<li>Actor and Action Video Segmentation from a Sentence</li>
<li>Synthesizing Images of Humans in Unseen Poses</li>
</ul>
<h4 id="2-从零开始PyTorch项目：YOLO-v3目标检测实现-链接"><a href="#2-从零开始PyTorch项目：YOLO-v3目标检测实现-链接" class="headerlink" title="2. 从零开始PyTorch项目：YOLO v3目标检测实现 链接"></a>2. 从零开始PyTorch项目：YOLO v3目标检测实现 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741405&amp;idx=2&amp;sn=27338efe8273586ffa60d17c5cc27c67&amp;chksm=871adee3b06d57f53631207bcab1eac0019672f58bf3ed1bc2328c4a090c9643bb4ec1ab5425&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><hr>
<h3 id="2018-04-27"><a href="#2018-04-27" class="headerlink" title="2018-04-27"></a>2018-04-27</h3><h4 id="1-详解计算机视觉五大技术：图像分类、对象检测、目标跟踪、语义分割和实例分割-链接"><a href="#1-详解计算机视觉五大技术：图像分类、对象检测、目标跟踪、语义分割和实例分割-链接" class="headerlink" title="1. 详解计算机视觉五大技术：图像分类、对象检测、目标跟踪、语义分割和实例分割 链接"></a>1. 详解计算机视觉五大技术：图像分类、对象检测、目标跟踪、语义分割和实例分割 <a href="https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247485505&amp;idx=1&amp;sn=220ec856e749d008abfac84e7f40ea19&amp;chksm=ec1fe5b8db686cae94165ee5a90a0e13857b9a3e8d34709793007297109e24b030aaad95ebe8&amp;mpshare=1&amp;scene=1&amp;srcid=042764p6jhr7E0OW3rzmjsJn#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li>图像分类：AlexNet -&gt; GoogleNet -&gt; VGGNet -&gt; ResNet -&gt; DenseNet</li>
<li>目标检测：R-CNN -&gt; Fast R-CNN -&gt; Faster R-CNN / YOLO &amp; SSD &amp; R-FCN</li>
<li>*目标跟踪：SAE(DLT) / CNN(FCNT/MD Net)</li>
<li>语义分割：FCN</li>
<li>实例分割：Mask R-CNN</li>
</ul>
<h4 id="2-从RCNN到SSD，目标检测算法盘点-链接"><a href="#2-从RCNN到SSD，目标检测算法盘点-链接" class="headerlink" title="2. 从RCNN到SSD，目标检测算法盘点 链接"></a>2. 从RCNN到SSD，目标检测算法盘点 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741534&amp;idx=1&amp;sn=02dc164ffcedbf22124b97841ba67fe5&amp;chksm=871adf60b06d567690fa2328b161c012a464687768e50f812a51b5533a7d68b99af1cf8f02b8&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li>很详细的教程</li>
</ul>
<h4 id="3-只有遗忘门的LSTM性能优于标准LSTM-链接"><a href="#3-只有遗忘门的LSTM性能优于标准LSTM-链接" class="headerlink" title="3. 只有遗忘门的LSTM性能优于标准LSTM 链接"></a>3. 只有遗忘门的LSTM性能优于标准LSTM <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741534&amp;idx=5&amp;sn=32b6759b956652c01590d1422e0eb59b&amp;chksm=871adf60b06d567632a2c9a609f76590c99a26921afe305ce83c819327c6ce42631235359233&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li>删除了i和o门，并把公式做了调整，发现准确率上升</li>
<li><a href="https://arxiv.org/abs/1804.04849" target="_blank" rel="noopener">THE UNREASONABLE EFFECTIVENESS OF THE FORGET GATE</a></li>
</ul>
<h4 id="4-标准化技术在训练深度神经网络中的应用-链接"><a href="#4-标准化技术在训练深度神经网络中的应用-链接" class="headerlink" title="4. 标准化技术在训练深度神经网络中的应用 链接"></a>4. 标准化技术在训练深度神经网络中的应用 <a href="https://mp.weixin.qq.com/s?__biz=MzI5NTIxNTg0OA==&amp;mid=2247490582&amp;idx=3&amp;sn=742257d13e4b846e3f13e4305a4abd33&amp;chksm=ec57ab91db2022870450026574fd881ab058df1a20580701f31d0cb35fd33037bf6855d9a26a&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li>Normalization可以提升模型效果、提高优化效果</li>
<li>介绍了几种Normalization的技术：BN、Layer Norm、Instance Norm、Divisive Norm、Group Norm、正交权重标准化</li>
</ul>
<h4 id="5-构建ResNet残差网络-链接"><a href="#5-构建ResNet残差网络-链接" class="headerlink" title="5. 构建ResNet残差网络 链接"></a>5. 构建ResNet残差网络 <a href="https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247489869&amp;idx=1&amp;sn=c01e8e14312598f371570de5fc7f8673&amp;chksm=fc85f85ecbf271486628659a0fbfeeafda2e07da0ebe8aa5b8b94c10d39fb3745bd6c11f25c9&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></h4><ul>
<li>一般来说，网络越深，效果越好，但超过25层效果反而下降，因为梯度不好传播，容易出现梯度爆炸等情况。而在ResNet提出以后，网络可以超过2000层</li>
<li>使用Keras搭建了ResNet</li>
</ul>
<hr>
<h3 id="2018-06-10"><a href="#2018-06-10" class="headerlink" title="2018-06-10"></a>2018-06-10</h3><h4 id="1-图深度学习-GraphDL-相关文章-链接"><a href="#1-图深度学习-GraphDL-相关文章-链接" class="headerlink" title="1. 图深度学习(GraphDL)相关文章 链接"></a>1. 图深度学习(GraphDL)相关文章 <a href="https://mp.weixin.qq.com/s/w5ldyp00CqkX8Kp-8Aw0nQ" target="_blank" rel="noopener">链接</a></h4><ul>
<li>Relational inductive biases, deep learning, and graph networks （图网络深度学习综述文章）</li>
<li>Relational Deep Reinforcement Learning（关系性深度强化学习）</li>
<li>Relational recurrent neural networks（关系性循环神经网络）</li>
<li>Neural Relational Inference for Interacting Systems</li>
<li>Videos as Space-Time Region Graphs</li>
</ul>
<hr>
<h3 id="2018-07-15"><a href="#2018-07-15" class="headerlink" title="2018-07-15"></a>2018-07-15</h3><h4 id="1-GAN全景图-链接"><a href="#1-GAN全景图-链接" class="headerlink" title="1. GAN全景图 链接"></a>1. GAN全景图 <a href="https://mp.weixin.qq.com/s/IjlIT-3FVY7IfYzNDtkkgg" target="_blank" rel="noopener">链接</a></h4><ul>
<li>从损失函数、对抗架构、正则化、归一化和度量方法等几大方向整理生成对抗网络的特性与变体</li>
<li>复现了当前最佳的模型并公平地对比与探索 GAN 的整个研究图景</li>
<li>在 TensorFlow Hub 和 GitHub 也分别提供了预训练模型与对比结果</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 深度学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose]]></title>
      <url>/2018/04/15/Coarse-to-Fine-Volumetric-Prediction-for-Single-Image-3D-Human-Pose/</url>
      <content type="html"><![CDATA[<p>CVPR 2017的文章：<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Pavlakos_Coarse-To-Fine_Volumetric_Prediction_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose</a></p>
<ul>
<li>提出一种对于物体周围的3D空间进行精细离散化的表示，并使用ConvNet来预测每个关节在每个voxel的可能性。相比于直接回归，这种方法提升了性能</li>
<li>提出一种coarse-to-fine的渐进优化预测的模式。这种方法解决了维度增加的问题，允许了迭代优化和图像特征的重复处理</li>
</ul>
<a id="more"></a>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2>]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
            <tag> Human Pose Estimation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Two-Stream Convolutional Networks for Action Recognition in Videos]]></title>
      <url>/2018/04/11/Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos/</url>
      <content type="html"><![CDATA[<p>著名的双流模型，发表于2014年的NIPS：<a href="http://papers.nips.cc/paper/5353-two-stream-convolutional" target="_blank" rel="noopener">Two-Stream Convolutional Networks for Action Recognition in Videos</a></p>
<ul>
<li>空间流处理静态图像，使用在ImageNet上预训练的ConvNet</li>
<li>时间流处理连续多帧稠密光流，得到运动信息。由于用于时间流训练的数据集小，文中提出一个multi-task learning</li>
<li>两个流经softmax输出的score进行平均或使用multi-class linear SVM进行融合</li>
</ul>
<a id="more"></a>
<h2 id="Two-stream-architecture-for-video-recognition"><a href="#Two-stream-architecture-for-video-recognition" class="headerlink" title="Two-stream architecture for video recognition"></a>Two-stream architecture for video recognition</h2><ul>
<li>使用同样结构的ConvNet分别对一张静态帧和L张光流进行处理，最后对双流经softmax输出的score进行平均或使用multi-class linear SVM进行融合</li>
<li>空间流网络就直接使用在ImageNet上大放异彩的网络，并使用预训练的参数</li>
<li><strong>注：这里双流只是结构一样，具体的参数值肯定不一样，一个是提取空间信息，一个是时间信息</strong><img src="/2018/04/11/Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos/1.png">
</li>
</ul>
<h2 id="Optical-flow-ConvNets"><a href="#Optical-flow-ConvNets" class="headerlink" title="Optical flow ConvNets"></a>Optical flow ConvNets</h2><ul>
<li>细节还没仔细看</li>
<li>最后是下采样得到224*224*2L送入网络</li>
</ul>
<h2 id="Multi-task-learning"><a href="#Multi-task-learning" class="headerlink" title="Multi-task learning"></a>Multi-task learning</h2><ul>
<li>空间流网络可以在ImageNet上预训练，但时间流网络的训练集相对而言就比较小了。为了减小由于训练集小而带来的过拟合问题，若把使用的两个数据集并成一个则会很麻烦</li>
<li>使用<strong>multi-task learning</strong>: ConvNet旨在学习一个general的video representation，对于两个数据集，在CNN后面有两个不同的分类器，分别用于输出UCF-101和HMDB-51数据集的score，而总loss就是两个分类器的loss相加</li>
</ul>
<h2 id="Implementation-details"><a href="#Implementation-details" class="headerlink" title="Implementation details"></a>Implementation details</h2><h3 id="ConvNets-Configuration"><a href="#ConvNets-Configuration" class="headerlink" title="ConvNets Configuration"></a>ConvNets Configuration</h3><ul>
<li>对于这个网络结构，和引用的[3]还有[31]比较类似，可以去查看这两个网络的细节</li>
<li>每一层都使用了Relu、3*3 stride=2的max-pooling、使用AlexNet提出的Local Response Normalisation(现在已经不用了)</li>
<li>空间流和时间流的区别就在于把时间流中的第二个归一化层去掉了(看上面的图)</li>
</ul>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ul>
<li>训练主要参考了AlexNet那篇文章的细节</li>
<li>使用mini-batch stochastic gradient descent, momentum=0.9</li>
<li>mini-batch_size=256个video，里面的帧是随机挑选的</li>
<li>从原始帧中随机提取224\224(区别于AlexNet中先从原始分辨率中提取center的256*256，再提取224*224，这里直接从原始分辨率中随机提取224*224，这也是作者认为在ILSVRC-2012准确率更高的原因)，并经历random horizontal flipping和RGB jittering</li>
<li>初始学习率是10^-2，随后的变化遵循一套固定的schedule：对于从头训练的ConvNet，在50K次迭代后学习率变成10^-3，在70K次迭代后变成10^-4，在80K次迭代后停止；对于fine-tuning的情况，学习率在14K次迭代后变为10^-3，在20K次迭代后停止训练</li>
</ul>
<h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><ul>
<li>对于一个视频，我们提取固定数量的帧(这里是25)，这些帧在时间上等间隔。对于每一帧，我们通过数据增强都能获得10个不同的input</li>
<li><strong>整个video的score是对所有选取的帧的score的平均</strong></li>
</ul>
<h3 id="Pre-training-on-ImageNet-ILSVRC-2012"><a href="#Pre-training-on-ImageNet-ILSVRC-2012" class="headerlink" title="Pre-training on ImageNet ILSVRC-2012"></a>Pre-training on ImageNet ILSVRC-2012</h3><ul>
<li>在ImageNet上对空间流网络进行预训练时，同样要使用上面说的数据增强技术，并发现结果比[31]中更好，作者认为的原因是：在这里，他们是对图片从原始分辨率直接提取224*224</li>
</ul>
<h3 id="Optical-Flow"><a href="#Optical-Flow" class="headerlink" title="Optical Flow"></a>Optical Flow</h3><ul>
<li>是在训练前调用OpenCV得到的</li>
<li>存储方面，为了减少对于float的存储，把光流数据rescaled到[0, 255]，并使用JPEG进行压缩</li>
</ul>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><ul>
<li>作者还尝试了slow fusion，发现slow fusion只有56.4%准确率，远不如双流好</li>
<li>在后面的实验中，空间流使用的是training the last layer on top of a pre-trained ConvNet<img src="/2018/04/11/Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos/2.png">
</li>
</ul>
<h3 id="Multi-task-learning-of-temporal-ConvNets"><a href="#Multi-task-learning-of-temporal-ConvNets" class="headerlink" title="Multi-task learning of temporal ConvNets"></a>Multi-task learning of temporal ConvNets</h3><ul>
<li>因为对于时间流的训练较难，尤其是在HMDB-51数据集上（数据量小），所以尝试不同的方案，发现multi-task learning最好，因为这种方案利用了最多的数据</li>
<li>若是对于HMDB-51的训练，那么在multi-task learning的过程中，<strong>可以把UCF-101的全部数据都用于训练</strong><img src="/2018/04/11/Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos/3.png">
</li>
</ul>
<h3 id="Two-Stream-ConvNets"><a href="#Two-Stream-ConvNets" class="headerlink" title="Two-Stream ConvNets"></a>Two-Stream ConvNets</h3><ul>
<li><strong>空间流和时间流网络互补，两个加在一起可以大幅提升准确率</strong></li>
<li><strong>使用SVM做fusion更好</strong></li>
<li><strong>使用bi-directional flow在这里没有提升</strong></li>
<li><strong>对时间流使用multi-task learning可以提升效果</strong><img src="/2018/04/11/Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos/4.png">
</li>
</ul>
<h3 id="Comparison-with-the-state-of-the-art"><a href="#Comparison-with-the-state-of-the-art" class="headerlink" title="Comparison with the state of the art"></a>Comparison with the state of the art</h3><ul>
<li>注：下表是对数据集的3个split求了平均，而上表则是split 1的结果<img src="/2018/04/11/Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos/5.png">
</li>
</ul>
<h2 id="Conclusions-and-directions-for-improvement"><a href="#Conclusions-and-directions-for-improvement" class="headerlink" title="Conclusions and directions for improvement"></a>Conclusions and directions for improvement</h2><ul>
<li>Training a temporal ConvNet on optical flow (as here) is significantly better than training on raw stacked frames</li>
<li>Extra training data is beneficial for our temporal ConvNet</li>
<li>There still remain some essential ingredients of the state-of-the-art shallow representation, which are missed in our current architecture.</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> Action Recognition </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[cs231n Let11 Detection and Segmentation]]></title>
      <url>/2018/04/06/cs231n-Let11-Detection-and-Segmentation/</url>
      <content type="html"><![CDATA[<h1 id="Lecture-11-Detection-and-Segmentation"><a href="#Lecture-11-Detection-and-Segmentation" class="headerlink" title="Lecture 11 Detection and Segmentation"></a>Lecture 11 Detection and Segmentation</h1><ul>
<li><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf" target="_blank" rel="noopener">slides</a></li>
<li><a href="https://www.youtube.com/watch?v=nDPWywWRIRo&amp;index=11&amp;t=0s&amp;list=PLFeNv0PW-fo5dSXiv2Xlsjvtb43S8m38b" target="_blank" rel="noopener">video</a></li>
</ul>
<a id="more"></a>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/1.png">
<h2 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h2><ul>
<li>图片中每个像素点都有一个label</li>
<li>不区分instances。如下图有多只牛，不同牛位置的pixel相应的label都是cow，并不会作区分。而Instance Segmentation则会对具体的object做区分<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/2.png">
</li>
</ul>
<h3 id="Sliding-Window"><a href="#Sliding-Window" class="headerlink" title="Sliding Window"></a>Sliding Window</h3><ul>
<li><p>在原始图像中逐像素提取patch，把这些patch一一扔进CNN架构中进行分类。这些patch都是以当前用来分类的像素点作为中心，即该patch的label是基于中心点像素的</p>
<blockquote>
<p>效率很低；而且从相邻的两个像素提取的patch几乎长的一样，最后训练得到的network权重也基本一样，这部分可以考虑shared，不需要重新去训练</p>
</blockquote>
<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/3.png">
</li>
</ul>
<h3 id="全卷积-Fully-Convolutional"><a href="#全卷积-Fully-Convolutional" class="headerlink" title="全卷积(Fully Convolutional)"></a>全卷积(Fully Convolutional)</h3><ul>
<li><p>由于逐像素效率低，那么就直接把一整张图片送入网络，同时对所有像素点进行分类，最后输出一张C*H*W的分类图，每个像素点都有C个类别的score，这样还做到了上面所说的相邻像素可以直接使用shared feature</p>
<blockquote>
<p>在原始分辨率下做卷积比较昂贵，内存占用等都会很大，尤其是当每一层的feature map数也很多的时候</p>
</blockquote>
<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/4.png">
</li>
</ul>
<h3 id="改进的Fully-Convolutional"><a href="#改进的Fully-Convolutional" class="headerlink" title="改进的Fully Convolutional"></a>改进的Fully Convolutional</h3><ul>
<li>既然在原始分辨率下做卷积代价高，那么就进行降维，随后再upsampling恢复原来的分辨率，得到具有原始分辨率的label图<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/5.png"></li>
<li>Unsampling<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/6.png"> <img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/7.png">
</li>
</ul>
<h2 id="Classification-Localization"><a href="#Classification-Localization" class="headerlink" title="Classification + Localization"></a>Classification + Localization</h2> <img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/8.png">
<ul>
<li>一些trick<blockquote>
<p>同时做分类与回归bounding box？————有些人可能会对不同的类分别做bounding box的回归(因为类别不同可能影响到物体的位置与大小识别，相当于回归的loss会因为类别的识别错误而大大增加)，然后取ground truth对应的两个loss相加<br>两个loss相加时的权重怎么看？————当作超参数进行训练</p>
</blockquote>
</li>
</ul>
<h3 id="Human-Pose-Estimation"><a href="#Human-Pose-Estimation" class="headerlink" title="Human Pose Estimation"></a>Human Pose Estimation</h3> <img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/9.png">
<h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><ul>
<li>优质介绍资源：<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741534&amp;idx=1&amp;sn=02dc164ffcedbf22124b97841ba67fe5&amp;chksm=871adf60b06d567690fa2328b161c012a464687768e50f812a51b5533a7d68b99af1cf8f02b8&amp;scene=0#rd" target="_blank" rel="noopener">链接</a></li>
<li>相比于Classification + Localization，Object Detection的每张输入图像都对应不同数量的output，即每张图片里有若干数量未知的待测物体</li>
</ul>
<h3 id="Object-Detection-as-Regression"><a href="#Object-Detection-as-Regression" class="headerlink" title="Object Detection as Regression"></a>Object Detection as Regression</h3><ul>
<li>若使用类似Classification + Localization的方法，那么由于每张图片中有不同的输出，若使用某个固定的网络，输出数量只能是一定的，因此无法简单的进行regression<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/10.png"> 
</li>
</ul>
<h3 id="Object-Detection-as-Classification-Sliding-Window"><a href="#Object-Detection-as-Classification-Sliding-Window" class="headerlink" title="Object Detection as Classification: Sliding Window"></a>Object Detection as Classification: Sliding Window</h3><ul>
<li>使用Semantic Segmentation中提到的idea，使用sliding window后，就是对每一个window过一次网络，因此就不用担心每张图片有不同的输出了。因为这样做的话，对于一张图片，其经过k次网络，也就有k个output了，k是window的个数<blockquote>
<p>window的大小、每次移动的位置都无法直接确定，而只能不断尝试，通过最后网络训练得到的结果进行判断。那么这种做法需要进行大量的训练，代价太大</p>
</blockquote>
</li>
</ul>
<h3 id="Region-Based-Methods"><a href="#Region-Based-Methods" class="headerlink" title="Region Based Methods"></a>Region Based Methods</h3><ul>
<li>由于用Sliding Window有太多的candidate window了，所以计算代价太大，那么我们可以考虑使用算法来直接找到一些出现object概率比较大的candidate区域，减小搜索范围（如可以先找edge，然后再找有没有形成闭合回路的edge，若有那么这些闭合的曲线很有可能就是object，可以作为candidate region</li>
</ul>
<h4 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h4><ul>
<li><p>先在input image上提取2000个ROI(ROI是固定算法)，随后把ROI warp成一样的size，再送入ConvNet，分别用SVM进行分类以及做线性回归(回归的是bounding box基于ROI的offset)。其中，在正式训练前，还需要对ConvNet进行微调，这时候是使用softmax进行微调</p>
<blockquote>
<p>由于仍然有2000个ROI，训练耗时还是很久，而且占用磁盘、内存资源；且测试速度也慢，无法做到实时性；ROI不能通过学习进行改进，可能算法本身的识别会有误差</p>
</blockquote>
<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/11.png"> 
</li>
</ul>
<h4 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h4><ul>
<li>既然对2000个ROI都训练ConvNet太耗时间，那么我们可以考虑把ROI提取放在feature map上，即先对input image用ConvNet进行特征提取，随后在提取的特征图上再做ROI提取，这样相当于只需要训练一个ConvNet就可以了，大大减少运行时间与其他资源</li>
<li>同时，Fast R-CNN使用softmax分类器代替了R-CNN中的SVM分类器<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/12.png"> </li>
<li>*但具体做的时候，其实ROI提取的步骤还是在input image上执行的，只是把提取的ROI根据卷积操作的空间对应性映射到feature map上<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/13.png"> 
</li>
</ul>
<h4 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h4><ul>
<li>Fast R-CNN的测试时间主要是花在ROI的提取上了。而且ROI提取是固定算法，无法通过训练加以改进，可能本身的识别存在一些问题。因此，Faster R-CNN把ROI改进成RPN(Region Proposal Network)，在这里Region Proposal的提取都是可以通过学习得到。模型具体的detail比较复杂，还得去看看paper<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/14.png"> 
</li>
</ul>
<h4 id="R-CNN-gt-Fast-R-CNN-gt-Faster-R-CNN"><a href="#R-CNN-gt-Fast-R-CNN-gt-Faster-R-CNN" class="headerlink" title="R-CNN -&gt; Fast R-CNN -&gt; Faster R-CNN"></a>R-CNN -&gt; Fast R-CNN -&gt; Faster R-CNN</h4> <img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/15.png"> 
<h3 id="Detection-without-Proposals-Methods-YOLO-SSD"><a href="#Detection-without-Proposals-Methods-YOLO-SSD" class="headerlink" title="Detection without Proposals Methods: YOLO/SSD"></a>Detection without Proposals Methods: YOLO/SSD</h3><ul>
<li>相比于Region based method对于每个region都要做一次独立的处理，YOLO和SSD直接使用一个很大的CNN对所有潜在的region做预测</li>
<li>Faster R-CNN速度慢，但更准确；SSD更快但没那么准确<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/16.png"> 
</li>
</ul>
<h2 id="Instance-Segmentation"><a href="#Instance-Segmentation" class="headerlink" title="Instance Segmentation"></a>Instance Segmentation</h2><h3 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h3><ul>
<li>在Faster R-CNN中加了一个类似语义分割里的全卷积网络，用来做像素级的分类</li>
<li>使用ROI Align取代了ROI Pooling，因为RPN在像素级分类中不够精准<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/17.png"> 
<img src="/2018/04/06/cs231n-Let11-Detection-and-Segmentation/18.png">  </li>
</ul>
]]></content>
      
        <categories>
            
            <category> 深度学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 公开课 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Fast Image Processing with Fully-Convolutional Networks]]></title>
      <url>/2018/03/16/Fast-Image-Processing-with-Fully-Convolutional-Networks/</url>
      <content type="html"><![CDATA[<p>CVPR 2017的一篇文章：<a href="http://cqf.io/papers/Fast_Image_Processing_ICCV2017.pdf" target="_blank" rel="noopener">Fast Image Processing with Fully-Convolutional Networks</a>，作者陈启峰</p>
<ul>
<li>提出一种使用FCN来替代原始图像处理的方法，可以对任意分辨率的图像进行操作</li>
<li>处理速度快、比原来的其他替代方法准确率更高、所有操作都基于同一个模型(只有具体的参数值不同，超参数也完全一致)</li>
</ul>
<a id="more"></a>
<ul>
<li>网上看到一篇不错的博文：<a href="http://blog.csdn.net/u011961856/article/details/77869567" target="_blank" rel="noopener">链接</a></li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>提出一种基于<strong>全卷积网络(FCN)</strong>来<strong>加速</strong>图像处理操作的方法，训练完可以直接用这个网络替代原先的图像处理操作符(即不再需要原来的操作来实现对应的图像处理效果了)</li>
<li>该新方法可以在<strong>各种分辨率</strong>下对图像进行操作，且只需要<strong>恒定</strong>的时间</li>
<li>相比之前别的替代方法，该新方法<strong>准确率更高、速度更快</strong></li>
</ul>
<img src="/2018/03/16/Fast-Image-Processing-with-Fully-Convolutional-Networks/1.png">
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>目前的很多图像处理方法需要<strong>较大的计算资源</strong>、<strong>运行时间也比较长</strong>(如双边滤波)。基于此，有很多人针对于特定的某一种图像处理方法提出一些改进策略来加速，但这些方法<strong>不能泛化</strong>到各种不同图像处理方法</p>
</li>
<li><p>一种普适的加速方法是：先对图像进行下采样，在低分辨率下执行图像处理操作，随后再上采样</p>
<blockquote>
<p>这么做有两个问题：1. 即使在低分辨率下，速度还是不够快；2. 在低分辨率下执行操作可能会影响图像处理的效果，即不够精准</p>
</blockquote>
</li>
<li><p>本文的方法与之前的方法有所不同，能够直接在<strong>原始分辨率</strong>上执行图像处理操作，且通过<strong>端到端的训练可以最大化精确度</strong>，训练完也就可以直接<strong>取代</strong>原来的图像处理操作</p>
</li>
<li><p>对模型的判定依据有三条：效果的精确度Accuracy、运行时间Speed、模型的大小Compactness</p>
</li>
<li><p>对于文中的十种不同的图像处理方法，可以使用<strong>同一个模型</strong>去取代，即只有具体的参数值不一样，超参数都完全一致</p>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>见原文</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><ul>
<li><p>Any network that has been used for a pixelwise classification problem such as semantic segmentation can instead be trained with a regression loss to produce continuous color rather than a discrete label per pixel. However, not all network architectures will yield high accuracy in this regime and most are not compact. (可以用回归，这样得到的像素点的RGB值是连续的，但精确度可能不够高，而且模型可能很大)</p>
</li>
<li><p>High-level vision的架构(尤其是针对图像分割的)被应用到low-level的图像处理问题上，表现都非常好，主要原因可能在于High-level vision的架构的<strong>感受野更大</strong>，因为图像处理问题本身大多都是基于全局的优化</p>
</li>
</ul>
<h3 id="Context-aggregation-networks-CAN"><a href="#Context-aggregation-networks-CAN" class="headerlink" title="Context aggregation networks (CAN)"></a>Context aggregation networks (CAN)</h3><ul>
<li>随着网络深度的增加，CAN的感受野呈指数增加（见下条的rs）。这保证了对高分辨率图像提取全局信息的同时，还能够保证参数不至于过多。CAD还具有运行时占内存空间小的优点：因为没有跳跃连接，所以只需要把两层保存在内存当中就可以了；而且由于每一层的大小都是一样的，只需要分配两块固定大小的buffer<img src="/2018/03/16/Fast-Image-Processing-with-Fully-Convolutional-Networks/2.png"></li>
<li>模型细节：L0和Ld都是m*n*3，m和n即为输入图像的尺寸。中间层Ls是m*n*w。不同层之间的计算如下。其中，下标i表示第i个feature map，rs是表示卷积核的dilation，即空洞卷积操作，随网络深度的增加而指数增长。对于L(d-1)，不使用dilation；对于Ld，使用了一个线性的变换(1*1的卷积)，将最后一层映射到了RGB空间。Φ则是leaky rectified linear unit，即Φ(x) = max(αx, x)。Ψs 是adaptive normalization function<img src="/2018/03/16/Fast-Image-Processing-with-Fully-Convolutional-Networks/3.png">
<img src="/2018/03/16/Fast-Image-Processing-with-Fully-Convolutional-Networks/4.png">
</li>
</ul>
<h3 id="Adaptive-normalization"><a href="#Adaptive-normalization" class="headerlink" title="Adaptive normalization"></a>Adaptive normalization</h3><ul>
<li><p>BN对于一部分图像处理方法能提升效果，一部分效果反而更差了。为此，提出了一种Adaptive normalization，结合了BN和identity mapping</p>
<img src="/2018/03/16/Fast-Image-Processing-with-Fully-Convolutional-Networks/5.png"> 
<p>后续待更新</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
            <tag> 图像处理 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ZOJ1007 Numerical Summation of a Series]]></title>
      <url>/2018/03/10/ZOJ1007-Numerical-Summation-of-a-Series/</url>
      <content type="html"><![CDATA[<p>数值分析Lab1，也是ZOJ1007 <a href="http://icpc.njust.edu.cn/Problem/Zju/1007/" target="_blank" rel="noopener">链接</a></p>
<ul>
<li>一道数学题，给的Hint非常强</li>
</ul>
<a id="more"></a>
<p>题目难点有两个：</p>
<ul>
<li>不知道要计算多少项才能满足精度</li>
<li>一旦多算就可能导致超时</li>
</ul>
<p>好在题目给了一个Hint：构造一个序列：ϕ(x)−ϕ(1)，这样收敛快且roundoff loss小<br>还给了一个求上界的不等式：<img src="/2018/03/10/ZOJ1007-Numerical-Summation-of-a-Series/1.png"></p>
<p>因此，对于这两个难点的解决办法如下：</p>
<ul>
<li>对于收敛项数，可以假设我们需要n项才能满足精度，那么可以根据不等式求出第n项后面所有余项和的上界，保证该上界小于误差范围即可，从而可以求解出n的最小值</li>
<li>同时，ϕ(x)和ϕ(x-1)之间可以发现存在一个关系（ϕ(x) = ϕ(x-1) * (x - 1) / x + 1 / (x * x);，直接通过该关系可以避免很多重复的计算</li>
</ul>
<p>那么为何要构造一个新序列呢？</p>
<ul>
<li>从收敛速度来看，ϕ(x)本身分母是2次方，按照上述方法求解出来的n比较大；而构造的这个新序列的分母有三次方，只需要更少的项就可以收敛，而且ϕ(1)为1，在求得新序列后较容易算得要求的ϕ(x)。网上还看到了一个更强的推导，分母有4次方，推导如下: <img src="/2018/03/10/ZOJ1007-Numerical-Summation-of-a-Series/2.png"></li>
<li>具体的roundoff loss会不会更小不好说，需要分析一下哪个计算次数更多了</li>
</ul>
<p>代码：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void Series_Sum(double sum[]);</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	int i;</span><br><span class="line">	double x, sum[<span class="number">3001</span>];</span><br><span class="line"></span><br><span class="line">	Series_Sum(sum);</span><br><span class="line"></span><br><span class="line">	x = <span class="number">0.0</span>;</span><br><span class="line">	for (i = <span class="number">0</span>; i&lt;<span class="number">3001</span>; i++)</span><br><span class="line">		printf(<span class="string">"%6.2f %16.12f<span class="subst">\n</span>"</span>, x + (double)i * <span class="number">0.10</span>, sum[i]);</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	return <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Series_Sum(double sum[])</span><br><span class="line">&#123;</span><br><span class="line">	int i, k;</span><br><span class="line">	double x;</span><br><span class="line">	double ans = <span class="number">0</span>;</span><br><span class="line">	for (i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		x = i * <span class="number">0.1</span>;</span><br><span class="line">		for (k = <span class="number">1</span>; k &lt; <span class="number">100000</span>; k++)</span><br><span class="line">		&#123;</span><br><span class="line">			ans += <span class="number">1.0</span> / ((k + x) * (k + <span class="number">2</span>) * (k + <span class="number">1</span>) * k);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//printf("%.6f\n", ans + 1);</span></span><br><span class="line">		sum[i] = (<span class="number">1.0</span> - x) * ((<span class="number">2.0</span> - x) * ans + <span class="number">0.25</span>) + <span class="number">1</span>;</span><br><span class="line">		ans = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	sum[<span class="number">10</span>] = <span class="number">1</span>;</span><br><span class="line">	for (i = <span class="number">11</span>; i &lt;= <span class="number">3000</span>; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		x = i * <span class="number">0.1</span>;</span><br><span class="line">		sum[i] = sum[i - <span class="number">10</span>] * (x - <span class="number">1</span>) / x + <span class="number">1</span> / (x * x);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 数值分析 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数值分析 </tag>
            
            <tag> 刷题 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python常用函数]]></title>
      <url>/2018/03/09/Python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</url>
      <content type="html"><![CDATA[<p>记录了一些python的常用函数</p>
<a id="more"></a>
<ul>
<li>列表的大小：len(L)</li>
<li>判断是否包含子串：’Acc’ in str[i]</li>
<li>字符串截取：str[s:t]</li>
<li>二维数组访问：a[1,1]；字符串列表访问：str[i][s:t]</li>
<li>找索引值：.index(‘loss’)</li>
<li>去除字符串内多余的空格：a.strip()</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Action Recognition Survey]]></title>
      <url>/2018/03/09/Action-Recognition-Survey/</url>
      <content type="html"><![CDATA[<p>关于Action Recognition领域的综述，Going Deeper into Action Recognition: A Survey <a href="https://www.sciencedirect.com/science/article/pii/S0262885617300343" target="_blank" rel="noopener">链接</a></p>
<a id="more"></a>
<h2 id="What-is-an-action"><a href="#What-is-an-action" class="headerlink" title="What is an action?"></a>What is an action?</h2><ul>
<li>Action is the most elementary human 1-surrounding interaction with a meaning.</li>
</ul>
<h2 id="Taxonomy"><a href="#Taxonomy" class="headerlink" title="Taxonomy"></a>Taxonomy</h2><img src="/2018/03/09/Action-Recognition-Survey/1.png">
<h3 id="Representation-based-Solutions"><a href="#Representation-based-Solutions" class="headerlink" title="Representation based Solutions"></a>Representation based Solutions</h3><ul>
<li>Earliest works in action recognition use <strong>3D models</strong> to describe actions</li>
<li>Constructing 3D models is difficult and expensive</li>
</ul>
<h4 id="Holistic-Representation"><a href="#Holistic-Representation" class="headerlink" title="Holistic Representation"></a>Holistic Representation</h4><ul>
<li><p>Motion Energy Image (<strong>MEI</strong>) and Motion History Image (<strong>MHI</strong>). “Bobick and Davis, 2001”</p>
<blockquote>
<p>The MHI template shows how the motion image is moving. Each pixel in MHI is a function of the temporal history of the motion at that point (i.e., higher intensities correspond to more recent movements)</p>
</blockquote>
<img src="/2018/03/09/Action-Recognition-Survey/7.png">
</li>
<li><p>The volumetric <strong>extension of MEI templates</strong>. （见下左图） “Blank, 2005” </p>
<blockquote>
<p>represent an action by a 3D shape induced from its silhouettes in the space-time</p>
</blockquote>
</li>
<li><p>Space-Time Volume (<strong>STV</strong>) “Yilmaz and Shah, 2005”</p>
<blockquote>
<p>An STV is build by stacking the object contours along the time axis</p>
</blockquote>
<img src="/2018/03/09/Action-Recognition-Survey/8.png">
</li>
<li><p><strong>Holistic representations flooded the research in action recognition roughly between 1997 to 2007. However, nowadays local and deep representations are favored</strong> </p>
</li>
</ul>
<h4 id="Local-Representation"><a href="#Local-Representation" class="headerlink" title="Local Representation"></a>Local Representation</h4><ul>
<li>interest point detection -&gt; local descriptor extraction -&gt; aggregation of local descriptors (从找到一个感兴趣点，到从兴趣点周围的一片区域提取一个描述子，再到把一堆局部描述子聚合在一起)</li>
</ul>
<h5 id="Interest-point-detection"><a href="#Interest-point-detection" class="headerlink" title="Interest point detection"></a>Interest point detection</h5><ul>
<li><p>3D-Harris Detector “Laptev, 2005”</p>
<blockquote>
<p>The 3D-Harris detector identifies points with large spatial variations and non-constant motions</p>
</blockquote>
</li>
<li><p>3D-Hessian Detector “Willems, 2008”</p>
</li>
<li><p>In certain domains, e.g., facial expressions, true spatiotemporal corners are quite <strong>rare</strong>, even if an interesting motion is occurring</p>
<blockquote>
<p>disintegrate spatial filtering from the temporal one</p>
</blockquote>
</li>
<li><p><strong>action clips</strong> are more likely to be obtained in uncontrolled environments</p>
<blockquote>
<p>a shaky camera can fire a series of irrelevant interest points<br>prune irrelevant features using statistical properties of the detected interest points</p>
</blockquote>
</li>
<li><p>spatiotemporal features obtained from <strong>background</strong>, known as static features, especially the ones that are near motion regions are <strong>useful</strong> for action recognition</p>
</li>
</ul>
<h5 id="Local-Desscriptors"><a href="#Local-Desscriptors" class="headerlink" title="Local Desscriptors"></a>Local Desscriptors</h5><ul>
<li><p>To obtain the local descriptor at an interest point, earlier works almost unanimously opt for cuboids. Later people introduced the notion of <strong>trajectories</strong></p>
</li>
<li><p>Edge and Motion Descriptors</p>
<blockquote>
<p>Histogram of Gradient Orientations (<strong>HOG3D</strong>) “Klaser, 2008”<br>Optical Flow Fields: Histogram of Optical Flow (<strong>HoF</strong>) “Laptev, 2008” &amp; Motion Boundary Histogram (<strong>MBH</strong>) “Dalal, 2006”</p>
</blockquote>
</li>
<li><p>Pixel Pattern Descriptors</p>
<blockquote>
<p>Volume Local Binary Patterns (<strong>VLBP</strong>) “Zhao, 2007” &amp; Local Binary Pattern histograms from Three Orthogonal Planes (<strong>LBP-TOP</strong>) “Kellokkumpu, 2008”<br>To describe a region R in an image, first use low-level features or mid-level features to extract a set of features zi, then use d*d covariance matrix of zi (RCD) as the descriptor for region R “Tuzel, 2006”</p>
</blockquote>
</li>
<li><p>From Cuboids to Trajectories</p>
<blockquote>
<p>An spatiotemporal interest point might not reside at the exact same spatial location within the temporal extends of a cuboid.<br>A trajectory is a properly tracked feature over time</p>
</blockquote>
</li>
<li><p>Use <strong>dense</strong> interest points instead of sparse</p>
</li>
</ul>
<h5 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h5><h3 id="Deep-Architectures-for-Action-Recognition"><a href="#Deep-Architectures-for-Action-Recognition" class="headerlink" title="Deep Architectures for Action Recognition"></a>Deep Architectures for Action Recognition</h3><ul>
<li>Spatiotemporal networks (空间+时间；3D-CNN)</li>
<li>Multiple stream networks (拆分为空间流和时间流)</li>
<li>Deep generative networks (无监督)</li>
<li>Temporal coherency networks (作为预训练网络)</li>
</ul>
<h4 id="Spatiotemporal-Networks-From-3D-CNN-to-3D-CNN-LSTM"><a href="#Spatiotemporal-Networks-From-3D-CNN-to-3D-CNN-LSTM" class="headerlink" title="Spatiotemporal Networks (From 3D-CNN to 3D-CNN+LSTM)"></a>Spatiotemporal Networks (From 3D-CNN to 3D-CNN+LSTM)</h4><ul>
<li><p>Arm the CNN with temporal information —— <strong>3D CNN</strong>. Use 3D kernels(filter extended along the time axis) to extract features from both spatial and temporal dimension. “<a href="http://ieeexplore.ieee.org/abstract/document/6165309/" target="_blank" rel="noopener">3D Convolutional Neural Networks for Human Action Recognition</a>“</p>
<img src="/2018/03/09/Action-Recognition-Survey/2.png">
<blockquote>
<p>3D CNN have a very rigid temporal structure. The network accepts a predefined number of frames as the input.<br>在空间上可以通过pooling来解决fixed spatial dimension，但是时间上为什么可以还没有解释；同时对于不同动作，输入的帧数也不明确</p>
</blockquote>
</li>
<li><p>How temporal information should be fed into CNN ? (Different <strong>Fusion Schemes</strong>)</p>
<ul>
<li>Max-pooling更好. “Ng, 2015”</li>
<li><strong>Slow Fusion</strong>: CNN accepts several consecutive parts of the video, and processes them through the very same set of layers to produce responses across temporal domain. These responses are then processed by fully connected layers to produce the video descriptor. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf" target="_blank" rel="noopener">“Karpathy, 2014”</a><img src="/2018/03/09/Action-Recognition-Survey/3.png"></li>
<li><strong>Early Fusion</strong>: the network is fed with a set of adjacent frames. “<a href="http://ieeexplore.ieee.org/abstract/document/6165309/" target="_blank" rel="noopener">3D Convolutional Neural Networks for Human Action Recognition</a>“</li>
<li><strong>Late Fusion</strong>: frame-wise features are fused at the last layer. “Karpathy, 2014”<blockquote>
<p>Multi-resolutional approach using two separate networks not only boosts the accuracy, but also reduces the number of parameterss to be learned. (见上右图) “Karpathy, 2014”</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Find <strong>generic video descriptors based on a 3D convolutional network</strong> (C3D). “Tran 2015”</p>
<ul>
<li>A network with 3 × 3 × 3 homogeneous filters (<strong>constant depth</strong> at every layer) performs better than varying the temporal depth on filters. Flexibility on the temporal extent is obtained with the inclusion of 3D pooling layers. </li>
<li>Obtained by averaging the outputs of the first fully connected layer.</li>
</ul>
</li>
</ul>
<ul>
<li><p>Improvements are observed by <strong>extending the temporal depth of the input</strong> as well as <strong>combining the decision of networks with different temporal awareness at the input</strong>. “Varol, 2016”</p>
</li>
<li><p><strong>Factorizing a 3D filter into a combination of a 2D and 1D filters</strong>, solving the problem of increasing the number of parameters of the 3D-CNN network. </p>
</li>
<li><p>Feed an <strong>LSTM</strong> network with features extracted from a 3D convolutional network. The two networks are trained separately. “Baccouche, 2011”</p>
<img src="/2018/03/09/Action-Recognition-Survey/4.png">
</li>
<li><p>Another <strong>end-to-end</strong> architecture based on <strong>LSTM</strong> named LRCN. (下图a) “Donahue, 2015”</p>
<ul>
<li>Group is a set of convolutional filters operating only on a particular set of feature maps from the previous layer.</li>
</ul>
</li>
</ul>
<h4 id="Multiple-Stream-Networks"><a href="#Multiple-Stream-Networks" class="headerlink" title="Multiple Stream Networks"></a>Multiple Stream Networks</h4><ul>
<li>A class of deep neural networks is devised to separate <strong>appearance</strong> based information from <strong>motion</strong> related ones for action recognition. “Simonyan, 2014” <ul>
<li>Multiple-stream deep CNN, with <strong>two parallel networks</strong></li>
<li><strong>Spatial</strong> stream network accepts raw video frames while the <strong>temporal</strong> stream network gets optical flow fields as input</li>
<li>Fine-tuning a pretrained network on the ILSVRC-2012 image dataset (Russakovsky et al., 2015) leads to higher accuracy</li>
<li>Stacking optical flow fields at the input of the temporal stream network (i.e., early fusion) is beneficial</li>
<li>The temporal stream network is modified to have more than one classification layer. Each classification layer operates on a specific dataset, aiming to <strong>learn a representation</strong>, which is not only applicable to the task in question, but also to other tasks.</li>
<li>The two streams are fused together using the softmax scores</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Fusion at an intermediate layer</strong> not only improves the performance but also reduces the number of parameters significantly “Feichtenhofer, 2016”</p>
<ul>
<li>having the fusion right after the convolutional layers will remove the requirement of costly fully connected layers in both streams<img src="/2018/03/09/Action-Recognition-Survey/5.png">
</li>
</ul>
</li>
<li><p><strong>Extension</strong> of the two stream network</p>
<ul>
<li>Dense trajectories traced over convolutional feature maps of the two-stream network are aggregated using the Fisher vector “Wang, 2015”</li>
<li>A third stream using audio signal is added to the network “Wu, 2015”</li>
</ul>
</li>
</ul>
<ul>
<li>The <strong>optical flow frames</strong> are <strong>the only motion related information</strong> used in two stream networks “Feichtenhofer, 2016”<ul>
<li>Optical flow cannot capture subtle but long-term motion dynamics</li>
<li>Certain details in actions are still out-of-reach in deep solutions</li>
</ul>
</li>
</ul>
<h4 id="Deep-Generative-Models"><a href="#Deep-Generative-Models" class="headerlink" title="Deep Generative Models"></a>Deep Generative Models</h4><ul>
<li><strong>Dynencoder</strong>: a class of deep auto-encoders to capture video dynamics<ul>
<li>Has three layers: xt -&gt; ht -&gt; ht+1 -&gt; xt+1</li>
<li>To reduce the training complexity, the parameters of the network are learned in two stages. In the pretraining stage, each layer is trained separately. Once pretraining is completed, an end-to-end fine tuning is performed</li>
<li>The <strong>reconstruction error</strong> of a video given a Dynencoder can be used as a mean for classification</li>
</ul>
</li>
</ul>
<ul>
<li><strong>LSTM Autoencoder Model</strong><ul>
<li>Consist of the <strong>encoder LSTM</strong> and <strong>the decoder LSTM</strong></li>
<li>The states of the encoder LSTM contain the appearance and dynamics of the sequence</li>
<li>Has <strong>reconstructive decoder</strong> and <strong>predictive decoder</strong><img src="/2018/03/09/Action-Recognition-Survey/6.png">
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Adversarial Models</strong><ul>
<li>The discriminative model learns to determine whether a sample is coming from the generative model or the data itself.</li>
</ul>
</li>
</ul>
<h4 id="Temporal-Coherency-Networks"><a href="#Temporal-Coherency-Networks" class="headerlink" title="Temporal Coherency Networks"></a>Temporal Coherency Networks</h4><ul>
<li>Temporal Coherency is a form of <strong>weak supervision</strong></li>
<li>Temporal coherency states that consecutive video frames are correlated both semantically and dynamically (i.e., abrupt motions are less likely)</li>
<li>Temporal coherency is not always a strong assumption to rely on</li>
<li><p><strong>Siamese Network</strong> (Chopra, 2005; Varior, 2016; Lu, 2016) is trained with tuples to determine whether a given sequence is coherent or not. </p>
<blockquote>
<p>Give more attention to human poses<br>Avoid ambiguities between positive and negative tuples<br>Compared to networks trained from scratch, pretrained networks based on the temporal coherency have potential to improve the accuracy</p>
</blockquote>
<img src="/2018/03/09/Action-Recognition-Survey/10.png">
</li>
<li><p>Action is split into two phases for classification, the precondition set Xp and the effect set Xe.</p>
<blockquote>
<p>An action is identified by the transformation required to map a high-level descriptor extracted from Xp to a high-level descriptor extracted from Xe.</p>
</blockquote>
<img src="/2018/03/09/Action-Recognition-Survey/11.png">
</li>
<li><p>Rank pooling (Fernando, 2015) is an effective solution for capturing temporal evolution<br>of a sequence. </p>
</li>
</ul>
<h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2> <img src="/2018/03/09/Action-Recognition-Survey/9.png">
<ul>
<li>No universal solution for all datasets</li>
<li><p>the <strong>KTH</strong> and the <strong>Weizmann</strong> datasets contain human actions in controlled conditions, and their scope is limited to basic actions such as walking, running and jumping. </p>
<blockquote>
<p>comparing solutions on the KTH and Weizmann datasets is <strong>less insightful</strong> unless a specific need is considered.</p>
</blockquote>
</li>
<li><p><strong>HMDB-51</strong> and <strong>UCF-101</strong> datasets contain camera motion (and shakes), viewpoint variations and resolution inconsistencies.</p>
<blockquote>
<p>these datasets are not well-suited for measuring the performance of <strong>action localization</strong></p>
</blockquote>
</li>
<li><p><strong>Hollywood2</strong> and <strong>Sports-1M</strong> datasets contain view-point/editing complexities (sudden viewpoint variations in the video streams)</p>
<blockquote>
<p>methods that rely on <strong>temporal coherency</strong> may fail on Sports-1M</p>
</blockquote>
</li>
<li><p>Algorithms benefiting from <strong>object details</strong> are expected to perform better</p>
</li>
<li><p>For <strong>Deep Learning</strong>, <strong>Sports-1M</strong> dataset is great while <strong>KTH and Wiezmann</strong> often leads to unsatisfactory performance</p>
</li>
</ul>
<h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2> <img src="/2018/03/09/Action-Recognition-Survey/12.png">
<ul>
<li>the state-of-the-art solutions based on both representation and deep learning perform <strong>equally well</strong><blockquote>
<p>One reason is the <strong>insufficiency of data</strong><br>A dominant theme to get around this limitation is to benefit from <strong>models pre-trained on images</strong></p>
</blockquote>
</li>
</ul>
<h2 id="Current-State-of-the-art-solutions"><a href="#Current-State-of-the-art-solutions" class="headerlink" title="Current State-of-the-art solutions"></a>Current State-of-the-art solutions</h2><h3 id="Handcrafted-Solutions"><a href="#Handcrafted-Solutions" class="headerlink" title="Handcrafted Solutions"></a>Handcrafted Solutions</h3><ul>
<li><strong>Dense trajectory descriptors</strong>, incorporated in various pooling strategies such as <strong>FV</strong>’s and <strong>Rank-Pooling</strong></li>
</ul>
<h3 id="Deep-Net-Solutions"><a href="#Deep-Net-Solutions" class="headerlink" title="Deep-Net Solutions"></a>Deep-Net Solutions</h3><ul>
<li>the <strong>spatiotemporal networks</strong> and <strong>two-stream networks</strong> outperform other network structures<blockquote>
<p>Equipped with 3D convolution filters<br>Training deeper networks demands more rigorous data augmentation techniques</p>
</blockquote>
</li>
</ul>
<h3 id="Fusion-with-Dense-Trajectories-always-help"><a href="#Fusion-with-Dense-Trajectories-always-help" class="headerlink" title="Fusion with Dense Trajectories always help"></a>Fusion with Dense Trajectories always help</h3><ul>
<li>The structures learned by deep networks are complementary to the handcrafted trajectory descriptors</li>
</ul>
<h2 id="What-algorithmic-changes-to-expect-in-the-future"><a href="#What-algorithmic-changes-to-expect-in-the-future" class="headerlink" title="What algorithmic changes to expect in the future?"></a>What algorithmic changes to expect in the future?</h2><ul>
<li><p>Moving towards <strong>deep architectures</strong> for action recognition is dominating the action recognition research lately</p>
<blockquote>
<p>Training deep networks difficult on video data -&gt; <strong>Knowledge Transfer</strong> (Use models trained on images or other sources)</p>
</blockquote>
</li>
<li><p>Blend <strong>3D convolutions</strong>, <strong>temporal pooling</strong>, <strong>optical flow frames</strong>, and <strong>LSTMs</strong> to boost the performance</p>
</li>
<li><p>Use <strong>data augmentation techniques</strong>, <strong>foveated architecture</strong> and <strong>distinct frame sampling strategies</strong></p>
</li>
</ul>
<h2 id="Most-State-of-the-art-Progress"><a href="#Most-State-of-the-art-Progress" class="headerlink" title="Most State-of-the-art Progress"></a>Most State-of-the-art Progress</h2><h3 id="Quo-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset-CVPR-2017"><a href="#Quo-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset-CVPR-2017" class="headerlink" title="Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset (CVPR 2017)"></a>Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset (CVPR 2017)</h3><ul>
<li>Propose a <strong>new dataset</strong> named “<strong>Kinetics</strong> Human Action Video dataset”, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos</li>
<li>Introduce a new <strong>Two-Stream Inflated 3D ConvNet (I3D)</strong>, reaching <strong>80.2% on HMDB-51</strong> and <strong>97.9% on UCF-101</strong> after <strong>pre-training on Kinetics</strong></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> Action Recognition </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Qua Vadis, Action Recognition? A New Model and the Kinetics Dataset]]></title>
      <url>/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/</url>
      <content type="html"><![CDATA[<p>CVPR 2017的一篇文章: <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Carreira_Quo_Vadis_Action_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Qua Vadis, Action Recognition? A New Model and the Kinetics Dataset</a></p>
<ul>
<li>在一个规模更大的新video数据集Kinetics上，重新评估了当下state-of-the-art的模型结构，并和在小数据集上训练的结构进行比较</li>
<li>提出一个新模型I3D，在Kinetics上预训练后，在HMDB-51数据集上取得了80.2%的准确率，在UCF-101上取得了97.9%的准确率</li>
</ul>
<p><strong>本文的idea*</strong>：</p>
<ul>
<li>根据之前3D-ConvNets的缺点(1. 参数多；2. 无法利用在ImageNet上预训练过的2D网络)，提出一种benefit from ImageNet 2D ConvNet design and their learned parameters的方法，并探究了在时间维度上的感受野要如何设置</li>
<li>吸收了之前state-of-the-art的模型，把双流的思想加到3D-ConvNet当中来，取得优异的效果（作者认为既然现在有了大数据集，那么3D ConvNet原先因为参数多而难训练的缺陷可以被大幅度改进。因此作者使用了3D ConvNet，同时双流这个思想还是很有用，因此这个新模型使用双流+3D ConvNet）</li>
<li>验证了视频模型的迁移学习同样有效，即在Kinetics上进行预训练能够提升模型效果</li>
</ul>
<a id="more"></a>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>在一个规模更大的新video数据集<strong>Kinetics</strong> Human Action Video dataset(包含大量数据，有400个动作分类，每个分类有超过400个实例，来源于YouTube，更有挑战性)上，重新评估了当下state-of-the-art的模型结构，并在该数据集上预训练后查看在小数据集上训练的结果提升</li>
<li>提出一个新的模型Two-Stream Inflated 3D ConvNet (<strong>I3D</strong>)。该模型在Kinetics上预训练后，在<strong>HMDB-51</strong>数据集上取得了<strong>80.2%</strong>的准确率，在<strong>UCF-101</strong>上取得了<strong>97.9%</strong>的准确率</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>有大量成功的事实证明：在ImageNet上训练过的架构可以有效地用在其他地方（即迁移学习）。但在视频领域，不知道是否在一个量较大的数据集上进行训练也可以有助于提升性能</li>
<li>本篇论文就是基于这个目的，重新实现了各种代表性的模型，并发现在大数据集上<strong>进行预训练确实能够提升性能</strong>，但提升幅度取决于具体<strong>模型类型</strong></li>
<li>基于上述发现，提出一个新模型I3D，能够充分发挥预训练的效果。它是基于当下最先进的图像分类模型，但把其中的卷积核以及pooling核都扩张成<strong>3D</strong>的形式</li>
<li>一个基于<strong>Inception v1</strong>的I3D模型效果远超之前最好的方法</li>
<li>本文没有把传统方法一起纳入比较，如bag-of-visual-words</li>
</ul>
<h2 id="Action-Classification-Architectures"><a href="#Action-Classification-Architectures" class="headerlink" title="Action Classification Architectures"></a>Action Classification Architectures</h2><ul>
<li><p>目前针对于video的模型架构还不明确，主要集中于以下几个问题</p>
<blockquote>
<p>卷积核是<strong>2D</strong>还是<strong>3D</strong><br>输入网络的是<strong>原始RGB视频</strong>还是预计算得到的<strong>光流</strong><br>对于2D的ConvNets来说，不同帧之间的信息是使用<strong>LSTM</strong>还是<strong>feature aggregation</strong></p>
</blockquote>
</li>
<li><p>比较的范围有三类对象</p>
<blockquote>
<p><strong>2D ConvNets with LSTM on top</strong><br><strong>Two-stream networks</strong><br><strong>3D ConvNets</strong></p>
</blockquote>
</li>
<li><p>下列是本文重新实现的5种代表性模型结构</p>
<img src="/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/1.png">
<img src="/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/2.png">
</li>
<li><p>之前由于缺乏数据，所使用的3D ConvNets模型都比较浅，最多只有8层。本文使用了如VGG、Inception等非常<strong>深</strong>的网络，并导入这些预训练网络的参数（除了C3D，因为没法导入，卷积核之类的都少一维），将这些网络<strong>扩展</strong>成时空特征描述子。同时，作者发现，这样的情况下，<strong>双流(two-stream)</strong>依然有用</p>
</li>
<li><p>本文使用的CNN结构是<strong>Inception v1加上BN</strong></p>
</li>
</ul>
<h3 id="ConvNet-LSTM"><a href="#ConvNet-LSTM" class="headerlink" title="ConvNet + LSTM"></a>ConvNet + LSTM</h3><ul>
<li>由于图像分类网络效果特别好，因此人们总想尽可能原封不动地把模型应用到视频上，如Karpathy做的那篇early/late/slow fusion的文章，但这样就会导致模型忽视了时序结构（如不能分辨开门与关门）</li>
<li>因此，可以在模型后面加上LSTM来处理时序问题</li>
<li>模型细节：把LSTM和BN加在Inception v1的最后一个average pooling层后面（即分类器之前），有512个节点。在模型最顶部加一个全连接层用于分类；The model is trained using cross-entropy losses on the outputs at all time steps. During testing we consider only the output on the last frame；输入帧是在25帧/s的视频流中每5帧取1帧，根据表1给出的信息，作者应该是从数据集的video中选取了5s的视频片段，所以总共是5s * 25帧/s * 1/5 = 25张rgb图像</li>
</ul>
<h3 id="3D-ConvNet"><a href="#3D-ConvNet" class="headerlink" title="3D ConvNet"></a>3D ConvNet</h3><ul>
<li>3D ConvNet看上去是一种很自然的方法，能够直接对于时空数据创建高层表征</li>
<li><p>但这个模型有两个问题：</p>
<blockquote>
<p>相比于2D，<strong>参数更多</strong>，也就更难训练（因为数据量不足），所以之前3D ConvNet用的都是<strong>浅层</strong>的架构<br>由于都是三维的核，<strong>无法直接用在ImageNet上预训练过的网络</strong>，因此只能在video数据集上train from scratch。由于之前的数据集量都太小，因此效果不是太有竞争力。但<strong>这种方法可能会比较适用于大数据集</strong></p>
</blockquote>
</li>
<li><p>模型细节：是原论文中C3D的变种。8层卷积、5层pooling、2层全连接。与C3D的区别在于这里的卷积和全连接层后面加BN；且在第一个pooling层使用stride=2，这样使得batch_size可以更大。输入是16帧，每帧112*112。</p>
</li>
</ul>
<h3 id="Two-Stream-Networks"><a href="#Two-Stream-Networks" class="headerlink" title="Two-Stream Networks"></a>Two-Stream Networks</h3><ul>
<li><strong>LSTM缺点</strong>：能model高层变化却不能捕捉低层运动(因为在低层，每个帧都是独立地被CNN提取特征)，有些低层运动可能是重要的；训练很昂贵</li>
<li><p><strong>Two-Stream Networks</strong>: 将单独的一张RGB图片和一叠计算得到的光流帧分别送入在ImageNet上预训练的ConvNet中，再把两个通道的score取平均</p>
<blockquote>
<p>这种方法在现在的数据集上效果很好<br>训练和测试都十分经济</p>
</blockquote>
</li>
<li><p>一个改进(<strong>Fused Two-Stream</strong>): 在最后一层卷积层之后，使用3D ConvNet把空间流和时间流<strong>融合</strong>（相比于传统双流是在softmax后才做fusion，把softmax输出的score进行平均）</p>
<blockquote>
<p>在HMDB数据集上提升了效果，测试时间也更短</p>
</blockquote>
</li>
<li><p>模型细节：输入是每隔10帧取连续的5帧以及相应的光流。在Inception v1之后，是一个3*3*3的3D卷积层，输出是512个channel，随后是一个3*3*3的3D max-pooling层以及全连接层。这个新的网络是用高斯随机初始化</p>
</li>
<li><p><strong>对于双流网络有两种实现</strong>，一种实现是训练时把两个流分开训练，测试的时候在最后把两个流的预测结果做平均；第二种是直接端到端进行训练。在c)和d)的实现中使用的是端到端；而在e)的实现中使用了第一种实现</p>
</li>
</ul>
<h3 id="New-Two-Stream-Inflated-3D-ConvNets"><a href="#New-Two-Stream-Inflated-3D-ConvNets" class="headerlink" title="New*: Two-Stream Inflated 3D ConvNets"></a>New*: Two-Stream Inflated 3D ConvNets</h3><ul>
<li>结论：3D ConvNets可以受益于在ImageNet上训练过的2D ConvNet模型，并有选择性的使用相应的预训练参数；虽然3D ConvNets可以直接从RGB流中学习到时序信息，但是使用光流还是可以提升效率</li>
<li>区别于之前的几种双流，光流数是RGB帧数的2L倍，这里光流和RGB帧都使用了64帧</li>
</ul>
<h4 id="Inflating-2D-ConvNets-into-3D"><a href="#Inflating-2D-ConvNets-into-3D" class="headerlink" title="Inflating 2D ConvNets into 3D"></a>Inflating 2D ConvNets into 3D</h4><ul>
<li>把一些很成功的2D模型转移成3D，通过把所有卷积核以及pooling核增加时间的一维</li>
</ul>
<h4 id="Bootstrapping-3D-filters-from-2D-filters"><a href="#Bootstrapping-3D-filters-from-2D-filters" class="headerlink" title="Bootstrapping 3D filters from 2D filters"></a>Bootstrapping 3D filters from 2D filters</h4><ul>
<li>想要利用在ImageNet上预训练好的2D模型的参数：</li>
<li><strong>Idea*</strong>: 若是把ImageNet中的同一张图片反复复制生成一个序列，那么这个序列就可以当作是一个video来训练3D模型了<blockquote>
<p>具体实现：<strong>把2D模型中的核参数在时间维上不断复制，形成3D核的参数，同时除以N，保证输出和2D上一样；别的非线性层结构都与原来的2D模型一样</strong></p>
</blockquote>
</li>
</ul>
<h4 id="Pacing-receptive-field-growth-in-space-time-and-network-depth-在时间维度上的感受野要如何变化，即conv和pooling的stride怎么选"><a href="#Pacing-receptive-field-growth-in-space-time-and-network-depth-在时间维度上的感受野要如何变化，即conv和pooling的stride怎么选" class="headerlink" title="Pacing receptive field growth in space, time and network depth (在时间维度上的感受野要如何变化，即conv和pooling的stride怎么选)"></a>Pacing receptive field growth in space, time and network depth (在时间维度上的感受野要如何变化，即conv和pooling的stride怎么选)</h4><ul>
<li>在Image模型中，对待水平和垂直两个空间维度往往是一致的，也就是两个维度上pooling核大小以及stride都一样</li>
<li>在时间维度上这样的对称对待未必是最优的(也就是时间维度上的pooling核大小选与空间上的一致是不可取的)，因为这取决于帧率和图像大小之间的相对值</li>
<li>具体实现：在Inception v1中，涉及到感受野变化的就是第一个卷积核(stride=2)以及后续4个max-pooling(stride=2)，还有最后的一个7*7的average-pooling层。在本文的实验中，作者发现：在前两个max-pooling层上，时间维度上的stride取1；而在别的max-pooling层上使用对称的stride(即时间维度上的stride和空间上的一致)；最后的average pooling使用2*7*7的核<img src="/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/3.png">
</li>
</ul>
<h4 id="Two-3D-Streams"><a href="#Two-3D-Streams" class="headerlink" title="Two 3D Streams"></a>Two 3D Streams</h4><ul>
<li>作者发现双流还是有价值的，可能因为3D ConvNet只有纯前馈计算，而光流提供了迭代的思想在里面</li>
<li>训练时，分别训练这两个网络，测试的时候在最后把两个流的预测结果做平均</li>
</ul>
<h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><ul>
<li>见原文</li>
<li>注：在训练时都是从原始video采样的，而test的时候是把全部的帧都送入网络。实现细节也可以看代码</li>
</ul>
<h2 id="The-Kinetics-Human-Action-Video-Dataset"><a href="#The-Kinetics-Human-Action-Video-Dataset" class="headerlink" title="The Kinetics Human Action Video Dataset"></a>The Kinetics Human Action Video Dataset</h2><ul>
<li>数据集细节参见另一篇提出这个数据集的文章 <a href="https://arxiv.org/abs/1705.06950" target="_blank" rel="noopener">The Kinetics Human Action Video Dataset</a></li>
</ul>
<h2 id="Experimental-Comparison-of-Architectures-模型本身的比较"><a href="#Experimental-Comparison-of-Architectures-模型本身的比较" class="headerlink" title="Experimental Comparison of Architectures (模型本身的比较)"></a>Experimental Comparison of Architectures (模型本身的比较)</h2> <img src="/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/4.png">
<ul>
<li>在UCF-101和HMDB-51上，I3D取得的效果也要好于之前的。这十分有趣，因为UCF-101和HMDB-51数据集本身比较小，而I3D模型参数非常多，按道理来说训练效果应该不会太好。这说明在ImageNet上预训练的效果可以扩展到3D</li>
<li>在UCF-101上效果最好，miniKinetics次之，HMDB-51最差，这和数据本身的难度、数据量大小都有关系</li>
<li>LSTM和3D-ConvNet在miniKinetics上表现的更有竞争力，这是因为这两种方法对数据量的需求比较大</li>
<li>在miniKinetics上，光流要比RGB流效果差，而在其他两个数据集上则相反，这是由于miniKinetics数据集本身有许多相机抖动</li>
<li>相比于其他模型，I3D模型似乎从光流中获益最大，这有可能是因为I3D的时间长度更大(有64帧)</li>
</ul>
<h2 id="Experimental-Evaluation-of-Features-用在迁移学习中，即把各种模型先在Kinetics数据集上做预训练，预训练得到的网络作为特征提取器，再去别的数据集上训练与测试"><a href="#Experimental-Evaluation-of-Features-用在迁移学习中，即把各种模型先在Kinetics数据集上做预训练，预训练得到的网络作为特征提取器，再去别的数据集上训练与测试" class="headerlink" title="Experimental Evaluation of Features (用在迁移学习中，即把各种模型先在Kinetics数据集上做预训练，预训练得到的网络作为特征提取器，再去别的数据集上训练与测试)"></a>Experimental Evaluation of Features (用在迁移学习中，即把各种模型先在Kinetics数据集上做预训练，预训练得到的网络作为特征提取器，再去别的数据集上训练与测试)</h2><ul>
<li>固定预训练的参数，在新数据集上只重新训练一个分类器</li>
<li><p>整个网络在新数据集上fine-tuning</p>
<blockquote>
<p>固定预训练的参数，在新数据集上只重新训练一个分类器的做法在I3D和3D ConvNet上也有不少提升，但在其他几种方法上几乎没有变化<br>整个网络在新数据集上fine-tuning的结果都得到大幅提升，尤其是<strong>I3D和3D ConvNet</strong><br>迁移学习对于I3D影响最大，这也可能是因为I3D的时间长度更大，在大数据集上预训练就可以学到更好的时间结构<br>而迁移学习对于没有使用3D ConvNet结构的影响不大，这可能是因为那些方法的输入都是离散的帧而不是连续的帧，而那些2D方法都用了ImageNet预训练的参数，这些独立的帧其实更像是image而不是video，所以已经在image的数据集上预训练过的结构在video的大数据上进一步pre-train不一定有明显提升</p>
</blockquote>
<img src="/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/5.png">
<img src="/2018/03/07/Qua-Vadis-Action-Recognition-A-New-Model-and-the-Kinetics-Dataset/6.png"></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 计算机视觉 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> Action Recognition </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数值分析]]></title>
      <url>/2018/03/05/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>ZJU 数值分析课程笔记</p>
<a id="more"></a>
<h2 id="2018-03-05"><a href="#2018-03-05" class="headerlink" title="2018-03-05"></a>2018-03-05</h2><h3 id="课程介绍"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍</h3><p>黄劲<br>hj@cad.zju.edu.cn<br>蒙民伟楼 431</p>
<p>30分Lab Pro + 18分Discussion + 7分Research Topic + 5分Q&amp;A + 40分考试<br>    考过高斯积分，尽可能提高精度<br>    discussion：2个人一组做报告，3-5分钟<br>    research topic：按组完成，有18个topic，5-10分钟展示</p>
<h3 id="数值分析（Numerical-Analysis）的作用是什么？"><a href="#数值分析（Numerical-Analysis）的作用是什么？" class="headerlink" title="数值分析（Numerical Analysis）的作用是什么？"></a>数值分析（Numerical Analysis）的作用是什么？</h3><ul>
<li>硬件只做最简单的+/-/*等，剩下的复杂计算都依赖于软件实现（尽管现在有部分简单的计算被加进了CPU）</li>
<li>计算机里面的数学几乎全是近似，如0.7都无法在计算机里面精确表示</li>
</ul>
<h3 id="这门课将要介绍什么"><a href="#这门课将要介绍什么" class="headerlink" title="这门课将要介绍什么"></a>这门课将要介绍什么</h3><ul>
<li>介绍经典的近似技术/逼近技术（approximation technique）</li>
<li>解释为何这些技术可以有效地工作</li>
<li>是将来从事科学计算的基础</li>
</ul>
<h3 id="Chapter-1-Mathematical-Preliminaries"><a href="#Chapter-1-Mathematical-Preliminaries" class="headerlink" title="Chapter 1 Mathematical Preliminaries"></a>Chapter 1 Mathematical Preliminaries</h3><h4 id="1-2-Roundoff-Errors-and-Computer-Arithmetic"><a href="#1-2-Roundoff-Errors-and-Computer-Arithmetic" class="headerlink" title="1.2 Roundoff Errors and Computer Arithmetic"></a>1.2 Roundoff Errors and Computer Arithmetic</h4><h5 id="误差来源："><a href="#误差来源：" class="headerlink" title="误差来源："></a>误差来源：</h5><ul>
<li><strong>Truncation Error</strong>：对于无穷项/无穷小数等，必须进行截断，即舍去后面的项（如泰勒展开）</li>
<li><strong>Roundoff Error</strong>：计算机本身进行实数运算时由于不精确产生的误差（因为计算机在运算时只能保留有限位数）</li>
</ul>
<h5 id="Roundoff-Error何时会影响结果的精确性？"><a href="#Roundoff-Error何时会影响结果的精确性？" class="headerlink" title="Roundoff Error何时会影响结果的精确性？"></a>Roundoff Error何时会影响结果的精确性？</h5><ul>
<li>做除法时，如果除数非常小，那么被除数的一个小误差，在商当中会产生巨大的误差，ex/y很大(因为y很小)<blockquote>
<p>如果一个值非常大，那么一定涉及了除法，如tan、log</p>
</blockquote>
</li>
<li><strong>结论*：必须先把式子简化后再输入计算机，这样可以减少计算机在运算过程中产生的Roundoff的误差</strong>（如秦九韶算法）</li>
</ul>
<h5 id="对于一个无限小数，有两种近似的处理："><a href="#对于一个无限小数，有两种近似的处理：" class="headerlink" title="对于一个无限小数，有两种近似的处理："></a>对于一个无限小数，有两种近似的处理：</h5><ul>
<li><strong>Chopping</strong>（直接截断）</li>
<li><strong>Rounding</strong>（四舍五入）</li>
</ul>
<h5 id="误差分类："><a href="#误差分类：" class="headerlink" title="误差分类："></a>误差分类：</h5><ul>
<li><strong>Absolute Error</strong>: |p-p*|</li>
<li><strong>Relative Error</strong>: |p-p*|/|p| 或 f~(x+e) - f(x)  / f(x)<blockquote>
<p>有效数字是一个相对误差<br>Rounding的每一步相对误差都较小（对于单次，四舍五入肯定比直接舍去要更精确），但是对于整个运算来说不一定</p>
</blockquote>
</li>
</ul>
<h5 id="一个定义："><a href="#一个定义：" class="headerlink" title="一个定义："></a>一个定义：</h5><img src="/2018/03/05/数值分析/1.png">
<h4 id="1-3-Algorithms-and-Convergence"><a href="#1-3-Algorithms-and-Convergence" class="headerlink" title="1.3 Algorithms and Convergence"></a>1.3 Algorithms and Convergence</h4><h5 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h5><ul>
<li>stable：输入有一个小的扰动，输出的扰动也很小</li>
<li>unstable：输入有一个小的扰动，输出的扰动很大</li>
<li>conditionally stable：仅当输入的数据是某几个特定选择时，是stable的</li>
</ul>
<h5 id="定义：-1"><a href="#定义：-1" class="headerlink" title="定义："></a>定义：</h5><p> E0 表示初始误差，En 表示第 n 次操作后的误差。</p>
<ul>
<li>若 En == C*n*E0 (C是常数)，那么error的增长是Linear的</li>
<li>若 En == C^n*E0 ，那么error的增长是Exponential的<blockquote>
<p>Linear的误差是不可避免的，但要尽可能避免Exponential的误差</p>
</blockquote>
</li>
</ul>
<h5 id="Example："><a href="#Example：" class="headerlink" title="Example："></a>Example：</h5><img src="/2018/03/05/数值分析/2.png">
<ul>
<li><p>Method 1：<img src="/2018/03/05/数值分析/3.png"></p>
<blockquote>
<p>|En| = |In - In*| = |(1-n*In-1) - (1-n*In-1*)| = n*|En-1| = … = n!*|E0|<br>随着n的增大，误差的增长是Exponential的，若去计算（每一次保留若干位）就会发现，明明In是递减的，其算到n比较大时，会增大，甚至在正负之间跳动</p>
</blockquote>
</li>
<li><p>Method 2：<img src="/2018/03/05/数值分析/4.png"></p>
<blockquote>
<p>区别于上面由In-1推到In，这里先定In，再推回In-1：由1/(e*(n+1)) &lt; In &lt; 1/(N+1)，取In’ = [1/(e*(n+1)) + 1/(n+1)]/2<br>|En| = |In - In’| -&gt; 0，当 n -&gt; ∞；|Ej| = |En|/(n*(n-1)*(n-2)…(j+1))<br>因为该方法的Error是有界的，就是区间长度，此时向前算，误差就会越来越小，所以就不会出现Method 1的大误差。实际计算中，该方法算出来的I0、I1也都是很准确的</p>
</blockquote>
</li>
</ul>
<hr>
<h2 id="2018-03-12"><a href="#2018-03-12" class="headerlink" title="2018-03-12"></a>2018-03-12</h2><h3 id="Chapter-2-Solutions-of-Equations-in-One-Variable"><a href="#Chapter-2-Solutions-of-Equations-in-One-Variable" class="headerlink" title="Chapter 2 Solutions of Equations in One Variable"></a>Chapter 2 Solutions of Equations in One Variable</h3><h4 id="2-1-The-Bisection-Method"><a href="#2-1-The-Bisection-Method" class="headerlink" title="2.1 The Bisection Method"></a>2.1 The Bisection Method</h4><h5 id="中值定理"><a href="#中值定理" class="headerlink" title="中值定理"></a>中值定理</h5><ul>
<li>若f属于C[a, b]，K是介于f(a)和f(b)之间的一个数(当然f是连续函数)，那么在(a, b)上必定存在一个数p，使得f(p) = K</li>
</ul>
<h5 id="二分法"><a href="#二分法" class="headerlink" title="二分法"></a>二分法</h5><ul>
<li>若f属于C[a, b]，且f(a) * f(b) &lt; 0，那么由二分法可以产生一个逼近f零点p的序列，并保证：<img src="/2018/03/05/数值分析/6.png"></li>
<li>二分的条件：单调、有界</li>
<li>二分时，使用 p = a + (b - a) / 2 而不是 p = (a + b) / 2 的原因是保证精度；使用sign(FA)*sign(FP)来判断是否大于0是因为担心使用FA*FP判断时会溢出</li>
<li>二分法的优点：<blockquote>
<p>很容易，只需要f单调、有界；而且总能收敛到某个解</p>
</blockquote>
</li>
<li>二分法的缺点：<blockquote>
<p>收敛慢；<br>可能在收敛过程中会丢掉某一个好的中间近似解；<br>若有多个解，只能收敛到某一个solution；————可以事先把区间划成多段[ak, bk]，保证f(ak) * f(bk) &lt; 0<br>二分法不能用来找复数根，因为complex number无序，不可排序</p>
</blockquote>
</li>
</ul>
<h4 id="2-2-Fixed-Point-Iteration"><a href="#2-2-Fixed-Point-Iteration" class="headerlink" title="2.2 Fixed-Point Iteration"></a>2.2 Fixed-Point Iteration</h4><ul>
<li><p><strong>思想</strong>：把求根问题转化成求不动点(若g(p) = p，则p被定义成g的一个不动点)的问题：把f(x)转化成等价的x = g(x)</p>
<blockquote>
<p>一个f(x)可以对应一堆g(x)<br>g(x)目标：能收敛，且收敛到f(x)的root    (如g(x)=x^2，初值选了&gt;1，那么永远不可能收敛)</p>
</blockquote>
</li>
<li><p><strong>求解方法</strong>：从一个初始的p0开始，随后通过pn = g(pn-1)生成一个序列，若这个序列收敛并且g是连续函数，则最终收敛得到的p=g(p)即为所求不动点 (因为pn = g(pn-1) = g(pn)，当n趋向于无限大）</p>
</li>
<li><p><strong>不动点定理</strong></p>
<blockquote>
<p>存在性：g属于C[a, b]且g(x)属于[a, b]，对于一切x属于[a, b]成立，则g在[a, b]有一个不动点<br>唯一性：在上述存在的条件下，若g’(x)在(a, b)存在，且存在一个正常数k &lt; 1，使得|g’(x)| &lt;= k，那么不动点在[a, b]上唯一<br>在不动点存在且唯一的条件下，使用上述求解方法可以收敛于[a, b]内的唯一不动点p</p>
</blockquote>
</li>
<li><p>若g满足不动点定理的条件，则用pn逼近p的误差界如下：</p>
<img src="/2018/03/05/数值分析/7.png"> 
</li>
<li><p>因此，根据这个误差界，我们可以在计算前估计大概要算多久。且我们发现k越小收敛越快</p>
</li>
<li><p><strong>构造g(x)时，要保证g’(x) &lt;= k &lt; 1，且k越小越好</strong></p>
</li>
</ul>
<h4 id="2-3-Newton-Raphson-Method"><a href="#2-3-Newton-Raphson-Method" class="headerlink" title="2.3 Newton-Raphson Method"></a>2.3 Newton-Raphson Method</h4><p>有条件收敛</p>
<hr>
<h2 id="2018-03-19"><a href="#2018-03-19" class="headerlink" title="2018-03-19"></a>2018-03-19</h2><h4 id="2-4-Error-Analysis-for-Iterative-Methods"><a href="#2-4-Error-Analysis-for-Iterative-Methods" class="headerlink" title="2.4 Error Analysis for Iterative Methods"></a>2.4 Error Analysis for Iterative Methods</h4><ul>
<li><strong>定义</strong>：<img src="/2018/03/05/数值分析/8.png"> 
<blockquote>
<p>a越大，收敛越快，因此人们都试图找到产生高阶收敛序列的方法</p>
</blockquote>
</li>
</ul>
<h4 id="2-5-Accelerating-Convergence"><a href="#2-5-Accelerating-Convergence" class="headerlink" title="2.5 Accelerating Convergence"></a>2.5 Accelerating Convergence</h4><p>Aitken’s 2 Method的假设：线性收敛，所以(Pn+1 - P)/(Pn - P) = lenda = (Pn - P)/(Pn-1 - P)，所以P可由三个P猜测，n越大lenda越小，所以猜测的P越准</p>
<hr>
<h2 id="2018-03-26"><a href="#2018-03-26" class="headerlink" title="2018-03-26"></a>2018-03-26</h2><h3 id="Chapter-6-Direct-Methods-for-Solving-Linear-Systems"><a href="#Chapter-6-Direct-Methods-for-Solving-Linear-Systems" class="headerlink" title="Chapter 6 Direct Methods for Solving Linear Systems"></a>Chapter 6 Direct Methods for Solving Linear Systems</h3><h4 id="6-1-Linear-Systems-of-Equations"><a href="#6-1-Linear-Systems-of-Equations" class="headerlink" title="6.1 Linear Systems of Equations"></a>6.1 Linear Systems of Equations</h4><ul>
<li>向后代换的高斯消元法<blockquote>
<p>先把A变成上三角矩阵，随后用向后代换的方式解未知数<br>akk被称为主元，若akk=0，则要把第k行和第i行做interchange(其中，aki!=0)<br>运算次数：</p>
<img src="/2018/03/05/数值分析/9.png"> 
</blockquote>
</li>
</ul>
<h4 id="6-2-Pivoting-Strategies"><a href="#6-2-Pivoting-Strategies" class="headerlink" title="6.2 Pivoting Strategies"></a>6.2 Pivoting Strategies</h4><ul>
<li>若某个主元非常小，会引起较大的误差</li>
</ul>
<hr>
<h2 id="2018-04-23"><a href="#2018-04-23" class="headerlink" title="2018-04-23"></a>2018-04-23</h2><h3 id="Chapter-8-Approximation-Theory"><a href="#Chapter-8-Approximation-Theory" class="headerlink" title="Chapter 8 Approximation Theory"></a>Chapter 8 Approximation Theory</h3><ul>
<li><strong>目标</strong>：给定一组x1…xm和y1…ym，找到一个能够拟合真实函数f(x)的简单近似函数P(x)，使得P(xi)-yi尽可能小。</li>
<li><strong>难点</strong>：(1) 给定的点对数一般很多；(2) 给定的yi不一定准，即不一定落在真实函数上（就好比取自线性函数的一堆点未必都是落在同一条直线上的）</li>
</ul>
<h4 id="8-1-Discrete-Least-Squares-Approximation"><a href="#8-1-Discrete-Least-Squares-Approximation" class="headerlink" title="8.1 Discrete Least Squares Approximation"></a>8.1 Discrete Least Squares Approximation</h4><ul>
<li><p><strong>设想</strong>：</p>
<blockquote>
<p>使得P(xi)-yi的最大值最小，即把单个的最大误差控制在一个范围内。这种方法被称为最小值问题，初等技术无法解决<br>使得sigma|P(xi)-yi|最小。这个值是绝对偏差，为了求解最小值，需要对这个式子求导，但这里有绝对值，存在一些点不可导</p>
</blockquote>
</li>
<li><p>解决方案：<strong>最小二乘逼近法</strong>：定义Pn(x)=a0+a1x+…+anx^n，使得最小化<img src="/2018/03/05/数值分析/10.png"> </p>
<blockquote>
<p>好处：把更多的权重赋予远离其他数据直线的点上，但又不允许该点完全主导逼近值</p>
</blockquote>
</li>
</ul>
<hr>
<h2 id="2018-05-14"><a href="#2018-05-14" class="headerlink" title="2018-05-14"></a>2018-05-14</h2><h3 id="Chapter-4-Numerical-Differentiation-and-Integration"><a href="#Chapter-4-Numerical-Differentiation-and-Integration" class="headerlink" title="Chapter 4 Numerical Differentiation and Integration"></a>Chapter 4 Numerical Differentiation and Integration</h3><ul>
<li>通过逼近的多项式的积分和导数来估计实际函数的积分和导数<h4 id="4-1-Numerical-Differentiation"><a href="#4-1-Numerical-Differentiation" class="headerlink" title="4.1 Numerical Differentiation"></a>4.1 Numerical Differentiation</h4></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 数值分析 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数值分析 </tag>
            
            <tag> ZJU课程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[资源汇总]]></title>
      <url>/2018/02/17/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/</url>
      <content type="html"><![CDATA[<p>记录了各个地方看到的资源整合，供日后查阅</p>
<a id="more"></a>
<h3 id="自己整理的"><a href="#自己整理的" class="headerlink" title="自己整理的"></a>自己整理的</h3><h4 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h4><ul>
<li><a href="https://dmortem.github.io/2018/04/06/cs231n-Let11-Detection-and-Segmentation/#more">cs231n Let11</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247485505&amp;idx=1&amp;sn=220ec856e749d008abfac84e7f40ea19&amp;chksm=ec1fe5b8db686cae94165ee5a90a0e13857b9a3e8d34709793007297109e24b030aaad95ebe8&amp;mpshare=1&amp;scene=1&amp;srcid=042764p6jhr7E0OW3rzmjsJn#rd" target="_blank" rel="noopener">详解计算机视觉五大技术：图像分类、对象检测、目标跟踪、语义分割和实例分割</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741534&amp;idx=1&amp;sn=02dc164ffcedbf22124b97841ba67fe5&amp;chksm=871adf60b06d567690fa2328b161c012a464687768e50f812a51b5533a7d68b99af1cf8f02b8&amp;scene=0#rd" target="_blank" rel="noopener">从RCNN到SSD，目标检测算法盘点</a></li>
</ul>
<h4 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h4><ul>
<li><a href="https://mp.weixin.qq.com/s/IjlIT-3FVY7IfYzNDtkkgg" target="_blank" rel="noopener">谷歌综述</a></li>
</ul>
<hr>
<h3 id="Zero-to-Hero：2017年机器之心AI高分概述文章全集-链接"><a href="#Zero-to-Hero：2017年机器之心AI高分概述文章全集-链接" class="headerlink" title="Zero to Hero：2017年机器之心AI高分概述文章全集 链接"></a>Zero to Hero：2017年机器之心AI高分概述文章全集 <a href="https://mp.weixin.qq.com/s/wDWF1RFaW9EOEoctyJvopQ" target="_blank" rel="noopener">链接</a></h3><h4 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724740&amp;idx=2&amp;sn=ff1006aa53de7e766c7b15760f196a3d&amp;chksm=871b1dfab06c94ec0b83bfe14c866433397e0006f9e6b3a65b1d76e04333ce99a4db341d5252&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | David Silver 全面解读<strong>深度强化学习</strong>：从基础概念到 AlphaGo</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724800&amp;idx=2&amp;sn=0d5e47e071c346eb4a485980deee5744&amp;chksm=871b1dbeb06c94a81b74afcde32d759b7118d60e60b710570a2d6cf53fbe2a9badaed44c5f05&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | <strong>迁移学习</strong>全面概述：从基本概念到相关研究</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724906&amp;idx=3&amp;sn=b6e1e70fb625222d0d0f1b30741e4e29&amp;chksm=871b1e54b06c974297180145f79525a0fbdb25b171aefd659ad1fac23356be3ad024c1e1a211&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 理解深度学习中的<strong>卷积</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724485&amp;idx=5&amp;sn=cff6f96f7d06544f9b6cc3acd5a48a91&amp;chksm=871b1cfbb06c95edfe8c6d2b73b0b170b7c193b94ac8f306868add06edb4d8effc53ae0f1181&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">综述 | <strong>知识图谱</strong>研究进展</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724029&amp;idx=2&amp;sn=18e1a3c233e7802d2297d9cbb1e7c35f&amp;chksm=871b12c3b06c9bd5319a472af2126c2a9731ad14da3159060e67f53daab7276bc7773aa03242&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">盘点 | 机器学习<strong>入门算法</strong>：从线性模型到神经网络</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724980&amp;idx=1&amp;sn=bd8bbf172316eb189ea256194e2d95fd&amp;chksm=871b1e0ab06c971c0b6996439d7f6a0691d7b05763071f6e14ccb6f9d108d42f367735d77601&amp;scene=21#wechat_redirect" target="_blank" rel="noopener"><strong>深度神经网络全面概述</strong>：从基本概念到实际模型和硬件基础</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725078&amp;idx=1&amp;sn=db7b6f92466bdf146ac9b0163880e42c&amp;chksm=871b1ea8b06c97be5256dd45e14ec50c7ac984b68045e869dab44bd11cfa411fab0e954860f9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器理解大数据的秘密：<strong>聚类</strong>算法深度详解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725041&amp;idx=1&amp;sn=0c57ba70e2613e6af80c4ab61c996d44&amp;chksm=871b1ecfb06c97d9547e50705d3e74a2b8c41254f0efc2dd88d2e89eec3bfac5da089f28c398&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">想了解<strong>概率图模型</strong>？你要先理解图论的基本定义与形式</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725041&amp;idx=4&amp;sn=3f2eae15dd83120ac0b9703cdc0a033f&amp;chksm=871b1ecfb06c97d99f0e0ca6c51d6987113106f489352d23f3a2615aa79a358a6df78f2977f9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">人工智能能骗过人类吗？愚人节特写：这不是玩笑</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725760&amp;idx=1&amp;sn=57391594edfeb9807b6288bfc0dacd30&amp;chksm=871b19feb06c90e85023a2fd9a6e447cd6c967ac25f21abf01685a0cf38f8adccf3012d5d54c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">三张图读懂机器学习：基本概念、五大流派与九种常见算法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729264&amp;idx=1&amp;sn=e748f5ba8142ece2fa63529889b602b8&amp;chksm=871b2f4eb06ca6588bb34d67e9d5ee67d0d614259e9a54a75a96379abff53a47efebd52c2454&amp;scene=21#wechat_redirect" target="_blank" rel="noopener"><strong>LSTM</strong> 入门必读：从基础知识到工作方式详解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729976&amp;idx=1&amp;sn=1f2e64ae2baefd82fd6dcac86d2cc77e&amp;chksm=871b2986b06ca0907fdc335b8f79f0c15cc4393ec45f89ad93d3c9a899c05224dc16e244b097&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从语言学到深度学习 <strong>NLP</strong>，一文概述自然语言处理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730634&amp;idx=1&amp;sn=4b7611508906396fba618d2aead27306&amp;chksm=871b34f4b06cbde2e0af7a8ff68774101931bd35792dd3eaa719e94d5798a8ce7e67a581b906&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">最全的 <strong>DNN 概述</strong>论文：详解前馈、卷积和循环神经网络技术</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731034&amp;idx=1&amp;sn=c700041fe10108ca1068c4d80aa0d05a&amp;chksm=871b3664b06cbf726bd93d7b3db4f15125df77a6f69ddb0304b292b932071d2d78104ad5d4f0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从贝叶斯定理到概率分布：综述<strong>概率论</strong>基本定义</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732899&amp;idx=1&amp;sn=f7447666808bf71132591db8d23a42d8&amp;chksm=871b3d1db06cb40ba96c261e02e49b9114872d7426d6a8e332249fa6eae3aa3b23b90046c48a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">追根溯源！一图看尽<strong>深度学习架构</strong>谱系</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733476&amp;idx=1&amp;sn=322794d996a905d1599677f166d9b640&amp;chksm=871b3fdab06cb6cccf74914e21d9e5c1210b6aedc2ac6c94aefcf1351760c3b4b93b461229da&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">徒手实现 CNN：综述论文详解<strong>卷积网络</strong>的数学本质</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733927&amp;idx=1&amp;sn=72f8362c4f39fb5fb093d09e13eba91b&amp;chksm=871b3919b06cb00fdef2c2908232ae767c8249015fe499f5bb3c5125542924cb68684a4d90b9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">读懂<strong>概率图</strong>模型：你需要从基本概念和参数估计开始</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734516&amp;idx=1&amp;sn=97750fa6b84ecdf97f3d0363d1d94ae3&amp;chksm=871b3bcab06cb2dcba6a0c46a8444af5e6e567c608c52ef8cd1da38479d662fede71dadf6aa6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从零开始：教你如何<strong>训练神经网络</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735358&amp;idx=1&amp;sn=a1c5550fc3f2296181d14a79bdd2fe47&amp;chksm=871ac680b06d4f961f02777fb1da6067daaf94f73a13c55181e5cf49b0a1b8daf3204d078fd1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">开发者必读：计算机科学中的<strong>线性代数</strong></a></li>
</ul>
<h4 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h4><h5 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725170&amp;idx=4&amp;sn=0fe562747d000cffc71371235ae531ac&amp;chksm=871b1f4cb06c965a851c20019e6a20244b7779ecea0d7b9984d6ecc432b423d1aa06132b7022&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">学界 | 定量研究：当前机器学习领域<strong>十大研究主题</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725277&amp;idx=1&amp;sn=91dcf45a21f0116525eb494722abc5d2&amp;chksm=871b1fe3b06c96f506e443111ab2ffc5230e373345aaa4a80e499404370bd86cb10ea05eca61&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习和深度学习<strong>引用量最高的 20 篇论文</strong>（2014-2017）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727657&amp;idx=1&amp;sn=1eff4d32c10d985185a3c8750a338342&amp;chksm=871b2097b06ca98126eed936ac38dc68752e43673880ed998a42937b8a8c268fcd65081eaefb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从<strong>贝叶斯</strong>角度，看深度学习的属性和改进方法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733038&amp;idx=1&amp;sn=3d73ee20747d60e9336800b514f3231f&amp;chksm=871b3d90b06cb4867c33267aed911300232d9aafe8e524b81cad78bfa5ad784f020b47e9334e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">良心 GitHub 项目：各种机器学习任务的<strong>顶级结果（论文）汇总</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733548&amp;idx=3&amp;sn=4b90bb7b81c31ded3860ea15418d1ee4&amp;chksm=871b3f92b06cb68424867aa0f10696b772a89bd83acff812773e9ba8ec8d68dbe2944b4b86ea&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 从朴素贝叶斯到维特比算法：详解<strong>隐马尔科夫模型</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734720&amp;idx=1&amp;sn=2cc7ee6f1fd4e4b2ec2a158e579657f7&amp;chksm=871ac4feb06d4de88807808264198ac18518957706c1ca91589afb5b0688d4f9d23b9d579eaf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">揭秘深度学习成功的<strong>数学原因</strong>：从全局最优性到学习表征不变性</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734862&amp;idx=2&amp;sn=20e1ecd998ee8505a58cca0f3909eb0b&amp;chksm=871ac570b06d4c667ddca20f83fbfd0a36533622b798f25e608a7efa39f5be207499594eb41c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 从 AlexNet 到残差网络，理解<strong>卷积神经网络的不同架构</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735095&amp;idx=1&amp;sn=1d2293dbaa13e62d232587f0ee1fe51b&amp;chksm=871ac589b06d4c9f2f962a3a31ee06d13de4c3b5fc972cf2536659261f80874f94bde2b1cbed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从 Pix2Code 到 CycleGAN：2017 年<strong>深度学习重大研究进展</strong>全解读</a></li>
</ul>
<h5 id="前沿方向"><a href="#前沿方向" class="headerlink" title="前沿方向"></a>前沿方向</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724740&amp;idx=1&amp;sn=e274066d69c18731b285dbf5e0a480fd&amp;chksm=871b1dfab06c94ecb356c2ddc47465b41507dd387d5daf2dafe7c9814cd23106405be442f3cf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">OpenAI 详解<strong>进化策略</strong>方法：可替代强化学习</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726358&amp;idx=1&amp;sn=784d7a9e7bc2f4c66d6a7791830cc078&amp;chksm=871b1ba8b06c92be00d52e5fd891bad281f07b5924920b66a2768167c11a381b22239f54d0ee&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从自编码器到生成对抗网络：一文纵览<strong>无监督学习</strong>研究现状</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726413&amp;idx=5&amp;sn=1e949e66425071aca0c6471ff1a6446f&amp;chksm=871b2473b06cad65c8bf779186a99874f483e662dfd1e4e19e905787d103c3458156c676af22&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 从文本到视觉：<strong>各领域最前沿的论文集合</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729423&amp;idx=1&amp;sn=7d78fbddbd79cb864e64516744224212&amp;chksm=871b2fb1b06ca6a7dbc4f8f057f17e737d7dbc7d7ced78a2e12dcef0616f830bd50cdd1973f0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从决策树到随机森林：<strong>树型算法</strong>的原理与实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731427&amp;idx=1&amp;sn=9dc135b7f5399951456950aa7544ccb0&amp;chksm=871b37ddb06cbecbb2cf5b82150e1564ac5243fd85a9eb7f4d39e96f8289af1702badf72d5cf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从概率论到多分类问题：综述<strong>贝叶斯统计分类</strong></a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733110&amp;idx=1&amp;sn=4ad8d8183de6db854de9c67646ad8600&amp;chksm=871b3e48b06cb75e02fd8917927c237a3ca434bfbe9cc6e7714f6abffe2cec1a123956aadb7b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从遗传算法到 OpenAI 新方向：<strong>进化策略</strong>工作机制全解</a></li>
</ul>
<h5 id="GAN-1"><a href="#GAN-1" class="headerlink" title="GAN"></a>GAN</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724769&amp;idx=2&amp;sn=6fa540106cf6a5fd55fc39d057092888&amp;chksm=871b1ddfb06c94c9e11d3a8281f60c0fce06a4e021fcd8eaab858c7f08ab9c939c4ad130e4b2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">综述 | 一文帮你发现各种出色的 GAN 变体</a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725730&amp;idx=4&amp;sn=7228767c7688ad8e3802a3978141d499&amp;chksm=871b191cb06c900ae5694a9f102151f483633c09c4892b384abee6055893e3ad35be9d73a31a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 生成对抗网络及其变体的论文汇总</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732216&amp;idx=1&amp;sn=b1801e5604bb3c2d3442e7bc016a54df&amp;chksm=871b32c6b06cbbd0294b0b3a94a2477cd01571425e3d5e7b7f316ab310ae83e2d287a2a7dba5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">生成对抗网络综述：从架构到训练技巧，看这篇论文就够了</a></li>
</ul>
</li>
</ul>
<h5 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725146&amp;idx=3&amp;sn=453e29cb6179e8e06df2133269c20812&amp;chksm=871b1f64b06c967276274cee90f5a036c09b08cec9e52111af6744c7f0c19d5a8c7e0eb06e0b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">干货 | <strong>物体检测</strong>算法全概述：从传统检测方法到深度神经网络框架</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725803&amp;idx=1&amp;sn=0805515d0edd5cf01d2be07b435eb312&amp;chksm=871b19d5b06c90c366c2a873ca1156ae61cef284c52c6bb7127f758f7fbb865748658f678a0f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">重磅 | <strong>自动驾驶</strong>计算机视觉研究综述：难题、数据集与前沿成果（附 67 页论文下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726632&amp;idx=1&amp;sn=bb9e6eedba961cad5e935295d9f379e1&amp;chksm=871b2496b06cad80a12b178e75413dc9c16ca24eb2aa22209ca5440f13b42445340c56f2ec45&amp;scene=21#wechat_redirect" target="_blank" rel="noopener"><strong>神经风格迁移</strong>研究概述：从当前研究到未来方向（附论文和代码）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730940&amp;idx=1&amp;sn=2a6a8520176368d467ca87fbc2e04c66&amp;chksm=871b35c2b06cbcd41593cf07aa5b7a7d0913f5d07de708fd554059b9f20f1b332190dd934025&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习<strong>目标检测</strong>模型全面综述：Faster R-CNN、R-FCN 和 SSD</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733805&amp;idx=1&amp;sn=1439bf16d6c534fa8da69d93bb33f0a4&amp;chksm=871b3893b06cb18521424a1f0bae26fa2235bf30eb95b698e1d3f12a49947daa8cfa492c8497&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">计算机视觉这一年：这是最全的一份 CV 技术报告</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733850&amp;idx=1&amp;sn=ee05c1e715621e41643cd6af5627a013&amp;chksm=871b3964b06cb0728981e6500c700fa71272726c66b3fee1dfd23c5d18de0205873767bdf973&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">计算机视觉这一年：2017 CV 技术报告 Plus 之卷积架构、数据集与新趋势</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734197&amp;idx=2&amp;sn=4e205aac262da52978e2286f5bde649c&amp;chksm=871b3a0bb06cb31d3ad73908c98d2b6ff68eef3d47e7bd96ab958b6b07159e7b1d10f8da7db5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 2017 CV 技术报告之图像分割、超分辨率和动作识别</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734471&amp;idx=2&amp;sn=5e1e47847ceb48cb7b5482bef9b96c3a&amp;chksm=871b3bf9b06cb2ef1fa8e17885334d56648103615c39bae92c3bb711ebbaf9facc8c1f8a09a2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 2017CV 技术报告：从 3D 物体重建到人体姿态估计</a></li>
</ul>
<h5 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725088&amp;idx=1&amp;sn=76ae9e837bda87e2d09b0eb33a50e3be&amp;chksm=871b1e9eb06c9788f7c2d5221e3fb9ee582f9320432404fe84f839920144a9f65d297a820ce6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener"><strong>语音合成</strong>到了跳变点？深度神经网络变革 TTS 最新研究汇总</a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728920&amp;idx=4&amp;sn=3c51fa0a95742d37222c3e16b77267ca&amp;chksm=871b2da6b06ca4b06489bca99d536eb5380e691d733ed9b6af45a25cf70b3d49321ff13eae80&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 从全连接层到大型卷积核：深度学习<strong>语义分割</strong>全指南</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732316&amp;idx=3&amp;sn=023dced1eaa4dc592f1fc273598c7b7d&amp;chksm=871b3362b06cba74545ec1582df7c6525ac3f6fb3dd2686c96cf693ac6b8f0cb3c57702b951c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">学界 | <strong>词嵌入</strong> 2017 年进展全面梳理：趋势和未来方向</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734670&amp;idx=2&amp;sn=f31497f57e8f2ce73d8af9f36c5be13c&amp;chksm=871ac430b06d4d26b8265844df8bec51f518164402e2dd6b05e23901b1678f38ac2ffdd4cceb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 一文概述 2017 年深度学习 <strong>NLP 重大进展与趋势</strong></a></li>
</ul>
</li>
</ul>
<h5 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729446&amp;idx=5&amp;sn=2c36cca9b5d26f52a0ccdeda1f848e8f&amp;chksm=871b2f98b06ca68e2a09d7e807b0d31485e9f2ffcd0e73967e4b24bba0d39d805713a8e4d3f1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">学界 | 一文综述所有用于推荐系统的深度学习方法</a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735119&amp;idx=1&amp;sn=e8712a9dd32ada0fb9ee8556198f69a0&amp;chksm=871ac671b06d4f67fd4db182ff7a4904f985a3ee58fd67ef1d355152a4858f05d94c2c1e74fa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">使用深度学习构建先进推荐系统：近期 33 篇重要研究概述</a></li>
</ul>
</li>
</ul>
<h4 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715438&amp;idx=2&amp;sn=3dafb301ec8103fce7ad88d6039cb3ad&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">业界｜谷歌 TensorFlow 的一份全面评估报告：好的坏的及令人讨厌的</a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725468&amp;idx=1&amp;sn=84a2dcc945ca36fc52153c8542fcb62d&amp;chksm=871b1822b06c91340c4e4a228e2c06899070aa45e6198d8ef9c048d6e2132b397b6362acc0d3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">初学者怎么选择神经网络环境？对比 MATLAB、Torch 和 TensorFlow</a></li>
</ul>
</li>
</ul>
<h4 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725088&amp;idx=2&amp;sn=e7220bf6afc52152df0762f5c170aebe&amp;chksm=871b1e9eb06c9788b71ae4d38d8cb48c8a6e1bc8c7f649040e4cebf19a2566b2506f4474b8e9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">业界 | 剖析用于深度学习的硬件：GPU、FPGA、ASIC 和 DSP</a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727205&amp;idx=1&amp;sn=986dee7d9cbba51690207ad2e81742c2&amp;chksm=871b275bb06cae4d64cff66f38790b09699474938e6807127eb0ffc1ebfd02de1dd7b9a42894&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">神经形态计算与神经网络硬件最全调查：从研究全貌到未来前景</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729894&amp;idx=1&amp;sn=e8c3b919fba8a23ee9cd882ee91b0af2&amp;chksm=871b29d8b06ca0cef76cf5043093e03e8b115f6c1eaf20d4ca03dd98c898167e3a26987cedaa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从 GPU、TPU 到 FPGA 及其它：一文读懂神经网络硬件平台战局</a></li>
</ul>
</li>
</ul>
<h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728837&amp;idx=1&amp;sn=5531c6fa3d3f03f6283b3d525b9a738b&amp;chksm=871b2dfbb06ca4ed42737c4fca972c37fad3e696744ca4f76da62c107135a8018e266ab1f4c3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从浅层模型到深度模型：概览机器学习<strong>优化算法</strong></a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732492&amp;idx=1&amp;sn=4fa1405edb2c683b9e27a2c1e5a733f2&amp;chksm=871b33b2b06cbaa41a5e6c3c051f163b7802e0fe9c383c3b908eefdddbc6b6b34dc197b664d3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">综述论文：当前深度神经网络<strong>模型压缩</strong>和加速方法速览</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734359&amp;idx=2&amp;sn=042387d99b309f0547babc5217fa6294&amp;chksm=871b3b69b06cb27fd2ee156ee0b0b9cab81e6afdfde170c4adf40ca62dd655302f342d1c5641&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 从修正 Adam 到理解泛化：概览 2017 年深度学习<strong>优化算法</strong>的最新研究进展</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734959&amp;idx=1&amp;sn=717b747cec3fdc7a4b9aa08c5f1195af&amp;chksm=871ac511b06d4c0734c5d66953c66210206693be9a6f7d5346a9c86cc801b3a0559a3700fc8f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文概览深度学习中的五大<strong>正则化方法</strong>和七大<strong>优化策略</strong></a></li>
</ul>
</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725146&amp;idx=1&amp;sn=33642c5ae292a6b0a20a3a26beb1008a&amp;chksm=871b1f64b06c9672435baf978c8089cc0b8d34c63701c2fbf36f8a334dc83b1a3ed4d634f34e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从强化学习基本概念到 Q 学习的实现，打造自己的迷宫智能体</a><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726814&amp;idx=1&amp;sn=7b5efae26f862b286cfc462eae133c75&amp;chksm=871b25e0b06cacf68cf70b171e63f2373990cb7a8766e85088be2275b61262e5b185853b551b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">回归、分类与聚类：三大方向剖解机器学习算法的优缺点（附 Python 和 R 实现）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728960&amp;idx=1&amp;sn=8b9e10a0c4170a136658262253c7b993&amp;chksm=871b2e7eb06ca7681edd3243ade430853a4b83c94b323f903aa925e3a7b8a53a17bb7e69238a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">基于 TensorFlow 理解三大降维技术：PCA、t-SNE 和自编码器</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729598&amp;idx=1&amp;sn=7d68cc7a009d616545d7afd983ee9c63&amp;chksm=871b2800b06ca116eaf8236cdeb8a3e56c1169a8629b9a72a363121a695d45a7c2c06cbddecf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂遗传算法工作原理（附 Python 实现）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729755&amp;idx=1&amp;sn=a5849c082ed099abf931e004339cef4d&amp;chksm=871b2965b06ca073ca5ed037622a0ddf88c327177786d0d8433d56c78af3d63d3e71995c0940&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">10 大深度学习架构：计算机视觉优秀从业者必备（附代码实现）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730721&amp;idx=1&amp;sn=171ed5893d5f09e1f4cc689ffe7e794b&amp;chksm=871b349fb06cbd8945df02b3f601f9c4384d3132f900b87a4a64f92b864e7230edfb4c11aebe&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从算法到训练，综述强化学习实现技巧与调试经验</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735018&amp;idx=1&amp;sn=8bf89833ed7984c245cb913c2ae3cb8a&amp;chksm=871ac5d4b06d4cc2f7244dd2fea21e2999c158b19f3572f456ed2dd09d8fbdc6658df379f7cf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2017 年度盘点：15 个最流行的 GitHub 机器学习项目</a></li>
</ul>
</li>
</ul>
<hr>
<h3 id="人工智能从入门到进阶，2016年机器之心高分技术文章全集-链接"><a href="#人工智能从入门到进阶，2016年机器之心高分技术文章全集-链接" class="headerlink" title="人工智能从入门到进阶，2016年机器之心高分技术文章全集 链接"></a>人工智能从入门到进阶，2016年机器之心高分技术文章全集 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722778&amp;idx=1&amp;sn=941eb40c57654222b3e883affa3d08b0&amp;chksm=871b15a4b06c9cb27521a6d22fa1546947c16cd1d620a8816ec37ea3e61bc7f9331ef648f600&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">链接</a></h3><h4 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721853&amp;idx=3&amp;sn=f9f0048cccefbf9c00dc94f2a71c7d00&amp;chksm=871b0a43b06c8355376d1bc897b4f3585b4a129d77a9e5b025f4c344f2ef264c05133cff7682&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习资料大全：从基础到各种网络</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719733&amp;idx=1&amp;sn=2fce6d18e8fcae9b805d4652a7c702e9&amp;chksm=871b018bb06c889d339f34b192579f2e7f97e2f7b64cbe3ccd85ec7b3ed9022178ed5a150359&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">30个深度学习库：按Python和C++等10种语言分类</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721418&amp;idx=1&amp;sn=71b28bce48b70f9fa30929db29e685e1&amp;chksm=871b08f4b06c81e24d16ef66265e142de1fd8a18fd872da99a2e70c4e10062ac41575ec0e382&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2016年不可错过的21个深度学习视频、教程和课程</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721817&amp;idx=4&amp;sn=a2e9f4c19f92fd95040f4b13935c6681&amp;chksm=871b0a67b06c837108989bc0cd0b2dc06ce2c0009190f1ab6cfd38bca5f6d08d6b56e776d811&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">程序员实用深度学习免费课程:从入门到实践 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721817&amp;idx=3&amp;sn=f03d9c31c8db61c7d980b0137c9e2da3&amp;chksm=871b0a67b06c8371ddaa7a49f56ee7b5b9725f52e0a3a930b9d424e7d6fae0ca24bca7e319af&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">9本不容错过的深度学习和神经网络书籍 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719393&amp;idx=1&amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习专业名词表：从激活函数到word2vec </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721717&amp;idx=2&amp;sn=6a58289f9f65448339a845f88f168088&amp;chksm=871b09cbb06c80dd7b790d34e3627eaf3f330b8670350ee5ad3718bc36e3d5f3f30581fe8453&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2016年年度十大Python库盘点</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650716071&amp;idx=1&amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2010-2016年被引用次数最多的深度学习论文 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722147&amp;idx=1&amp;sn=0584e654c66f694502ff2918dcbc3ca1&amp;chksm=871b0b1db06c820bc8396e6b4ab1ced5f0bada892385eabed7fb581c5b911162bfe326bc36a0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">自学数据科学&amp;机器学习，19个数学和统计学公开课推荐 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721121&amp;idx=5&amp;sn=5af0fb9465ce9345c017adfb1d0c9796&amp;chksm=871b0f1fb06c8609b8b9d792b222b16f7b6fa4479a6d426663ab03cf1ebebd5209080bebe48b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio新书《Deep Learning》中文版开放预览（附PDF下载链接） </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715120&amp;idx=2&amp;sn=108bc0f1bac2deb0b423a2587ebe306a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">数据科学家应该掌握的12种机器学习算法（附信息图）</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720472&amp;idx=1&amp;sn=a0d8f835a300fb5d0c4a3a224cc17924&amp;chksm=871b0ca6b06c85b0461163c3043bf45ab6d58dd57263ce381646ba71842608785d97e00014f6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从入门到研究，人工智能领域最值得一读的20份资料</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715104&amp;idx=3&amp;sn=2f3c9a625519f6265a3ba755697cad56&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">关于数据科学的十本好书 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719875&amp;idx=1&amp;sn=f1030f9dbd1d8080585b4d3bba3a9b73&amp;chksm=871b02fdb06c8beb2dc94e3f69a76fa56aafb3c310d03e53f3aca2167a27a9e115fbb6b0bfe2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">哈佛大学九大自然语言处理开源项目 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718688&amp;idx=1&amp;sn=c473fd7fe002fe6b8b5b917c432daf27&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">ICML 2016演讲视频：数百个演讲带你读懂机器学习</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721717&amp;idx=1&amp;sn=470fef6589c81afa913b2e0572996f92&amp;chksm=871b09cbb06c80ddc4c21fc55511b30c6e1a0461c9f1c0588ce9dd484d6216d819e949a1a259&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio研究生科研指导演讲：解读人工智能全貌和下一个前沿 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720663&amp;idx=2&amp;sn=d06c7a2e8cdde84901ffd8335a775737&amp;chksm=871b0de9b06c84ff467a63042b17ad1622224fc1ab84597ab80b64ab0049c4f4b09cabc3d7dc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yann LeCun演讲：人工智能的下一个前沿——无监督学习</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720780&amp;idx=1&amp;sn=39ac663849c90ab31d3dd04013f7e646&amp;chksm=871b0e72b06c8764becc21ecb10ece2b7d285f72a85cec79920967abe53bdbf7a16522623caf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">今年GitHub排名前20的Python机器学习开源项目</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715438&amp;idx=3&amp;sn=2c2a6e4dfda2307d818dcab385ef6727&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习工程师和数据科学家最应该读的16本书 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722365&amp;idx=4&amp;sn=af6b4a85b4e447d0d54e71399f6d8e93&amp;chksm=871b1443b06c9d55f1678dbe89573c1fcb31758b12b6b992cb63be11b7b1dc6b9f1874cee0bc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">任何阶段的学习者都适用的参考：机器学习领域书目全集 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718578&amp;idx=1&amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio深度学习暑期班学习总结，35个授课视频全部开放</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722318&amp;idx=2&amp;sn=f03f56fb91bfd5fe393268f74435349f&amp;chksm=871b1470b06c9d661a72d727c76e7f75a8cf57c17c97542cc1c8b330b8969b1fd2748722fb95&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Andrej Karpathy CS294课程总结：可视化和理解深度神经网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719828&amp;idx=2&amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Geoffrey Hinton最新演讲梳理：从人工神经网络到RNN应用</a></li>
<li><a href="">吴恩达NIPS 2016演讲现场直击：如何使用深度学习开发人工智能应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721406&amp;idx=1&amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">NIPS 2016最全盘点：主题详解、前沿论文及下载资源</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719377&amp;idx=1&amp;sn=114e536fc2ca22edcb6ad6ceb332228e&amp;chksm=871b00efb06c89f953e6d7320a7f5fed54e062687425c1dee8166b16704fef23f4eb53b1a473&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福大学周末学习盛宴：12位大牛解读深度学习</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719367&amp;idx=1&amp;sn=1cd2e133a56eb3e841e98ab837086df8&amp;chksm=871b00f9b06c89eff783040ad6b30152440e628908fc478b9b8cbce991f914f94237e1333fb1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">提升深度学习模型的表现，你需要这20个技巧</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720407&amp;idx=1&amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">TensorFlow开源一周年：这可能是一份最完整的盘点 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718160&amp;idx=3&amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">五大主流深度学习框架比较分析：MXNET是最好选择 </a></li>
</ul>
<h4 id="基础介绍文章"><a href="#基础介绍文章" class="headerlink" title="基础介绍文章"></a>基础介绍文章</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719723&amp;idx=3&amp;sn=0338d470c8668aa912aeebc18c1ced0e&amp;chksm=871b0195b06c8883bab39807043824dcec576180f006226672da649459e7c2de0ecd3fd98c6e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2016伦敦深度学习峰会观感：人工智能面临的三大难题</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722085&amp;idx=1&amp;sn=14a9cc3610e0de25587a707f554939f0&amp;chksm=871b0b5bb06c824da313d70525cca67c9c7417951174455f1e27d9431af132e914c5ab4f6be5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2016机器学习与自然语言处理学术全景图：卡耐基梅隆大学排名第一 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720407&amp;idx=3&amp;sn=f8484e3aa14bfe9b925d75bb9acc52e2&amp;chksm=871b0ce9b06c85ff78b2ec6a708e0a9128027a8e862a08a2fca38a17d1aa117f48b27402f133&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2016年美国机器人路线图出炉，最新机器人产业盘点 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720758&amp;idx=3&amp;sn=0d7e70cfd3624296fc8aac4944a359dc&amp;chksm=871b0d88b06c849e71808681107f2b695233bdd37d7a79249cad5b2721f4285ed50577bee89d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一张图看懂全球Bot布局 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715580&amp;idx=1&amp;sn=cc67a90fe35702732f1a67e3e59d80f6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio：深度学习崛起带来人工智能的春天 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718943&amp;idx=1&amp;sn=258117d392ca1bfc37d6496992da5eae&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">神经网络架构演进史：全面回顾从LeNet5到ENet十余种架构</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719010&amp;idx=1&amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Andrej Karpathy：计算机科学博士的生存指南 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721559&amp;idx=3&amp;sn=98a74c48397f8a8d9166a3bf0b74fb4f&amp;chksm=871b0969b06c807f90e72c890c4b23308501f46c7315823c3fee1c423817ed81626d3da9d711&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">贝叶斯神经网络简史</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720407&amp;idx=2&amp;sn=86603b0276580e9e969e78cac606fe3c&amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">百度首席科学家吴恩达刊文：人工智能的能力和不足 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721378&amp;idx=1&amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">高盛百页人工智能生态报告：美国仍是主导力量，中国正高速成长</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720663&amp;idx=1&amp;sn=ffadef6ce7d0e2d60e09c0c8bdc366c5&amp;chksm=871b0de9b06c84ffad7621ec0b3e7578d085d9557f029067d978a286e22ff5e67e0b98ed209b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">伯克利教授Stuart Russell：人工智能基础概念与34个误区</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720174&amp;idx=2&amp;sn=cb195f4dfda478510479eba5dc53fc99&amp;chksm=871b03d0b06c8ac674234d2bcea8515c2720bb502bcb281024b71ebaf4864e1e6fad863d3ebd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">初学者必读：解读14个深度学习关键词</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720335&amp;idx=3&amp;sn=7552135b320b24ce9b273423187b5a78&amp;chksm=871b0c31b06c852753124d9962aff43c049f2283dcfa78cc8ca51289aa0dd2db53d88b2c2e96&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">智能时代每个人都应该了解：什么是深度学习？</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720553&amp;idx=2&amp;sn=8f77792079e14219da4006247d738652&amp;chksm=871b0d57b06c84414a164a210ac350e6fc22af6ba06c2604c749776431fef53731c7f40439c7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">CMU机器学习系负责人：人工智能与人类的未来是共生自主 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715759&amp;idx=2&amp;sn=d005ca89ba3b0bd2eae4b7677cbb8be2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">CMU教授邢波：人工智能的路径、方向与未来 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650716455&amp;idx=2&amp;sn=48da4b101ef293de0f627aeb3ba3231b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从供应链优化到差异化定价：机器学习十种方式变革制造业 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721938&amp;idx=1&amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">对比深度学习十大框架：TensorFlow最流行但并不是最好 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721480&amp;idx=3&amp;sn=0ee6a881f01d8d1bee16d2042ac93e5f&amp;chksm=871b08b6b06c81a027a5b5490f1c9decf3d70002e1f1e1869c25c7a12657f9cfa518b855cf9b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">当AI遇上AR ——从微软HPU说起 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720922&amp;idx=5&amp;sn=110bf38376c42b55d95521dd04944828&amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">洞悉AlphaGo超越围棋大师的力量：机器之心邀你一起强化学习</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719022&amp;idx=2&amp;sn=6efb98d3650bd963122744b14b09e1d9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">东南大学漆桂林教授：知识图谱不仅是一项技术，更是一项工程 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717374&amp;idx=1&amp;sn=14c7af07c4d6859a7cb8d7a8650d5825&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">人工智能全局概览：通用智能的当前困境和未来可能 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722118&amp;idx=1&amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">访谈百度IDL林元庆：百度大脑如何在人脸识别上战胜人类「最强大脑」 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720302&amp;idx=4&amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">TensorFlow 生态系统：与多种开源框架的融合 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719511&amp;idx=2&amp;sn=ef5f5c1d8d70cc81cdcd2c6fde36f695&amp;chksm=871b0169b06c887f46d4b87987bd58881875f352c3bdb5d8c2e39d9898b6bcac8b7c0c31783d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Kaggle创始人问答：深度学习会淘汰其他的机器学习方法吗？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721755&amp;idx=1&amp;sn=61837dc0127c1c829522e1772959a0dd&amp;chksm=871b09a5b06c80b3d89848a140f13519bf2c3e264724a8604603751079f43252365e5f40dadd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器之心年度盘点 | 从技术角度，回顾2016年语音识别的发展</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719333&amp;idx=2&amp;sn=ba2491a4c22da7512d9add55c1ac50ee&amp;chksm=871b001bb06c890d71a688cd127557913694240b6a81ea1681552677d63cec27fcd45570dc4d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习的基本局限性：从一个数学脑筋急转弯说起 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721777&amp;idx=3&amp;sn=20cf64536919147639b2f5cbad38df0f&amp;chksm=871b098fb06c80995100a9afee640203b14f5429f72ee9259b01b6c87d72396beeecdea99144&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">人们都在说人工智能，其实现在我们真正做的是智能增强</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717606&amp;idx=4&amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">人工智能、机器学习、深度学习，三者之间的同心圆关系 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722126&amp;idx=1&amp;sn=00b5c6ed7e4c576c8be3eae1dc348cfe&amp;chksm=871b0b30b06c8226b163198b78ad40b52715509d3b36f0774670d6e0e284378cc3bdeca42d4a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">R vs Python：R是现在最好的数据科学语言吗？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722239&amp;idx=3&amp;sn=aa556d22c8dc71195175930fda1655d0&amp;chksm=871b0bc1b06c82d70e62081d87c1e75291ea15f631aff5c0a5d03de41ffbbcc4be650e63b014&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福NLP团队介绍交互式语言学习：从语言游戏到日程规划 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720597&amp;idx=2&amp;sn=815b3426c4855e446e4aa118abdee0d6&amp;chksm=871b0d2bb06c843da11f16f85510da8cb398542c82a80a8822ac9f78beb24aaf58f066eaaed2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福大学副教授Reza Zadeh：神经网络越深就越难优化</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=402228099&amp;idx=1&amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">神经网络和深度学习简史（三）：强化学习与递归神经网络</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=402552632&amp;idx=1&amp;sn=694a4a327a79c4efeeb4db15b3ff4a28&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">神经网络和深度学习简史（四）：深度学习终迎伟大复兴 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717977&amp;idx=2&amp;sn=705d47688adadcdce6e09a81e3381e2d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习技术在股票交易上的应用研究调查</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721378&amp;idx=4&amp;sn=cb49818959281909d8878bea5b34e837&amp;chksm=871b081cb06c810a0075a475beeecbbe41a915679f05d629aa2e4d3a38da45e0899a764a98be&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习十大飙升趋势 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=401846516&amp;idx=1&amp;sn=ed76da1e8f99c604957c8889692de884&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习入门，以及它在物联网和智慧城市中的角色</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720765&amp;idx=3&amp;sn=a9ec5e451cc7e46ab254b663ec78c3b6&amp;chksm=871b0d83b06c8495b977ba6f82c3aa5974a6d2066e3fec63f9fc33e7e0766a2008804795895e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">服务器端人工智能，FPGA和GPU到底谁更强？</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721102&amp;idx=1&amp;sn=347d3a3b5fd136df7bc51fb67948fd30&amp;chksm=871b0f30b06c86263fd2d51665aaa5e81d1e3cbc0044ed71ab0f74238a461ba0e75490a04af7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Science「机器人子刊」创刊号，五大研究解读机器人领域最新进展 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718975&amp;idx=1&amp;sn=2b0ccf0c746e6f10707e5357168d51d6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">西红柿还是猕猴桃？一个案例帮你入门机器学习</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715201&amp;idx=1&amp;sn=d7ad8c79bf060875b6247d634c52449b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">详细解读神经网络十大误解，再也不会弄错它的工作原理 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719646&amp;idx=2&amp;sn=3f84e8af0ca03476eb843f57b497465e&amp;chksm=871b01e0b06c88f6c77601db4a1d224a5007ba306eac7d0522c0b973ca9c3d57c4fabf57a5c4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">基于图的机器学习技术：谷歌众多产品和服务背后的智能</a> </li>
</ul>
<h4 id="技术起点"><a href="#技术起点" class="headerlink" title="技术起点"></a>技术起点</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719723&amp;idx=4&amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">10种深度学习算法的TensorFlow实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719794&amp;idx=2&amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">数十种TensorFlow实现案例汇集：代码+笔记 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720367&amp;idx=2&amp;sn=d71e1e6550faece1cb5fb58bd7c919d9&amp;chksm=871b0c11b06c8507d765a781b3ff49c1755deba7f12f36763b468aa23dfafccd768f59538004&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习入门必备：如何用Python从头实现感知器算法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718527&amp;idx=1&amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">ACM 最新月刊文章：强化学习的复兴</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720174&amp;idx=4&amp;sn=da197d35bf9b5ac59b9ffb8e442264f0&amp;chksm=871b03d0b06c8ac622e5ff2b83c786b7fb34d49b6186f1d9f1964b28e31c1e0d7b2ac3863afc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">人工智能开发者的入门指南</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717691&amp;idx=2&amp;sn=3f0b66aa9706aae1a30b01309aa0214c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从入门到精通：卷积神经网络初学者指南</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718466&amp;idx=1&amp;sn=016f111001e8354d49dd4ce279d283cd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习敲门砖：任何人都能看懂的TensorFlow介绍 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720463&amp;idx=2&amp;sn=50d88169778ec31a1e1e2d801325005d&amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind提出的可微神经计算机架构的TensorFlow实现 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718229&amp;idx=4&amp;sn=f47990a661e1522a5794d6334a334830&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">RNN 怎么用？给初学者的小教程</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=401970614&amp;idx=2&amp;sn=479370f70613e431d35c752139c0b602&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习教程：从感知器到深层网络</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721559&amp;idx=4&amp;sn=950d87934d39712fab6164d3d2a37be5&amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">OpenAI 的 PixelCNN++实现：基于 Python的实现 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719828&amp;idx=2&amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Geoffrey Hinton最新演讲梳理：从人工神经网络到RNN应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717557&amp;idx=1&amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">官方指南：如何通过玩TensorFlow来理解神经网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720174&amp;idx=1&amp;sn=d770ab6ccbf25c6569d002472daf1b3b&amp;chksm=871b03d0b06c8ac6c16a6e37e1dcc2a5f490e4ab5a21b82b76a2a41d3a1d35d76a6a3d21fdc3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一篇文章带你进入无监督学习:从基本概念到四种实现模型</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721979&amp;idx=2&amp;sn=146a34534414fb4842398cac62cd201a&amp;chksm=871b0ac5b06c83d3eeb71d5b39d74f9d5648d7e334039cf6d6a3d42b18856abc47ba229b8890&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">NIPS 2016上22篇论文的实现汇集 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721979&amp;idx=1&amp;sn=82ccf18462e569d43d72736aef57177a&amp;chksm=871b0ac5b06c83d30e65fcd1344bf4b9773281af6cd58f4d3e6709f24d66f6c2bbbfaddb8ccf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习初学者入门实践：怎样轻松创造高精度分类网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718717&amp;idx=1&amp;sn=85038d7c906c135120a8e1a2f7e565ad&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">解决真实世界问题：如何在不平衡类上使用机器学习？</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717628&amp;idx=1&amp;sn=a6f1b35f8168f1bc842ca36bb3a69368&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">卷积神经网络架构详解：它与神经网络有何不同？</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717709&amp;idx=2&amp;sn=2bff1e56bc75d65e178476ea9a93b2c5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">LSTM和递归网络基础教程</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718717&amp;idx=2&amp;sn=9cf62b1b684f5dea3c735d1413a50689&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">门外汉如何使用谷歌的Prediction API做机器学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718597&amp;idx=2&amp;sn=98c141c6d73eb62a0f3f8aa2a8231b66&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">NVIDIA趣味解读：深度学习训练和推理有何不同？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722126&amp;idx=4&amp;sn=96b2fa1fe3fc858d415ddddf2ac3f8e5&amp;chksm=871b0b30b06c82262fec886bc76b0427542dcf8b1fb4bae62d851d032e4fc22d247e981f263f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何利用 Python 打造一款简易版 AlphaGo </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715104&amp;idx=2&amp;sn=f6ba338c02f8e08c7821b4ecd5a527e9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何用图像识别技术来变革商业？这里有份操作指南 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719093&amp;idx=4&amp;sn=d852318f6b3adb5ef7730def66fb0a93&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">MIT生成视频模型，预测静态图片的未来场景 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720257&amp;idx=1&amp;sn=92ac1424c5880a406c1a00558359792b&amp;chksm=871b0c7fb06c8569e23927623aa3c98af8a3377069ba6cd11a0acecb54cd8ce7896e29238b97&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">EMNLP 2016干货：从原理到代码全面剖析可用于NLP的神经网络</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718504&amp;idx=1&amp;sn=ba884ec5bd9dd93b77c85f91d8371056&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">使用机器学习翻译语言：神经网络和seq2seq为何效果非凡？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720758&amp;idx=1&amp;sn=3004c425e0d427f4900a182d74bed31d&amp;chksm=871b0d88b06c849e951469ae1ed54e5f66074d6322eb6681c85727bb8199154709c04c48c034&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">神经网络快速入门：什么是多层感知器和反向传播？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718853&amp;idx=4&amp;sn=4f33d503f1602e608b34c6cda4e55dad&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">神经网络中激活函数的作用 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720582&amp;idx=2&amp;sn=06076c800c912622d8fa42665d7de1fc&amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719294&amp;idx=1&amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习漫游指南：强化学习概览</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717969&amp;idx=1&amp;sn=712e4880e63db42bcb4db5ba06c9856d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习与神经网络全局概览：核心技术的发展历程 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=402261356&amp;idx=1&amp;sn=f66ee62b002b8a9879d3c428f846e440&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">最全的深度学习硬件指南 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719118&amp;idx=2&amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">主流深度学习框架对比：看你最适合哪一款？ </a></li>
</ul>
<h4 id="继续进阶"><a href="#继续进阶" class="headerlink" title="继续进阶"></a>继续进阶</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720132&amp;idx=1&amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">40年认知架构研究概览：实现通用人工智能的道路上我们已走了多远？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721682&amp;idx=1&amp;sn=6bdbf5739bb312449cb60cb6679f98d2&amp;chksm=871b09ecb06c80fa59dba741fb79e44021d5ae16f67488c38b3fb477235a203931da86c829bc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">第四范式联合创始人陈雨强：机器学习在工业应用中的新思考 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719971&amp;idx=2&amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">词嵌入系列博客Part1：基于语言建模的词嵌入模型 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720050&amp;idx=2&amp;sn=9fedc937d3128462c478ef7911e77687&amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">词嵌入系列博客Part2：比较语言建模中近似 softmax 的几种方法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720074&amp;idx=2&amp;sn=183fc6285835a48ae7c6bbcce228b063&amp;chksm=871b0334b06c8a22b072f61d4f914210468db7df36a1c6586bd9b6bf3fc6d9f821101d5254c0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">词嵌入系列博客Part3：word2vec 的秘密配方 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718853&amp;idx=1&amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从分割到识别，全面解析Facebook开源的3款机器视觉工具 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718786&amp;idx=1&amp;sn=58e6cdf2ffb0f47eb831e0cd623ce0e1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从硬件到软件：OpenAI 解读自家的深度学习基础架构</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719694&amp;idx=1&amp;sn=93c5aa0b6dd9cdb35c8b8186ce70afff&amp;chksm=871b01b0b06c88a6ee9c3264e67b3e3256f007c4046fefb1d003f91ada71d00547f91b48ca21&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">分布式深度学习：神经网络的分布式训练</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720463&amp;idx=4&amp;sn=ddffc71e49002f731ada533cf05cc84d&amp;chksm=871b0cb1b06c85a73aeb3562836c2ff15357417ce7106ceed06f8987b1cdb70a990895592e9d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Embedding 新框架模型：Exponential Family Embeddings </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719294&amp;idx=3&amp;sn=d23a6d7c03732f7218f70447336801bd&amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">FPGA vs. ASIC，谁将引领移动端人工智能潮流？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717977&amp;idx=3&amp;sn=e07366137aab6694c3d3d4a311ed6c54&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">概述性论文：卷积神经网络的近期研究进展 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715279&amp;idx=2&amp;sn=fd25ed0539b7bf8e79f5e99eea47b889&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《Nature》 封面文章：人工智能引发材料科学变革 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721922&amp;idx=3&amp;sn=b7af3daa477955e0466c521fd45a23e6&amp;chksm=871b0afcb06c83ead80f3cc7e2e650ba441d4068ecd10532272fc4c0b88aadf8b9b24fa8cc19&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">概述论文：迁移学习研究全貌 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721602&amp;idx=2&amp;sn=f18e2d3a23dec485350611651e571031&amp;chksm=871b093cb06c802aecc953e10c6bf5a14784ce3bad2c82170262ed6d6d7daedfcea9cceb804d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Andrej Karpathy：你为什么应该理解反向传播 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721284&amp;idx=1&amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">GAN之父NIPS 2016演讲现场直击：全方位解读生成对抗网络的原理及未来</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719228&amp;idx=2&amp;sn=b3ccd8c77c2ef81369c02b85de013038&amp;chksm=871b0782b06c8e94e88ce927f8357a6637b051c9f2ace9dbadea84c77b1b8ca0fec7efdb7448&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Google Brain 讲解注意力模型和增强RNN </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719723&amp;idx=2&amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌Magenta项目是如何教神经网络编写音乐的？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721644&amp;idx=4&amp;sn=51ff444c29797ea83f55f47c694b2e84&amp;chksm=871b0912b06c8004a9d5cf461a496b693f5c5010896a0b32f1ae5ede9ab32ce2de4b2a8f37b0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">基于MXNet 的神经机器翻译实现 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721121&amp;idx=3&amp;sn=e21d84cb34b75b744a31fb27c3af8528&amp;chksm=871b0f1fb06c8609de11c76854c1ad9582aece4b79eed6d94b588498109d78a2c62ffe69e02c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">2016深度学习重大进展：从无监督学习到生成对抗网络</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715145&amp;idx=1&amp;sn=84ddd1cbb981e260e49100ec39d01663&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习遇上基因组，诊断疾病和揭示深层生物原理或迎来突破 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719794&amp;idx=3&amp;sn=a64c739eab79f95c85685db7b06d3649&amp;chksm=871b024cb06c8b5aa3e8b3ddd59de64dcf32f05b068bda1fa6c9400a491de6f63b1ca4a81d14&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">King+Woman-Man=Queen:用基于Spark的机器学习来捕捉词意</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721817&amp;idx=2&amp;sn=110962b592985cb01216feafe0d8510e&amp;chksm=871b0a67b06c8371b96cff1675cc762f4677dc02a94d985c21c28ba8af1c1afccca64080e41f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">初学者必读:从迭代的五个层面理解机器学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722553&amp;idx=5&amp;sn=81228e1becc1895699fd5a87e120be05&amp;chksm=871b1487b06c9d915136b64c14800f60af13ac956060716b654b1a8944beffe0947b036cce47&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">轻量级Matlab深度学习框架LightNet的实现 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650714956&amp;idx=3&amp;sn=de8326724feb96cd5891e6198226a365&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何基于机器学习设计一套智能交易系统？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718229&amp;idx=1&amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何在TensorFlow中用深度学习修复图像？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720420&amp;idx=2&amp;sn=179fa42fafe685265fef3b88f186fd62&amp;chksm=871b0cdab06c85cc1500ab14605fe2848188bb55cebd0cfdb1af6c6b1e0c1d2f2b3cf886394a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习中的并行计算：GPU、CUDA和实际应用 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720922&amp;idx=5&amp;sn=110bf38376c42b55d95521dd04944828&amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度解读AlphaGo胜利背后的力量：强化学习</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718429&amp;idx=1&amp;sn=46214968459af95e85efe12b8a26b11b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">英伟达自动驾驶技术解读：用于自动驾驶汽车的端到端深度学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720663&amp;idx=3&amp;sn=d9f671f77be23a148d1830448154a545&amp;chksm=871b0de9b06c84ffaf260b9ba2a010108cca62d5ce3dcbd8c98c72c9f786f9cd460b27b496ca&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度解读最流行的优化算法：梯度下降 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718391&amp;idx=1&amp;sn=99fd9d942768706e93f7f1aa744ea4b7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Science：斯坦福大学用迁移学习预测非洲贫困状况 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720823&amp;idx=4&amp;sn=2ed3964e94e3076e060e48a4708faa2a&amp;chksm=871b0e49b06c875fd2ead27692e8c2b35ac38724adc0215183a434283f4f869fde11e7036c5e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">用 Word2vec 轻松处理新金融风控场景中的文本类数据 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720969&amp;idx=1&amp;sn=d5723c205f594616932624684d3a1327&amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Science：实用量子计算机已近在咫尺 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720561&amp;idx=3&amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习硬件架构简述</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718634&amp;idx=1&amp;sn=1220e691541c34281c64655a01793cb0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度学习系列Part2：迁移学习和微调深度卷积神经网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719170&amp;idx=1&amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">图文并茂的神经网络架构大盘点：从基本原理到衍生关系</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717143&amp;idx=1&amp;sn=4eb48040935380a7c87d18efea403d58&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">为你的深度学习任务挑选性价比最高GPU </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719511&amp;idx=3&amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718229&amp;idx=3&amp;sn=bb2fd16046e6e08bea612a5f7fd0f2dd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">用于视觉任务的CNN为何能在听觉任务上取得成功？ </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722208&amp;idx=1&amp;sn=52397806416c7d7f570d5c8fc9ecb96e&amp;chksm=871b0bdeb06c82c85c03e7a07a3c71d9258969470ed8b70eeff850db98a0b7b98cda6fe787ee&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">自然语言处理领域深度学习研究总结：从基本概念到前沿成果 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720780&amp;idx=3&amp;sn=bac6cbe4972c236ee0bcdbf76139fa98&amp;chksm=871b0e72b06c8764837fdf6f6cc8b01361b883c0a86bb253163cde5f380beb2e413d855d84b9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">专访谷歌Jeff Dean：强化学习适合的任务与产品化应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720302&amp;idx=1&amp;sn=c88634da158f36db23b9dc7d0dc550ad&amp;chksm=871b0c50b06c854694984e193f289deb51a5efe71f53223dc37feb70509fd957c8af5bb61ab3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">重磅论文：解析深度卷积神经网络的14种设计模式</a></li>
</ul>
<h4 id="前沿研究"><a href="#前沿研究" class="headerlink" title="前沿研究"></a>前沿研究</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721777&amp;idx=4&amp;sn=a55d6807a8e65059c426876c623f655b&amp;chksm=871b098fb06c80990a07affb5ecae55b496ca5e3a8b42e686d287b3bd308235c04a2d29c9a28&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">并行运算，Facebook提出门控卷积神经网络的语言建模</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718798&amp;idx=3&amp;sn=6ec32a0f0f09b8f193c578ee0af9d7ae&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">FAIR与微软研究院合著论文：通过虚拟问答衡量机器智能 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717728&amp;idx=2&amp;sn=228e5905d7cd6fd175fc596e2d511eed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">FusionNet融合三个卷积网络：识别对象从二维升级到三维 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720234&amp;idx=3&amp;sn=1fe8cce38750ad900e31109e4358ee0a&amp;chksm=871b0394b06c8a826c9af5302dc38ccc8279db3288b573227d0547d27a720aec5dba2592e0e6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌新论文提出神经符号机：使用弱监督在Freebase上学习语义解析器 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720399&amp;idx=4&amp;sn=3dcdb45229af883cd646985fe0964537&amp;chksm=871b0cf1b06c85e7eeebdb857bcc95b456e5f5ccdb597c9739d6b2fda96069bc1fc53cb32b6b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Google Brain与OpenAI合作论文：规模化的对抗机器学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721644&amp;idx=5&amp;sn=55b63682dc248b842e9229f6db251c6e&amp;chksm=871b0912b06c800437eedb3fab4ca179a8e83aac4c2879b218974a26e26f79cf6829aa6f4dfd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌新论文：使用生成对抗网络的无监督像素级域适应 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720367&amp;idx=3&amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌ICLR 2017论文提出超大规模的神经网络：稀疏门控专家混合层 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718466&amp;idx=3&amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌论文：使用循环神经网络的全分辨率图像压缩 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722239&amp;idx=4&amp;sn=3544eee8b2bf5eeab1ae852ba9fde64c&amp;chksm=871b0bc1b06c82d74fa57cbcb0d9f6178a78d474c6bfe93db174dd0c8f580272e398006b0f14&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌新论文提出适应性生成对抗网络AdaGAN：增强生成模型 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718943&amp;idx=4&amp;sn=f93b540a0b28100a6912e916d2ad1ac0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌技术论文：用于YouTube推荐的深度神经网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719170&amp;idx=3&amp;sn=5c9dd730e1454335efdae14b24cd2053&amp;chksm=871b07bcb06c8eaa7e4e210727f03214ddf633513522828ac2d3c5a339ee50486d5f32833566&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌与微软合著论文：由知识引导的结构化注意网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719594&amp;idx=2&amp;sn=b8398c3059b23babb02487baf2cc738f&amp;chksm=871b0114b06c8802ed86e1bc0a17fb33d79500962206eb480bdf023b25c753a7535bb877df2b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌深度解读：机器人可以如何通过共享经历学习新技能 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719099&amp;idx=2&amp;sn=52807674a2235e7ed8065a165427e1d6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌NIPS 2016提交的8篇论文：从无监督学习到生成模型 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718429&amp;idx=2&amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌DeepMind论文：使用合成梯度的解耦神经接口 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722118&amp;idx=2&amp;sn=42199ff21f3b06912e487de2c83eca1b&amp;chksm=871b0b38b06c822ef121554a1f9bf23ef49e15cbbe6d84ac11c8e68eb377746a24809aa8e34c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌提交ICLR 2017论文：学习记忆罕见事件 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722472&amp;idx=4&amp;sn=892464db8e5e2d1e060bfeeacef63882&amp;chksm=871b14d6b06c9dc0e5f870684b95dee11d47f75d155d601f86e9700ddc0c1b65191d9c46e19b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌提出深度概率编程语言Edward：融合了贝叶斯、深度学习和概率编程</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721938&amp;idx=4&amp;sn=64634dd519ee70c35fdf1e771da7d9e5&amp;chksm=871b0aecb06c83face511e46c836911a7a15c69980a76198ae928aa935b51d162ebe20946a35&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌新论文提出预测器架构：端到端的学习与规划 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720220&amp;idx=4&amp;sn=85923b1102993f0c88c0394ae0ecb4fc&amp;chksm=871b03a2b06c8ab4ca055cc73ee73c50275f70990ccdab71107626640548b916d383c549ea18&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind最新论文：线性时间的神经机器翻译 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718504&amp;idx=3&amp;sn=0469d037c1d004270da3006216a97cef&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind David Silver论文：学习跨多个数量级的值 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719494&amp;idx=3&amp;sn=67ed3e91731a47abe1a29df4c949119b&amp;chksm=871b0178b06c886e6da4c83c0c26476c2f679f5e72d542531c5fbb8c798b6d768f9a9c596485&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind论文：在线Segment to Segment神经传导</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719745&amp;idx=2&amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind深度解读Nature论文：可微神经计算机 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719843&amp;idx=4&amp;sn=d54e7e415990bcfe69727e0b9f4c5f98&amp;chksm=871b021db06c8b0b008c7004e130d596ae14f4b4de017098ecc4409e54fad8a4a77d3bcb93f4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind论文：调控运动控制器的学习和迁移 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720969&amp;idx=2&amp;sn=d1fae404486906125e01b5def7e26d94&amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind NIPS 2016论文盘点（Part1）：强化学习正大步向前 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721102&amp;idx=2&amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">DeepMind NIPS 2016论文盘点（Part2）：无监督学习的新进展 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719772&amp;idx=2&amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">ECCV 2016 最佳论文新鲜出炉 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719971&amp;idx=3&amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Geoffrey Hinton论文：使用快速权重处理最近的过去</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717143&amp;idx=2&amp;sn=dbb912c06671f0ba4bb7faf8b1677831&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">哈工大讯飞联合实验室最新论文刷新机器阅读理解纪录 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715759&amp;idx=3&amp;sn=20d16db66afb2d742422f0a3abfa7f1e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">华盛顿大学论文：使用机器学习分析科学文献中的视觉信息 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718786&amp;idx=5&amp;sn=1c91d80ce0422c7049bfdbaa8188d56f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Ian Goodfellow 论文：通过视频预测的用于物理交互的无监督学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719909&amp;idx=4&amp;sn=90e189c8989817e3b52d2a40c355da10&amp;chksm=871b02dbb06c8bcdc29a69b7a9ba2711f3ba1e2a08192e184f298093b404fa57272cdfdf81b9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Ian Goodfellow 论文：用于隐私训练数据的深度学习的半监督知识迁移</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715900&amp;idx=4&amp;sn=948406fcbd53cdca4ce96bd33a28874d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">IBM论文：多尺度循环神经网络在对话生成中的应用 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715145&amp;idx=3&amp;sn=21d98866046180034d68da334501ce24&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">ICLR2016会议，不可错过Facebook提交的七篇论文 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718262&amp;idx=1&amp;sn=0391500e43530e7f4a8b8053176e5d7f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">计算机科学领导者：卡内基梅隆大学ACL2016论文汇总 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715794&amp;idx=3&amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">论文：TensorFlow，一个大规模机器学习系统 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717969&amp;idx=4&amp;sn=7fa67419573685604dde9811d434f6b8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">论文：通过连续奖励策略梯度学习在线比对 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718688&amp;idx=4&amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">论文：基准评测当前最先进的深度学习软件工具 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720189&amp;idx=3&amp;sn=8e0d8f7d3b9c037935736e09f85a4884&amp;chksm=871b03c3b06c8ad57d13417933b779f6b0a5931c3448ef9bf2129fb64b0c3f4c84293358aebf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">论文：一种用于训练循环网络的新算法Professor Forcing</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718988&amp;idx=4&amp;sn=79c38974f2908e909e0f3bdd140cfa88&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">论文：高斯混合模型的似然方法中的局部极大值：结构结果和算法结果</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721081&amp;idx=3&amp;sn=111d844d50c98582695d04fa2b252c89&amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">NIPS 2016现场：谷歌发布 28 篇机器学习论文 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715615&amp;idx=1&amp;sn=f114c4683656991bd331dc9971499a02&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Nature论文：无监督表征学习，用电子健康病历增强临床决策</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650716475&amp;idx=1&amp;sn=2b03deead0c1e63be80fdc239293e805&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Nature论文：从不确定性表征到自动建模 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718527&amp;idx=2&amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">NIPS 2016 公布571篇接收论文 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719581&amp;idx=3&amp;sn=e75b2fcd08d4ef5d8feeb79ebc223d18&amp;chksm=871b0123b06c883511d8dbf853bb60f8e0903e335ed384421d1ab8db96ebf45d9b4cf3e96356&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">OpenAI与NASA论文：用于张拉整体机器人运动的深度强化学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720257&amp;idx=3&amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">OpenAI论文：神经GPU的扩展和限制 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650721777&amp;idx=1&amp;sn=a51774b58c1b39ae9cb23c41361780af&amp;chksm=871b098fb06c80992893818772a5c9410adb8826f60ae44d9468685413708c9c1c4583f967df&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">苹果发布第一篇人工智能研究论文：模拟+无监督方法改善合成图像 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650716071&amp;idx=2&amp;sn=fb8944218199ac4c29af926d8847cc58&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">商汤科技论文解析：人脸检测中级联卷积神经网络的联合训练</a> </li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717606&amp;idx=3&amp;sn=9d20357d6ce5877e7df31058c1ba0b4c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福大学李飞飞最新论文：弱监督动作标记的连接时序模型 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720285&amp;idx=5&amp;sn=583751084a6855b35f684f582afd7976&amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Vicarious在ICLR2017提交无监督学习论文：层级组合特征学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719118&amp;idx=3&amp;sn=4565fb14db41208571b808956a39e310&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yann LeCun论文：基于能量的生成对抗网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717728&amp;idx=3&amp;sn=2de2d33afc32c04f2bcb1cfe1a788c0f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio 论文：一种神经知识语言模型 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720390&amp;idx=1&amp;sn=8ad603e853b88706ca4916495f59b228&amp;chksm=871b0cf8b06c85ee216eb2d46361de137679cd9fd7d09a2a72cdf06d79d6c01dfe1683eb003c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yann LeCun提交ICLR 2017论文汇总：从GAN到循环实体网络等 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650717572&amp;idx=2&amp;sn=da7a53cde74285f229fcf6827bbb17d6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Bengio论文：用于序列预测的actor-critic算法 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718133&amp;idx=4&amp;sn=97ce57340e916cb049ec96c96fa55fe3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio论文：迈向生物学上可信的深度学习 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719794&amp;idx=4&amp;sn=8a1d4e46663439c509f8d580e2b871e8&amp;chksm=871b024cb06c8b5a1cbc79b9b2d9ff0d312842f04ad375ef7838c30f1b639cb3d1e1724f2902&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio论文：使用线性分类器探头理解中间层 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718391&amp;idx=3&amp;sn=75cac85169b49af157755a3cbc68670e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Yoshua Bengio论文：Mollifying Networks</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720220&amp;idx=2&amp;sn=0f2f5061e470ffbf76fee6ac77b3cf52&amp;chksm=871b03a2b06c8ab4a0cb275b1044fb23a646997af91d5753439488ee976512c84979eadd2293&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718106&amp;idx=2&amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">微软ACL 2016论文汇集，自然语言技术逼近人类对话水平 </a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650718072&amp;idx=2&amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">自然语言顶级会议ACL 2016谷歌论文汇集 </a></li>
</ul>
<hr>
<h3 id="专知汇总-链接"><a href="#专知汇总-链接" class="headerlink" title="专知汇总 链接"></a>专知汇总 <a href="https://mp.weixin.qq.com/s/M8sM4zxah0zQIX-Zj7wE6Q" target="_blank" rel="noopener">链接</a></h3><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247484863&amp;idx=1&amp;sn=c6df323610ce2ff331853a3095e0a28e&amp;chksm=fc85e4accbf26dba859b6f7c66e8df641e09ae357b8fc1ea264cba9b647873a75e8b9f3311a0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃01】<strong>深度学习</strong>知识资料大全集（入门/进阶/论文/代码/数据/综述/领域专家等）（附pdf下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247484871&amp;idx=1&amp;sn=f9e47d38bded1e5e93467511599a6fae&amp;chksm=fc85e4d4cbf26dc28f1e532009c2019560fb1edb7de36abe3f93dec79a245de0f2bb09d7eb50&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃02】<strong>自然语言处理</strong>NLP知识资料大全集（入门/进阶/论文/Toolkit/数据/综述/专家等）（附pdf下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247484883&amp;idx=1&amp;sn=25d151494b2c0bc37161e30e181d41e3&amp;chksm=fc85e4c0cbf26dd686eab19eee631616ecc7b70a5a8784fe41cca027f23b40a0afd14886c7d8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃03】<strong>知识图谱</strong>KG知识资料全集（入门/进阶/论文/代码/数据/综述/专家等）（附pdf下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247484897&amp;idx=2&amp;sn=f742514390dc3bc49551fce4752443c2&amp;chksm=fc85e4f2cbf26de4d67d97b6920336ee1edf745989b27ea8f3bf0690b9d2580b3012b8b93b55&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃04】<strong>自动问答QA</strong>知识资料全集（入门/进阶/论文/代码/数据/综述/专家等）（附pdf下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247484926&amp;idx=1&amp;sn=4e34a442c126c46bba27a7f17df3e61e&amp;chksm=fc85e4edcbf26dfb3d715188fd1910ffd6e90a9e18f4022391e4f6ef8801c07982757f750817&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃05】<strong>聊天机器人Chatbot</strong>知识资料全集（入门/进阶/论文/软件/数据/专家等）(附pdf下载)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247484948&amp;idx=1&amp;sn=54d84127b3c8d1ddfd2bbff419db8cbe&amp;chksm=fc85e707cbf26e11ca48032467cee9d02ee1bfac72634edd529c51b97a7af58deb232b0d12d5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃06】<strong>计算机视觉CV</strong>知识资料大全集（入门/进阶/论文/课程/会议/专家等）(附pdf下载)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485001&amp;idx=2&amp;sn=be5a7c8ff658dd2e8886ee108c67839e&amp;chksm=fc85e75acbf26e4c934b9d854901bc88baf2c62f43ec9350e4a5ab164ec4e2343df5cd6bfacc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃07】<strong>自动文摘AS</strong>知识资料全集（入门/进阶/代码/数据/专家等）(附pdf下载)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485060&amp;idx=2&amp;sn=b0ab17992453bb4663a3e31600d4da6e&amp;chksm=fc85e797cbf26e812e66354d242f6ddccf1968b4e63bb0fdfa97013fed8dbb7e210ab548a358&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃08】<strong>图像描述生成Image Caption</strong>知识资料全集（入门/进阶/论文/综述/视频/专家等）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485072&amp;idx=2&amp;sn=e9f4f0d1daeb3a144e37fcfcc61e908f&amp;chksm=fc85e783cbf26e95d153af7c825ef9b8fc4fc6fd37f75709de98eae769e6b70f8da29ae65a73&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃09】<strong>目标检测</strong>知识资料全集（入门/进阶/论文/综述/视频/代码等）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485095&amp;idx=2&amp;sn=652a98f8df8cf02998ad53dcef06c568&amp;chksm=fc85e7b4cbf26ea2365234dc47421175db18e0391eb544b76b4fac63373737b9df6fc14230a1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃10】<strong>推荐系统RS</strong>知识资料全集（入门/进阶/论文/综述/视频/代码等）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485159&amp;idx=2&amp;sn=4bafae4029a93f005b3f9ffb30c4e5d6&amp;chksm=fc85e7f4cbf26ee21ba2464d71ec1f80dd02986e892c033f76025d8be947e84a8e1ff5501d1c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃11】<strong>GAN生成式对抗网络</strong>知识资料全集（理论/报告/教程/综述/代码等）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485190&amp;idx=2&amp;sn=be5f153c1c87b1b1140e31e7c7a6de39&amp;chksm=fc85e615cbf26f03700a58c3ec97871ae3bf3fd7ee5f88233cfdbd1cb34f906c4b3e5e57ba65&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃12】<strong>信息检索 Information Retrieval</strong> 知识资料全集（入门/进阶/综述/代码/专家，附PDF下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485208&amp;idx=2&amp;sn=999388c9cb910085460884a3b0ff8c37&amp;chksm=fc85e60bcbf26f1dc76e3cfbb91c605e3cd23ffc50b127a4813ec910551953545c6011c42a4c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃13】工业学术界<strong>用户画像 User Profile</strong> 实用知识资料全集（入门/进阶/竞赛/论文/PPT，附PDF下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485245&amp;idx=2&amp;sn=8368f8329f98a0eff50307d3d79b1853&amp;chksm=fc85e62ecbf26f3896f7b3114077b29911f3b72aacd3caf110f8ee4514bbda1a2620dafaa268&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃14】<strong>机器翻译 Machine Translation</strong>知识资料全集（入门/进阶/综述/视频/代码/专家，附PDF下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485258&amp;idx=2&amp;sn=768af221106519064fa4e9ef79569fb4&amp;chksm=fc85e659cbf26f4fad66e73eacc8d719daf6e6b12723639d2c87067ef6d88052b17c32fdd988&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃15】<strong>图像检索Image Retrieval</strong>知识资料全集（入门/进阶/综述/视频/代码/专家，附PDF下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485322&amp;idx=4&amp;sn=393dfcabc94d5d6090008625c6116b6e&amp;chksm=fc85e699cbf26f8f992792aea507b8ae1bcdb5f5b3dec168831943df6fdff1d3add771ea0e8f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃16】<strong>主题模型Topic Model</strong>知识资料全集（基础/进阶/论文/综述/代码/专家，附PDF下载）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485396&amp;idx=2&amp;sn=385fd9d2ebc6468a81d8ab6a0ce9489e&amp;chksm=fc85e6c7cbf26fd1cd3c03c419b15547e7c48fded35c704b1b55790072bc9b76f5f9d8b0964f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃17】<strong>情感分析Sentiment Analysis</strong> 知识资料全集（入门/进阶/论文/综述/视频/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485417&amp;idx=3&amp;sn=c6dcaba675873c0f35a4c510842b0d32&amp;chksm=fc85e6facbf26fec9a1668f6b89bec245ccc6741fd795d95e71c644fcb792be26ae37047b2e9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃18】<strong>目标跟踪Object Tracking</strong>知识资料全集（入门/进阶/论文/综述/视频/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485434&amp;idx=3&amp;sn=f35545e289dd3c3701c3a1a0460b59fd&amp;chksm=fc85e6e9cbf26fff60a1d8a04d079ad470bcf9b204859ee8eec67191baf9e318bb29f4a907c2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃19】<strong>图像识别Image Recognition</strong>知识资料全集（入门/进阶/论文/综述/视频/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485464&amp;idx=3&amp;sn=77fd30180cf66e1cb7b276509b38f358&amp;chksm=fc85e90bcbf2601dfe6439076bb00896befe621dcdd75dfb77a931839b3b362d3226c4cd2ad5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃20】<strong>图像分割Image Segmentation</strong>知识资料全集（入门/进阶/论文/综述/视频/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485479&amp;idx=4&amp;sn=9a5d3c9ffe4c862ce218eef3fce97246&amp;chksm=fc85e934cbf26022e021a8d8280c513b65e2cc34e49ce3843f0e5a2d57f4986d5accfb5108a6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃21】<strong>视觉问答VQA</strong>知识资料全集（入门/进阶/论文/综述/视频/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485541&amp;idx=3&amp;sn=29fc7a7b3933e90bfdd6ad7a53c0b039&amp;chksm=fc85e976cbf260602acd4bbf7129124b72f406865cb7424654102d1c6b2c3aa64b43bb3ef21c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃22】<strong>机器阅读理解RC</strong>知识资料全集（入门/进阶/论文/综述/代码/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247485941&amp;idx=3&amp;sn=eacc0bbc4bfdf24295f8465aa829a059&amp;chksm=fc85e8e6cbf261f07a4ec78ed883247272e60b0707828cbc0374e6c8a7f731000a17eb206d27&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃23】<strong>深度强化学习RL</strong>知识资料全集（入门/进阶/论文/综述/代码/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247486017&amp;idx=5&amp;sn=c8715937f09a5e16c8eca68abf2348ca&amp;chksm=fc85eb52cbf262448ff922da5199a6f9019c093fab8114cef6ff0a960b4f5d3d4626410406b5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃24】<strong>视频描述生成(Video Captioning)</strong>知识资料全集（入门/进阶/论文/综述/代码/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247486136&amp;idx=5&amp;sn=90c5f0dfae1bb302aa9a141488944245&amp;chksm=fc85ebabcbf262bde80f5e92cde4842330f69c7c7a05da364d882b7b52b85b9463775c2bbcaa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃25】<strong>文字识别OCR</strong>知识资料全集（入门/进阶/论文/综述/代码/专家，附查看）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&amp;mid=2247486572&amp;idx=3&amp;sn=cbf52c0ffcaaca3bf05d4a8fe259e421&amp;chksm=fc85ed7fcbf264694ddcdaaa71ff830669dd7976e259d10da903ca554e1277ea7a5db6fdd930&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【专知荟萃26】<strong>行人重识别 Person Re-identification</strong>知识资料全集（入门/进阶/论文/综述/代码，附查看）</a></li>
</ul>
<hr>
<h3 id="2017年机器之心发布的教程-链接"><a href="#2017年机器之心发布的教程-链接" class="headerlink" title="2017年机器之心发布的教程 链接"></a>2017年机器之心发布的教程 <a href="https://mp.weixin.qq.com/s/NUO_5nzH_nrGBZS8p-9mFQ" target="_blank" rel="noopener">链接</a></h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><h5 id="1-机器学习基础"><a href="#1-机器学习基础" class="headerlink" title="1. 机器学习基础"></a>1. 机器学习基础</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723678&amp;idx=1&amp;sn=5cb049e37427dd2b2a4e30e42bcc2fff&amp;chksm=871b1120b06c983651bf92526cd8554225304200364d39cd18592fd8a6848d1f84cf80aeea22&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂机器学习、数据科学、人工智能、深度学习和统计学之间的区别</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730366&amp;idx=1&amp;sn=916f9def7419523c310c0f1563f05361&amp;chksm=871b2b00b06ca216072dacac0796aca1010ca401343ccdb330159561c863c69ca7d3112b0a96&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">人人都能读懂的无监督学习：什么是聚类和降维？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731247&amp;idx=1&amp;sn=d90fcbf1d0412fdda08e00f611628e2e&amp;chksm=871b3691b06cbf87f677cf35208cc79572aef7148e5974e5389174793d88c6a4ad17025a4a09&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何解读决策树和随机森林的内部工作机制？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729915&amp;idx=2&amp;sn=5da6789719cdc3785cae0034ea950934&amp;chksm=871b29c5b06ca0d3e09f00691c0eff7f4989ed628d609c64fd9ef08266a78eedf19b8fc0d739&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 拟合目标函数后验分布的调参利器：贝叶斯优化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734720&amp;idx=4&amp;sn=f4960f34392d429b4fb06c4e5d614427&amp;chksm=871ac4feb06d4de82614161d552ed79fd482bac2269b133799ff3d0a3e9c47917553b15b2fb0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 区分识别机器学习中的分类与回归</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734809&amp;idx=2&amp;sn=d46b3e5879fd4d7692efaaf260b32be2&amp;chksm=871ac4a7b06d4db127f59213182fc84cd9a2390aeeb63bf31e444f775a4cd308249f4238b889&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 思考VC维与PAC：如何理解深度神经网络中的泛化理论？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734959&amp;idx=2&amp;sn=93882c4f286880d7db364ba7b33dd6ce&amp;chksm=871ac511b06d4c07cdb878f1b5eed2b27573a0b06b683b0f57ded04852b31f0cb6072a81138f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 理解XGBoost机器学习模型的决策过程</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729251&amp;idx=3&amp;sn=c700055d6f78cd60c5df87bb20a1ed59&amp;chksm=871b2f5db06ca64b94a89bcfcd91705e58be8343a79fdaf045a94a00f1184cf5d543eabe54f0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">业界 | 似乎没区别，但你混淆过验证集和测试集吗？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733678&amp;idx=3&amp;sn=5ee8cc5ad692dfe78150b041031c8e13&amp;chksm=871b3810b06cb106f94bc07bffe76909d38638f057a4cd751efdf7ac313af50e87ab324d6bbd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 初学者如何学习机器学习中的L1和L2正则化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723438&amp;idx=1&amp;sn=a778051186c0e1fb3cdb4076868fd54a&amp;chksm=871b1010b06c99063ec5599dcecbed5ce3065e7c2f0ab1cc11a8251f2472838302f89cf51d52&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习算法集锦：从贝叶斯到深度学习及各自优缺点</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650737028&amp;idx=3&amp;sn=a6a849924056f4a1300b04bd55c7f87a&amp;chksm=871acdfab06d44ec6ec46b5aeb82df96b6371a81f1ff5f2e64aba4ce1274ee6bfcc24ed2a01e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 机器学习新手必看10大算法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728330&amp;idx=2&amp;sn=dadc2ac166249dbb600014c44077ae87&amp;chksm=871b23f4b06caae2c1eaf4c2b81af316bb194d153d3bcb8fafb768bd04d41159922aba2efd95&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 详解支持向量机SVM：快速可靠的分类算法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722941&amp;idx=2&amp;sn=328ba8aa2657217c1d90304018ba3bc6&amp;chksm=871b1603b06c9f155faf0f1e6d6a62f9d014bcaa85f57abc9f0f9ff0ab0ac608b1749f12c170&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">干货 | 详解支持向量机（附学习资源）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728869&amp;idx=4&amp;sn=377e2da3d6fe3ec06154d4cc01a9c6e0&amp;chksm=871b2ddbb06ca4cd28b77c43c425723ea2dcc3843affb43a798fb26533c66d2d8f5e26e70d5d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 遗传算法的基本概念和实现（附Java实现案例）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731659&amp;idx=3&amp;sn=b3f6e3ea45f30dc85d6df7551b34ead5&amp;chksm=871b30f5b06cb9e30a6d2cdc22787895d92be9404227da60ec6c1a2e0e1b7b1091a82740da6c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 利用达尔文的理论学习遗传算法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733235&amp;idx=2&amp;sn=6b9572da8fec231a908018f76a6de380&amp;chksm=871b3ecdb06cb7db23652a12f56ecb5b864efdd3932dc78c00a0ea4f2279495a9b3d52b9da5f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 详解可视化利器t-SNE算法：数无形时少直觉</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733784&amp;idx=4&amp;sn=3ef3ebd598561e7cc46633bb5a743dd7&amp;chksm=871b38a6b06cb1b0c826c6f17c0a5ca018c1b20ada4c45e316f074b4c46975f92464c875382a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 如何构建稳固的机器学习算法：Boosting&amp;Bagging</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730393&amp;idx=4&amp;sn=274c6be9075b05e52638652ca22884b4&amp;chksm=871b2be7b06ca2f198d34f526b7dc5b50ee4ec3154e9d192e24f820b52c86d183d42c2a469c3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 神经网络调试手册：从数据集与神经网络说起</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732235&amp;idx=3&amp;sn=1731dfe5c6687328352d76558b34d49f&amp;chksm=871b32b5b06cbba344f9ed8961a61a7f287bfc173adaf6594b345b70cd29f7c635f57e203899&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">观点 | 三大特征选择策略，有效提升你的机器学习水准</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735095&amp;idx=3&amp;sn=3922972fc1b8ef2faf4d91a87e2fc062&amp;chksm=871ac589b06d4c9f5f1b35b2a70546d45fed4b0954e5064a8a25e74376083752d3d34ebc0833&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何为单变量模型选择最佳的回归函数</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736547&amp;idx=1&amp;sn=9c57bf436dee384038b1c9c8f884fbde&amp;chksm=871ac3ddb06d4acb17009cc40f2e0bdb843505eab2ec09bf1d8c8fce8ff5ea27486683f8e754&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器学习老中医：利用学习曲线诊断模型的偏差和方差</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733110&amp;idx=3&amp;sn=c96d3754e8b0c297e9ae8769ba490f16&amp;chksm=871b3e48b06cb75e5bd5fb1556ff709192253c60e85f3d78f95bfa1be9cbc3fa560ca3c559c5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何为时间序列数据优化K-均值聚类速度？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736044&amp;idx=3&amp;sn=3434f7818f809926c3fbc852c6810d5e&amp;chksm=871ac1d2b06d48c482d6c4b81858bafdbcdec8edb9cf271c92f15fe2776cfe7e4056f5fb5549&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 将应用机器学习转化为求解搜索问题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724464&amp;idx=1&amp;sn=1f34358862bacfb4c7ea17c864d8c44d&amp;chksm=871b1c0eb06c95180e717d8316b0380602f638a764530b4b9e35ac812c7c33799d3357d46f00&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从重采样到数据合成：如何处理机器学习中的不平衡分类问题？</a></li>
</ul>
<h5 id="2-深度模型基础"><a href="#2-深度模型基础" class="headerlink" title="2. 深度模型基础"></a>2. 深度模型基础</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734516&amp;idx=1&amp;sn=97750fa6b84ecdf97f3d0363d1d94ae3&amp;chksm=871b3bcab06cb2dcba6a0c46a8444af5e6e567c608c52ef8cd1da38479d662fede71dadf6aa6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从零开始：教你如何训练神经网络</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728195&amp;idx=3&amp;sn=4d7e69e3f74a0679967a8186214635a3&amp;chksm=871b237db06caa6bd51d4bc54a13608e893f15844abba298a8c74087fdae8e911e2ecf4c9d5e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 深度学习初学者必读：张量究竟是什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726033&amp;idx=4&amp;sn=e8cdbcb2a80aa78939c4880393ac5c47&amp;chksm=871b1aefb06c93f94d5fbd1491f993332df3c9c6e6d6a0fc020e1e0c8b1a510c76bcb3c91b43&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">解读 | 通过拳击学习生成对抗网络（GAN）的基本原理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723168&amp;idx=2&amp;sn=68b21b815688443a0dd7caa115cc13fa&amp;chksm=871b171eb06c9e085ab0f2223e6bab04d2eecfa430ca071b19d5c377d909d46724269126dbf3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">干货 | 直观理解GAN背后的原理：以人脸图像生成为例</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724206&amp;idx=4&amp;sn=8c56ffd127b92ca0d9186477d724759e&amp;chksm=871b1310b06c9a064c43234df278e8d52a3fcfba87d9932fa51895e6367f835ec333d6063c7b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从基本概念到实现，全卷积网络实现更简洁的图像识别</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730929&amp;idx=2&amp;sn=65ef24e111c9d3d537b8ea95d3fc87bc&amp;chksm=871b35cfb06cbcd9923c5057724486636cee60a47e3b91bfc44de255c5244448f4611df18da7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 初学者指南：神经网络在自然语言处理中的应用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731207&amp;idx=2&amp;sn=ce4158846e5ecc07879d9fd853377a9c&amp;chksm=871b36b9b06cbfafce0fcd5f4fa69439a7a2ba58e29377294d2e244cec065bca83f844b9921b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 深度学习：自动编码器基础和类型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732434&amp;idx=2&amp;sn=c668f9e835a4dc48730048478ba24526&amp;chksm=871b33ecb06cbafae7e8126b8726b273111231d841c1f980c5cc5594dc9a94aff4b676ef4fbd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 请注意，我们要谈谈神经网络的注意机制和使用方法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735126&amp;idx=2&amp;sn=9c56d9f6a4fff5f6e1d026d8c98b21c7&amp;chksm=871ac668b06d4f7ece3109204cc5eba8ae099a7e64a42fce284e239ef2b68aba64a06407020c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 经典必读：门控循环单元（GRU）的基本概念与原理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735672&amp;idx=3&amp;sn=bdcbeb175a9e26a0e3e51d40b3e3c3f9&amp;chksm=871ac046b06d4950ed1eb1cfc46e920d392aefebd026acc48c64233d10c858e9821cb2af0ecf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 迁移学习在图像分类中的简单应用策略</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726125&amp;idx=3&amp;sn=b094179cb4edf18168e01272ceccefe1&amp;chksm=871b1a93b06c9385ff46c210c4619c2b0005e9198d74a9d362ebb8b4b6d321e9bc7132bd24cb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">解读 | 如何从信号分析角度理解卷积神经网络的复杂机制？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728605&amp;idx=2&amp;sn=a876df57cad1d2b9f38aea9add2afb34&amp;chksm=871b2ce3b06ca5f50fd0127c9c3e62a64b4ea98910bc2a49c6df30cb0f0d2cea48ac81fc4a64&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 无监督学习中的两个非概率模型：稀疏编码与自编码器</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728643&amp;idx=2&amp;sn=0494d4e6e89c05fdecb9588637ad0135&amp;chksm=871b2cbdb06ca5ab5683f3d1b5630b0bf9260ba9f27e48842d9ab6bb9b110f10ccad0ff5071a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 从任务到可视化，如何理解LSTM网络中的神经元</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729486&amp;idx=2&amp;sn=dec2376601e005b7ba127720ed5f9d1a&amp;chksm=871b2870b06ca166a8427b08375ea12df3512e1ed82e07dbcf504e1a70d994cbead5bf744364&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 将注意力机制引入RNN，解决5大应用领域的序列预测问题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728879&amp;idx=3&amp;sn=897571064a4b367c08d1aaef6360832b&amp;chksm=871b2dd1b06ca4c7178cc125289d957fc46bdc9c0f8cdff5103c01fed383ca4c3c2f36e8090d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 听说你了解深度学习最常用的学习算法：Adam优化算法？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728437&amp;idx=2&amp;sn=8ef78af1a8583283c61faf59cdc1aa9a&amp;chksm=871b238bb06caa9dffcf5ac5098f492300eedf37d6843bb1bc83116576fa2f155bad73be5d0d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何解决LSTM循环神经网络中的超长序列问题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725861&amp;idx=5&amp;sn=eb538dc638da2a0b70c95b59d1b3a0f2&amp;chksm=871b199bb06c908d03cfa568ff747b52706d98fc4c26ea3b2af48a70b2f68a01cdd34ee51fa0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 一个基于TensorFlow的简单故事生成案例：带你了解LSTM</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731550&amp;idx=3&amp;sn=d3d79c5f75d1a7c5aadfbaacbb263b6f&amp;chksm=871b3060b06cb976785ab9a4498f7d6a81261e431a8657419e9a3a028d39063286a35167edbf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何判断LSTM模型中的过拟合与欠拟合</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733409&amp;idx=3&amp;sn=6e41b8b1b2242e37949fdc95e8460976&amp;chksm=871b3f1fb06cb60936551b449af0c52fc2927f5d510a96b2c5c2f21d9b58677c2486032daf16&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何估算深度神经网络的最优学习率</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735824&amp;idx=3&amp;sn=07ca2cb7c3af2325df3dc1a7121c69a6&amp;chksm=871ac0aeb06d49b8e1c679f21fe368e0dd21d845a74bcc369026430deda888e6dc6a792d5bf1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何为神经机器翻译配置编码器-解码器模型？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734243&amp;idx=3&amp;sn=53e89ded6b781dd37e552497b8c334fb&amp;chksm=871b3addb06cb3cb1de38c819b56c2a14c436e4d53a83c8b32b2c948082af5c92c70800a3098&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用深度学习处理结构化数据？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725579&amp;idx=1&amp;sn=bab76962e07731866917d7b8509d6222&amp;chksm=871b18b5b06c91a36e5c0c1f5e196385ef9865f7aebf6b98f5b590e7bea0e912ad06c57991ef&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">改进卷积神经网络，你需要这14种设计模式</a></li>
</ul>
<h5 id="3-强化学习基础"><a href="#3-强化学习基础" class="headerlink" title="3. 强化学习基础"></a>3. 强化学习基础</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725146&amp;idx=1&amp;sn=33642c5ae292a6b0a20a3a26beb1008a&amp;chksm=871b1f64b06c9672435baf978c8089cc0b8d34c63701c2fbf36f8a334dc83b1a3ed4d634f34e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从强化学习基本概念到Q学习的实现，打造自己的迷宫智能体</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729997&amp;idx=4&amp;sn=cf136a75277f01e7ad7c8dc89421ee09&amp;chksm=871b2a73b06ca3653a4ef2266c031db68fc615d8ba56a47f88d67fe96de62ef144babc08aae4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Keras+OpenAI强化学习实践：深度Q网络</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735126&amp;idx=1&amp;sn=221754f7ea0f551b569d2ff81c30c21f&amp;chksm=871ac668b06d4f7e78305a734b02fdb6991e7c13ada6365193ba626ce92418743a2c6896eac6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一份数学小白也能读懂的「马尔可夫链蒙特卡洛方法」入门指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735505&amp;idx=2&amp;sn=cf35da35cc5d760314a8b48f64b22ed8&amp;chksm=871ac7efb06d4ef9dd25450c1ff6bad5c70f73a53bbc133357faeba9f6a876e22f0f028934d2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 蒙特卡洛树搜索是什么？如何将其用于规划星际飞行？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729826&amp;idx=2&amp;sn=5590b0c185ddef32b119ef372a468a36&amp;chksm=871b291cb06ca00a98c37e6c558329ca8d51525ef2919be490876a45d87ac732f3491ebdfab9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Keras+OpenAI强化学习实践：行为-评判模型</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731034&amp;idx=1&amp;sn=c700041fe10108ca1068c4d80aa0d05a&amp;chksm=871b3664b06cbf726bd93d7b3db4f15125df77a6f69ddb0304b292b932071d2d78104ad5d4f0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从贝叶斯定理到概率分布：综述概率论基本定义</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725041&amp;idx=1&amp;sn=0c57ba70e2613e6af80c4ab61c996d44&amp;chksm=871b1ecfb06c97d9547e50705d3e74a2b8c41254f0efc2dd88d2e89eec3bfac5da089f28c398&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">想了解概率图模型？你要先理解图论的基本定义与形式</a></li>
</ul>
<h4 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723653&amp;idx=4&amp;sn=5a365b573a9169a54f472c84e03afa7a&amp;chksm=871b113bb06c982de2933924a91297dac24f03bcde26431d885ea38d9a6074cd8175b32a9610&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">干货 | 机器学习需要哪些数学基础？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729055&amp;idx=1&amp;sn=2a4cf2be611cb32da5d245cb17389c1a&amp;chksm=871b2e21b06ca73793c6e61e2eddf079711115ba9b6b232efcd31a1f191eafd22187806ab877&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度神经网络中的数学，对你来说会不会太难？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729640&amp;idx=4&amp;sn=947ac4fb6765797bac76ae6c6c395c14&amp;chksm=871b28d6b06ca1c02db2790f5dae76a27c45e06ed4327779a340fbeffa9b99e08f10794716de&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">观点 | Reddit 热门话题：如何阅读并理解论文中的数学内容？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729690&amp;idx=2&amp;sn=5e90776562550c882af34c5424c3bb2c&amp;chksm=871b28a4b06ca1b2ffa71d2dbacffdecc2c2a710474f3972f3e02ec677055417a674851c3267&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 基础入门：深度学习矩阵运算的概念和代码实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731427&amp;idx=1&amp;sn=9dc135b7f5399951456950aa7544ccb0&amp;chksm=871b37ddb06cbecbb2cf5b82150e1564ac5243fd85a9eb7f4d39e96f8289af1702badf72d5cf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从概率论到多分类问题：综述贝叶斯统计分类</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650737481&amp;idx=1&amp;sn=10e82e52991eb87170e22109857c3dec&amp;chksm=871acf37b06d4621aabc409f95c72f935670c8595f274d62bf5283fdf275f052f29b73c27ab0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器之心最干的文章：机器学习中的矩阵、向量求导</a></li>
</ul>
<h4 id="致初学者"><a href="#致初学者" class="headerlink" title="致初学者"></a>致初学者</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725654&amp;idx=4&amp;sn=505ababb07a6bee5d42a6254a7493a7e&amp;chksm=871b1968b06c907e9f84888ecb2ced8d3f52f0129720872e97f923b94deb34383eacefb4a5cf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Kaggle CTO Ben Hamner ：机器学习的八个步骤</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729193&amp;idx=3&amp;sn=5f251a5861eb891df377d9bc41b4d468&amp;chksm=871b2e97b06ca7816f32fcfd915d7727adbbbe04958e37fb83b2919d968601a76f6a232178d7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Kaggle初学者五步入门指南，七大诀窍助你享受竞赛</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736276&amp;idx=1&amp;sn=6fc23652c35b573e9a5a857e157d49f5&amp;chksm=871ac2eab06d4bfc2e0a6f76f032ba92d74d36d3ac6b553d54ac59f3745ab5b48506d35a91df&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从零开始，教初学者如何征战Kaggle竞赛</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724242&amp;idx=1&amp;sn=703d242700e29813d6c482daf6b211c5&amp;chksm=871b13ecb06c9afa28f8aad729496620078985e4eae8a1296fc407dbd70c1d70fabb3b2817fa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">只需十四步：从零开始掌握Python机器学习（附资源）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726987&amp;idx=4&amp;sn=0f4df6830f2e0996428a1ae1bf0489ea&amp;chksm=871b2635b06caf23a526b425c05b40e2cb1363eac41c1c154edab39fd3fe3a3ad022d72615f2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何从初入行者进阶为人工智能先锋青年？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730149&amp;idx=4&amp;sn=a06118e5d8ca388472866920d3644c8d&amp;chksm=871b2adbb06ca3cddbee982fd01ce9bcab69cd33fc782bda3ae20aa2bd50cb0c84db1f8ba09d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">观点 | 如何从一名软件工程师转行做人工智能？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724131&amp;idx=3&amp;sn=985c3f1e67e6b2bc6d8b89da500b4314&amp;chksm=871b135db06c9a4b482ac76150225a0ad4bbc530e16788087bbfb0444e35c8199b62b868a48f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何转行成为一名数据科学家？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725468&amp;idx=1&amp;sn=84a2dcc945ca36fc52153c8542fcb62d&amp;chksm=871b1822b06c91340c4e4a228e2c06899070aa45e6198d8ef9c048d6e2132b397b6362acc0d3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">初学者怎么选择神经网络环境？对比MATLAB、Torch和TensorFlow</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726987&amp;idx=3&amp;sn=45a0ece0f4e7b9530f3d4aefd572ff0e&amp;chksm=871b2635b06caf23ea77e496a280580ea517169787b10aed39a0f2bcf4c18ab9377b9a0575a3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 初学者如何选择合适的机器学习算法（附速查表）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=1&amp;sn=5e791710b46502661e25ff6f7528003b&amp;chksm=871b1106b06c98107174c81401c1f7017b35939ab20bc83b305ecae8b503690518fd32d75bbd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">经验之谈：如何为你的机器学习问题选择合适的算法？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727504&amp;idx=4&amp;sn=904472921ecf36cc12d2bf8df56c5004&amp;chksm=871b202eb06ca938334a28c47b3c7b77554fbf6dd4b2a901b4379d51483118eec95792736d7d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 企业应该怎样选择数据科学&amp;机器学习平台？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727535&amp;idx=1&amp;sn=8dea385aced84ac19c041d910996dfee&amp;chksm=871b2011b06ca90703b00c5360b0469215fad6396772f4c0b3953b792cd7a1fb7afb29c55119&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">实验研究工作流程详解：如何把你的机器学习想法变成现实</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731954&amp;idx=3&amp;sn=2790b787064d92f0b32aa68cce15c6cf&amp;chksm=871b31ccb06cb8da11fa32d56c0b00e829431348f91961c1197401eab0a4077b084ef22973bb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">观点 | 机器学习新手工程师常犯的6大错误</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735018&amp;idx=4&amp;sn=82759b19c393f46ff780ce08b5000088&amp;chksm=871ac5d4b06d4cc23f45b84613feea1ecbaddb1fcaad7f77862cd3ef54df8d0fb81c5c5dda74&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用Docker成为更高效的数据科学家？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732524&amp;idx=1&amp;sn=72ee2160fc63eb024c4f60d2d36f84a3&amp;chksm=871b3392b06cba84dce2866381a9c9f33e6dc5cfed1b2c9be3e361eb391bfdf9b46370e7a1fb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从标题到写作流程：写好一篇论文的十条基本原则</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731362&amp;idx=1&amp;sn=b076060a823b31049d22e22e8eec0690&amp;chksm=871b371cb06cbe0a4a0751d45b8fb0c4827ca1da519b3292de0a3e9875a91f56fa982c0a5ccd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">论文格式排版你真的做对了吗? 常用格式及其LaTeX书写方法介绍</a></li>
</ul>
<h4 id="课程"><a href="#课程" class="headerlink" title="课程"></a>课程</h4><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730321&amp;idx=1&amp;sn=dbf710544d5a00341fca20dd814a33a3&amp;chksm=871b2b2fb06ca239a2b4b4c9d7ce35e831eef85faaf57f83e527cce949df6e2fecd7a9f8b206&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">蒙特利尔大学开放MILA 2017夏季深度学习与强化学习课程视频（附完整PPT）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729791&amp;idx=1&amp;sn=df681f5152fc57027fff928fa9cc28ab&amp;chksm=871b2941b06ca057168c8fb3778321193e2d8c3f9bbfe31531e7681fb0ab6b3ea60ea42e4d26&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福CS231n Spring 2017开放全部课程视频（附大纲）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733008&amp;idx=1&amp;sn=661bf0c6ce18d9f590884af540b27b7b&amp;chksm=871b3daeb06cb4b8042b7affe0fbf7ce5569788999e96d4fc0404df58c13b14adda2c1fdf299&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">斯坦福大学秋季课程《深度学习理论》STATS 385开讲</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732524&amp;idx=3&amp;sn=b1dc4de81422332f0cf3a645fe2fc8bd&amp;chksm=871b3392b06cba84620dbddf76503d437f6df93db3eaa64807033695dd1455e68076c450afb9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | CMU统计机器学习2017春季课程：研究生水平</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728136&amp;idx=2&amp;sn=02cc1e6020db67ae28f5b2b53e312fa0&amp;chksm=871b22b6b06caba0f4c260810342108264c7dde7c20e2ec62b169029aebe0f7ac3f302848cf4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 斯坦福CS231n 2017最新课程：李飞飞详解深度学习的框架实现与对比</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731659&amp;idx=1&amp;sn=0ad68e73f2501eb9d2d9d28eae3e1390&amp;chksm=871b30f5b06cb9e319d8231ea735c564f2b20ebe917fd9b34e24be815095fd3b69c3461bf386&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">三天速成！香港科技大学TensorFlow课件分享</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731685&amp;idx=1&amp;sn=9b8cfdf380ff9c8c91b45ebe7452f4ee&amp;chksm=871b30dbb06cb9cd199412e72d7740970e82c7c61057473871287706a4239f3661eafbfd1630&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">四天速成！香港科技大学 PyTorch 课件分享</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729826&amp;idx=1&amp;sn=9efa4e62ae2456cc509b85a66a376be4&amp;chksm=871b291cb06ca00ac758954e0d76301490af5d5f4d6ab5824f0e46ae0b0dbfa891fb9b210036&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">吴恩达Deeplearning.ai课程学习全体验：深度学习必备课程（已获证书）</a></li>
</ul>
<h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><h5 id="1-机器学习基础实现"><a href="#1-机器学习基础实现" class="headerlink" title="1. 机器学习基础实现"></a>1. 机器学习基础实现</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722778&amp;idx=3&amp;sn=4baa72592dd8432a25cdecd742eb82fe&amp;chksm=871b15a4b06c9cb23f0c112b3bf74de38f2871f90d1ddf53c13b78380bc563b3636684fd3ded&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从头开始：用Python实现带随机梯度下降的线性回归</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726606&amp;idx=1&amp;sn=c26b56e320e8abab053ad24bd73e52b6&amp;chksm=871b24b0b06cada6da34fd3a0240acbc5614d69439bd9b5499ab3b20eb60753a7b69b9388012&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">初学TensorFlow机器学习：如何实现线性回归？（附练习题）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729997&amp;idx=3&amp;sn=557c6978fa2cdf1af2420d68d48edbf7&amp;chksm=871b2a73b06ca36535713c6b5646b3e451b49fe64484e133ffaea1ac4513b2c4905aabaca34a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从头开始：用Python实现带随机梯度下降的Logistic回归</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722795&amp;idx=3&amp;sn=53a95b9ecc269dc0ec8926253b2d5412&amp;chksm=871b1595b06c9c83d205dcab550d14f2709bbae290219b2ce0ad913a0677dc617f138d1ebb6f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从头开始：用Python实现随机森林算法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650722844&amp;idx=3&amp;sn=c9e5f788db0b83e0320acc50d8ab4286&amp;chksm=871b1662b06c9f74b2770e8d1cc9f181ec5089d004cc34e578bbcbe547d25ef331010e205c25&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从头开始：用Python实现基线机器学习算法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723438&amp;idx=4&amp;sn=cf3902a9933afe08ac3c38452044cddd&amp;chksm=871b1010b06c99062809133f3ad6279bccd64768a761a2aa6495367048069bc13788929b276a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从头开始：用Python实现决策树算法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734337&amp;idx=1&amp;sn=da6584b604d99896e19bf556ddc053ad&amp;chksm=871b3b7fb06cb26930fe516caaba19907fc80d303dde991104829ab4743545c3bc18ad934c8f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">听说你用JavaScript写代码？本文是你的机器学习指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728212&amp;idx=3&amp;sn=55ea48009447b6ad52f7422fa925fae0&amp;chksm=871b236ab06caa7ce2de9e483f03a9ffe3d2e594b8af407ff2ee963c8487952028aba33c1452&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用JavaScript构建机器学习模型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726358&amp;idx=3&amp;sn=29b9a4a0206291f9fd9e50a01e11d21c&amp;chksm=871b1ba8b06c92be9bb14151079ba5ce5784f203859ec6a5b3bb6c83e9d44ad80fda655213de&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 初学文本分析：用Python和scikit-learn实现垃圾邮件过滤器</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729725&amp;idx=3&amp;sn=842cdf4afb9c1c6c8b0fa935b576ff41&amp;chksm=871b2883b06ca1955bee87dcd09faef6b89088acfccd8aa10a404ad572e63de24296b709038d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何通过牛顿法解决Logistic回归问题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736180&amp;idx=1&amp;sn=4e26c6a0b3c72fd82809ce94b476c55a&amp;chksm=871ac24ab06d4b5c38d08eeb6236c30e8c905ae02dbb7b6356022a97e7cc9cd468ad90ffa8d7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">每个Kaggle冠军的获胜法门：揭秘Python中的模型集成</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736577&amp;idx=3&amp;sn=158015af74af324524ac4462406aa7e6&amp;chksm=871ac3bfb06d4aa9f117c55abba570c5e179f6d6f341e8f794b64830a1f762775e16e0fa6db6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何在Python中快速进行语料库搜索：近似最近邻算法</a></li>
</ul>
<h5 id="2-深度网络基础实现"><a href="#2-深度网络基础实现" class="headerlink" title="2. 深度网络基础实现"></a>2. 深度网络基础实现</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727449&amp;idx=4&amp;sn=63d7df34d597d6648d8373daad0a356a&amp;chksm=871b2067b06ca97154af0ad047b76a3f476f364c602ad21e8a59aabf99cf29a2a60e1addea04&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 初学者入门：如何用Python和SciKit Learn 0.18实现神经网络？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730189&amp;idx=3&amp;sn=7c6db64c53342e7d9274b865b304a94e&amp;chksm=871b2ab3b06ca3a55d4dd6f3f3778ec7f83d8069698c64dd6f93be392ffe1c1575be5e8872a5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用30行JavaScript代码编写神经网络异或运算器</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731455&amp;idx=3&amp;sn=3235f705bfe42be73b7be1227eb91d5d&amp;chksm=871b37c1b06cbed7df05dd898f7eeadded146d3656069519995f9140cb61aa0d7b5e63db377d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 使用MNIST数据集，在TensorFlow上实现基础LSTM网络</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734699&amp;idx=2&amp;sn=7aea11805597957bf5ffbafba37a27aa&amp;chksm=871ac415b06d4d03af99c489951afbf49a4209b1b96eb58fa4925723ea40e67b88ab04fcb432&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用Keras集成多个卷积网络并实现共同预测</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733523&amp;idx=4&amp;sn=63adfa76c6522488572227ba3b1f874e&amp;chksm=871b3fadb06cb6bb45f9ac082126300db61819bc1acbfd600ccf32c6913e1ce478c4fe0ee0f8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 在Python和TensorFlow上构建Word2Vec词嵌入模型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731623&amp;idx=3&amp;sn=613f739fb333adb51db877f0000c5698&amp;chksm=871b3019b06cb90f2b64d4de5bda1eb000562f60b65ca88b5ca559199f805aa1355529912b13&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 详解如何使用Keras实现Wassertein GAN</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730287&amp;idx=1&amp;sn=5697b072a5671ac201e15b43339efab9&amp;chksm=871b2b51b06ca247ac1fdc939e39cfc44cbc2ee25e1b105cf9a582395ddbcdd43cfe18fecd40&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器之心GitHub项目：从零开始用TensorFlow搭建卷积神经网络</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730786&amp;idx=4&amp;sn=9965afeb050e2e7431baef39636e28e2&amp;chksm=871b355cb06cbc4adf2e536f52596f383ee314303c72eb09b4cf6791603d337d59d97b5c68f5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何基于TensorFlow使用LSTM和CNN实现时序分类任务</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735415&amp;idx=1&amp;sn=e088f8796abb0d4d09906481fd5c0265&amp;chksm=871ac749b06d4e5fadc74b7f593a574c14d145e4215379f7302dbfabe304a86d044ebcbfecd5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">作为TensorFlow的底层语言，你会用C++构建深度神经网络吗？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731567&amp;idx=3&amp;sn=2908b05fc138ed58bfdef23199f48075&amp;chksm=871b3051b06cb9472b6775d67e2ca9fb27b9110df0c9d783dec8277c66219b1ef01ee2ff1cf6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 十分钟搞定Keras序列到序列学习（附代码实现）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736232&amp;idx=2&amp;sn=04b1deed56d718decdf271f166d209e2&amp;chksm=871ac216b06d4b004614ec20979bec27b458578eb5fb3255af1d0c9451581528594b19608038&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 想实现DCGAN？从制作一张门票谈起！</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725900&amp;idx=2&amp;sn=19d6aa4d36d5cb5cea0517085ea2ed7e&amp;chksm=871b1a72b06c93647896acb49817dc90934aebc3069036f02353d44d15c2edea529b599b8bfd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 通过PyTorch实现对抗自编码器</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732524&amp;idx=2&amp;sn=2877d47c9fb4bfa47c348fa14e4b2706&amp;chksm=871b3392b06cba849b3370aad1a21cdb8bece6f53208ed95563b555843faa65e32fedeed011c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 基于Keras的LSTM多变量时间序列预测</a></li>
</ul>
<h5 id="3-计算机视觉实现"><a href="#3-计算机视觉实现" class="headerlink" title="3. 计算机视觉实现"></a>3. 计算机视觉实现</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729406&amp;idx=2&amp;sn=a5e37e1d653bbc74063994f739ce3920&amp;chksm=871b2fc0b06ca6d6590ea266086c5a7061d094a12e3dfde3fd3bfdbb7b09f980785139e30b9b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | TensorFlow从基础到实战：一步步教你创建交通标志分类神经网络</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732958&amp;idx=2&amp;sn=60826101ff6094c366da6f7040f6c3ce&amp;chksm=871b3de0b06cb4f698ac110dcecf7084edb264355a2585c72f311cd27b08b96989736950eb0b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用TensorFlow和自编码器模型生成手写数字</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732216&amp;idx=4&amp;sn=6a43499b4af953ff6779e9165e1cea00&amp;chksm=871b32c6b06cbbd09c10b8504cdee6ded71995cf87e7fc95c9c1e7b4feaf2eb7e47a06444fba&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 无需复杂深度学习算法，基于计算机视觉使用Python和OpenCV计算道路交通</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731098&amp;idx=2&amp;sn=833275efb1b49db7c0469b84fce21fc4&amp;chksm=871b3624b06cbf32c343a6f8a7d128f5a5e92df3da8d994b59069ee48e9edae2a0f708c1be0b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 深度学习 + OpenCV，Python实现实时视频目标检测</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730538&amp;idx=3&amp;sn=4dfaf1599cbb0cbf3ae66b1c7244bc7d&amp;chksm=871b3454b06cbd42d25f83dfe2171c941805230d79dae7faa1a073cabc91a9437015073d3f96&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何通过57行代码复制价值8600万澳元的车牌识别项目</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732561&amp;idx=3&amp;sn=3244bf3628ed274c80eb30c6bbc97171&amp;chksm=871b3c6fb06cb57993bf24dea12f55c3e598e89c6503e5c3e65e24c27d9819315b6b8572cb61&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 百行代码构建神经网络黑白图片自动上色系统</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731852&amp;idx=2&amp;sn=3914978de93da05405b85c38d2a1bbb3&amp;chksm=871b3132b06cb8246c230aaa7ed5e88b50fb557519fdb9103852f4815c9ffcb117d1794a2d8d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 盯住梅西：TensorFlow目标检测实战</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726926&amp;idx=3&amp;sn=11c4a301ec8cf646b01afb7fbc3eba5e&amp;chksm=871b2670b06caf66ad9ba8f4832e51d10e6548220f7762f26b947e298da3432e864da1796502&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 从数据结构到Python实现：如何使用深度学习分析医学影像</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734670&amp;idx=1&amp;sn=60cdf724b9cbd3497c116e3e5418809c&amp;chksm=871ac430b06d4d26f33cc2a2db2c1bb9b3862a6cf0dec60e651577ea67fb1209b86afb96e6df&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">仅需15分钟，使用OpenCV+Keras轻松破解验证码</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728960&amp;idx=3&amp;sn=a5898f12ff2c978967faf71bf6551c54&amp;chksm=871b2e7eb06ca76857e82b419b7d0bb533b2058f6e1c5c5ba2135f0a4193a4087a1115df582b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用TensorFlow API构建视频物体识别系统</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729786&amp;idx=3&amp;sn=5275db7b6967bf4cbb8e98324bcd7fb3&amp;chksm=871b2944b06ca052fbef497fda64593a5f9c7792ee13590253480ff2b51ea8e31fe6f4d29754&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 经得住考验的「假图片」：用TensorFlow为神经网络生成对抗样本</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732855&amp;idx=1&amp;sn=87319e9390200f24dfd2faff4d7d364a&amp;chksm=871b3d49b06cb45fd8a68d003310b05562d9f8ff094ed08345f112e4450f7e66e6cf71c5b571&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">先读懂CapsNet架构然后用TensorFlow实现，这应该是最详细的教程了</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730488&amp;idx=2&amp;sn=9e64f2923512cb46d3011b0d200fba49&amp;chksm=871b2b86b06ca2908777e6b7a1045f23bf9e086b5a9f166e9bb9276c9d327fa151971b484e74&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用深度学习去除人物图像背景</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729791&amp;idx=3&amp;sn=273d8f1eb58490cea54433f1d5253bbf&amp;chksm=871b2941b06ca057d3294aeed4eb9584acb6038bad0334e9c0f19d998d5e521bc89b477081ed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 如何通过CRF-RNN模型实现图像语义分割任务</a></li>
</ul>
<h5 id="4-自然语言处理实现"><a href="#4-自然语言处理实现" class="headerlink" title="4. 自然语言处理实现"></a>4. 自然语言处理实现</h5><ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736777&amp;idx=1&amp;sn=d837a23210743031688380e4596558ee&amp;chksm=871accf7b06d45e189adbc7eb4e9d9fc518446e9aeb9a07b79a4a6ca08bdab21b926b3484a3a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何解决90％的自然语言处理问题：分步指南奉上</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733162&amp;idx=3&amp;sn=c6812109a57d9370ed96ebdd35945e6e&amp;chksm=871b3e14b06cb70266c8bbed6c8ab19fa5b8242514f1e1e9fa71d215595c6634a8fda67a418f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | Github项目：斯坦福大学CS-224n课程中深度NLP模型的PyTorch实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728901&amp;idx=1&amp;sn=7c9a47a9b55678794cd5f70460e0f561&amp;chksm=871b2dbbb06ca4adaf245336ad83a7d4afeebb251bb13328f78f5313a3888faaeb0dc714bb15&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌开放GNMT教程：如何使用TensorFlow构建自己的神经机器翻译系统</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734546&amp;idx=2&amp;sn=7fe918a35c35342e3c210c4eeebf0edc&amp;chksm=871b3bacb06cb2ba7e51ddccf0c703d6f9346da5ba3909d4268485c031b77388a94e6f252019&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从头开始在Python中开发深度学习字幕生成模型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728136&amp;idx=4&amp;sn=04d55487be6ad40bfc87e8f849f5d2d0&amp;chksm=871b22b6b06caba0258a749290b1824b1bb47a18563e69554d99e06593a8549b88c0f1f8c0c9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 谷歌全attention机器翻译模型Transformer的TensorFlow实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724740&amp;idx=5&amp;sn=c9caf66b1a31396d101a03b4b5012dec&amp;chksm=871b1dfab06c94eca730ea122c7e90f5438ae0ff0b71b3c97df1349fa1c6782da66bbcf13395&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用TensorFlow构建、训练和改进循环神经网络</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734276&amp;idx=2&amp;sn=5ac3f59ced7f27b442e630c66a30ea8e&amp;chksm=871b3abab06cb3aca0c2313c86f786249829caf242633252eff0b23649976e7c1b013e605379&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Kaggle网站流量预测任务第一名解决方案：从模型到代码详解时序预测</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732184&amp;idx=4&amp;sn=b523a8971c9d0c6e886a777aa1603364&amp;chksm=871b32e6b06cbbf0f9d84bbefca1b67a9af4c7326dd675bfd8727c930b7db7dde5b13b5c1314&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 用于金融时序预测的神经网络：可改善移动平均线经典策略</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725842&amp;idx=4&amp;sn=a2e725f09cc7062b66c20e9e48fa12b0&amp;chksm=871b19acb06c90ba638f788589cd3ef2a0cb32db8469dcac0ad454297059f3bd6f0bacd2eaed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用PyTorch实现递归神经网络？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736180&amp;idx=3&amp;sn=5e3c2d3fab70dcb632a58b9b62a91669&amp;chksm=871ac24ab06d4b5ccdeda3977cdc1bdc2fe112e9a442dba12c84dfce568b29bce8d486003b56&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 用数据玩点花样！如何构建skip-gram模型来训练和可视化词向量</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730149&amp;idx=2&amp;sn=e82c3d1a2af7bd4c7af24af44f8729dc&amp;chksm=871b2adbb06ca3cd6714d0084852e37d021c4bae92ce51003740bf6bfebdd3528df08157c00b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 利用TensorFlow和神经网络来处理文本分类问题</a></li>
</ul>
<h5 id="5-强化学习实现"><a href="#5-强化学习实现" class="headerlink" title="5. 强化学习实现"></a>5. 强化学习实现</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733367&amp;idx=3&amp;sn=59d112b5ee7675995d45b96789ffd93d&amp;chksm=871b3f49b06cb65f8e07e3e75e8f36f91862bf1e5677be34c751ad060d9b17d331da5047e0c7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 深度强化学习入门：用TensorFlow构建你的第一个游戏AI</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725012&amp;idx=4&amp;sn=bcf6817a533068610ecac7d9aa3710c6&amp;chksm=871b1eeab06c97fc2bb118b41c267084b4f0e2f6b30a61aa59d50e7eaadbf43f62477037f8cb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 价值迭代网络的PyTorch实现与Visdom可视化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729371&amp;idx=5&amp;sn=186796678dc315b33e3520dad31db821&amp;chksm=871b2fe5b06ca6f38e4a750578164ed969af86ff4623fa5eabd2b90c6c181801987226f42035&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">解读 | 如何使用深度强化学习帮助自动驾驶汽车通过交叉路口？</a></li>
</ul>
<h5 id="6-深度学习框架"><a href="#6-深度学习框架" class="headerlink" title="6. 深度学习框架"></a>6. 深度学习框架</h5><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734471&amp;idx=1&amp;sn=be4cd4b85ed84f997baf4c88543dc3f4&amp;chksm=871b3bf9b06cb2ef94ea9531ec74fef14b8db5d1996b0cf0c9bd31ca3594ef1f54feaea17109&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">分布式TensorFlow入坑指南：从实例到代码带你玩转多机器深度学习</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736925&amp;idx=2&amp;sn=3ec7f2370ce60ff1bc18f5122e0aa5f2&amp;chksm=871acd63b06d4475c22d227bb03b696dbaea94b5c0ec5486c03db2a056b051ec2e436d3f5976&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从零开始：TensorFlow机器学习模型快速部署指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724464&amp;idx=3&amp;sn=1323508f08c25d827d42052cfa796d24&amp;chksm=871b1c0eb06c9518178211d5eac00b8089f68d182076be20ed0954126112f8296d1e7daec7ce&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | TensorFlow极简教程：创建、保存和恢复机器学习模型</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650737338&amp;idx=1&amp;sn=34c5cab8287b2138b7f80ff730fe2cd0&amp;chksm=871acec4b06d47d299d3a72ec955d0353b690f8734c61ae864d1054a90c5f07a6cdc0f9fe380&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">快速开启你的第一个项目：TensorFlow项目架构模板</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726048&amp;idx=1&amp;sn=492ccde81a2ca2a344f995c5f92a3107&amp;chksm=871b1adeb06c93c87b81f9c6a9e6e041e01a2885949d16e8a7e758a26a0237421b59257de7a4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">TensorFlow初学者指南：如何为机器学习项目创建合适的文件架构</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723520&amp;idx=2&amp;sn=53680fb4b709beb19b28d071907958fe&amp;chksm=871b10beb06c99a8993cd1729197bb05ab5f341359bf21fd6b3d3f134f51051d948265ca4abb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 七个小贴士，顺利提升TensorFlow模型训练表现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731491&amp;idx=3&amp;sn=0c75c7d4c476031ced5ae40b972fb6b3&amp;chksm=871b379db06cbe8b26e51e83a9d870c09e270d00b17c54b826fde937abd7544f8198dcf2b231&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何从TensorFlow转入PyTorch</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732373&amp;idx=5&amp;sn=62ce53bbfe4532126420861745a6f96f&amp;chksm=871b332bb06cba3dbcbff490767c965dd3432e0bb14c56e9a1c40b24b7db701b197aeb29d53b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何利用C++搭建个人专属的TensorFlow</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724206&amp;idx=1&amp;sn=2f5d695bdd080d0d005875021a6752ea&amp;chksm=871b1310b06c9a064c716b53e18157373289213408b3c92ed250d18d5228fc60cbc421d07983&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">谷歌云大会教程：没有博士学位如何玩转TensorFlow和深度学习（附资源）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729714&amp;idx=2&amp;sn=8aac55a04ca9aabd774c8b813ea50494&amp;chksm=871b288cb06ca19a424d929d32fd54e462dc62d3a0353960a25825f00587721d78af1640792b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 维度、广播操作与可视化：如何高效使用TensorFlow</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729690&amp;idx=3&amp;sn=3cd89df0bbece3930b4a88e4dae08669&amp;chksm=871b28a4b06ca1b2542539d36f6a306038141ee3d1a296ecad1d08cd5e4908b4589ae91d04b4&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | PyTorch内部机制解析：如何通过PyTorch实现Tensor</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725703&amp;idx=1&amp;sn=d8094022c03672cdc1c088f3409774a9&amp;chksm=871b1939b06c902fe05502b68eb15536f4e4d38021050c52c607baccf2977cc8c80b61cd3579&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">贾扬清撰文详解Caffe2：从强大的新能力到入门上手教程</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726389&amp;idx=3&amp;sn=cfb5761a2eae87b423390e4a459b1c12&amp;chksm=871b1b8bb06c929d918d958e2d6ecc71f20c3f8955677c8ea1580e7ba17cfc334a1740c23b2a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | TensorFlow 官方解读：如何在多系统和网络拓扑中构建高性能模型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730716&amp;idx=3&amp;sn=1fb5cd9028ff08f10e2cbc9a9dc25f14&amp;chksm=871b34a2b06cbdb462d1adad0ef6cd2758bab429cfd072ba9be3850d3037302ada21f1e795cc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用TensorFlow中的高级API：Estimator、Experiment和Dataset</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730929&amp;idx=4&amp;sn=e17df54969506e0aa2840f760815d24e&amp;chksm=871b35cfb06cbcd916283ee7035801aa1d8c717f3c3c9bc138c22fdb17029f99d8c6c6f2a918&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Docker Compose + GPU + TensorFlow 所产生的奇妙火花</a></li>
</ul>
<h4 id="工具方法"><a href="#工具方法" class="headerlink" title="工具方法"></a>工具方法</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736232&amp;idx=4&amp;sn=3332215f55785b316965f1c004d74508&amp;chksm=871ac216b06d4b006805a43097b9d94f6c2ed3e247817370de03fde0ffd835a50996b3594158&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何优雅而高效地使用Matplotlib实现数据可视化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733784&amp;idx=2&amp;sn=6d8b2f4268083235e2a0060f412759c5&amp;chksm=871b38a6b06cb1b0b005f0b6512723747c2686ed9ec826dc6e9e785b681f7b9e0fbfbccead00&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用百度深度学习框架PaddlePaddle做数据预处理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733750&amp;idx=2&amp;sn=5420df0c2ccd9ee5fd8906483551f53d&amp;chksm=871b38c8b06cb1de36475e9965290661da8ca748b05f7d63c9cfc0d2819b95aba0a425195869&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 一文入门Python数据分析库Pandas</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733523&amp;idx=1&amp;sn=445df1a0c8ccc3b39c8dbb2bb148a08b&amp;chksm=871b3fadb06cb6bb1c6bc91eb4bb1978f77f6c80e1dbe39f211ad1e1cacee48a5e4ef2a3b0ed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">代码优化指南：人生苦短，我用Python</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732472&amp;idx=4&amp;sn=1fe80480abdaf6f66c442d68e111cebf&amp;chksm=871b33c6b06cbad070ef7d336b44d8021f68129114155244866c6a5075d63a342c0481b7e9d3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 从数组到矩阵的迹，NumPy常见使用大总结</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728951&amp;idx=2&amp;sn=a299c07c5d621ae55f9727e1f3af24ce&amp;chksm=871b2d89b06ca49f0791a6acbda06e8bcfe1a435a703e02f2b38da0667736848aa6267f5be2c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Python代码优化指南：从环境设置到内存分析（一）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731852&amp;idx=3&amp;sn=ebdf5a6ea339264fbaec150902359e7d&amp;chksm=871b3132b06cb824cd80e446c0eecb8f814c2fa7469fde4dd2ddcb9599ab6d728f2cb5c4eddb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 如何利用VGG-16等模型在CPU上测评各深度学习框架</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731954&amp;idx=2&amp;sn=0fd2d0276bba664710d6ac6c8d5bdcb5&amp;chksm=871b31ccb06cb8dae1729d6eb1f043635015f2b16a6f76bcd77aa0f77ad19d5fca61532e6958&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 手把手教你可视化交叉验证代码，提高模型预测能力</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727887&amp;idx=3&amp;sn=c95b0a5137ae25a3d9ece41208917187&amp;chksm=871b21b1b06ca8a7acaa4971bed1dd97a4eb4d2a4ec440d615f08ee298706268b57640be0540&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用Kubernetes GPU集群自动训练和加速深度学习？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736429&amp;idx=2&amp;sn=6421643f152771aa8ebb6c78db598f47&amp;chksm=871ac353b06d4a457bdd0a98fe86c8f259e7ca03e1b8a512fd394b461602ab6c28786a9adf60&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | Prophet：教你如何用加法模型探索时间序列数据</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733548&amp;idx=1&amp;sn=0d8388ea530acc77418acdd35274e119&amp;chksm=871b3f92b06cb68476247cea7bc28fa98cc4fee9ec67a415a95ee29260be7c5ddeb6ff3dab21&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">初学机器学习的你，是否掌握了这样的Linux技巧？</a></li>
</ul>
<h4 id="云端"><a href="#云端" class="headerlink" title="云端"></a>云端</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725146&amp;idx=4&amp;sn=7d9be4cb07b0cd7967afbc08d9f2f19c&amp;chksm=871b1f64b06c9672b6b5f9addbe855cdd667f4beff7d40418e9e199d3b88a9217e08134b5615&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 新手指南：如何在AWS GPU上运行Jupyter noterbook？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733632&amp;idx=4&amp;sn=0a3ca577582086225b406a56a2dc2c56&amp;chksm=871b383eb06cb128fe95c4317934b8bd9c3cee81c5d0707bc7ea1ad65d488112aee2b573d7da&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 只需15分钟，使用谷歌云平台运行Jupyter Notebook</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735484&amp;idx=2&amp;sn=b777fbf5c1449c6cf9a44e1a3ee854fe&amp;chksm=871ac702b06d4e1430e11be7ce62f23482d39cb054dc572b759a45ff7329aff34dce21207e4f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">入门 | 完全云端运行：使用谷歌CoLaboratory训练神经网络</a></li>
</ul>
<h4 id="边缘设备"><a href="#边缘设备" class="headerlink" title="边缘设备"></a>边缘设备</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726048&amp;idx=3&amp;sn=bd73de47cd65a1772c2df027cabd6a5c&amp;chksm=871b1adeb06c93c89ce7d9b45c1636a80a397871f119b0f316f426e01e804e8d86dc9f6399fc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | BerryNet：如何在树莓派上实现深度学习智能网关</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728605&amp;idx=1&amp;sn=38451fe201d44bef51684ac7ab5a7173&amp;chksm=871b2ce3b06ca5f574de4b1620b3f3eda96832068be920a65dd5d17734433bd2adda18ea455e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">机器之心实操 | 亚马逊详解如何使用MXNet在树莓派上搭建实时目标识别系统</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725442&amp;idx=1&amp;sn=e47020aa77c347753eb453deded29364&amp;chksm=871b183cb06c912a33be69a4321f5aeca0d6f9b4a93b0f7bb1717553bbc0ec12b7ae62a57001&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">手把手教你为iOS系统开发TensorFlow应用（附开源代码）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727685&amp;idx=2&amp;sn=1bd2b0ca546474957a856c9614f2353d&amp;chksm=871b217bb06ca86d35fcc93a0d84e2a2067dbbe8743d91ea2adf7422dfc4bdc86a7595cde33b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用Swift在iOS 11中加入原生机器学习视觉模型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726773&amp;idx=2&amp;sn=074c4b365962e6e64a953a5002d9351f&amp;chksm=871b250bb06cac1de2cf004725ac0214acb9710d3ac48fea703d419ea2f3ad328d20ddbeda37&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用谷歌Mobile Vision API 开发手机应用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728570&amp;idx=3&amp;sn=b8b12344ac610095843410e3d81d5915&amp;chksm=871b2c04b06ca512c177de40df14f11c14c4f57e0106b161ee6b0bb21ebba71929cbd2f5e7a0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">开源 | 深度安卓恶意软件检测系统：用卷积神经网络保护你的手机</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727250&amp;idx=2&amp;sn=2cedf785cd4c67837c599c5251c8e4ea&amp;chksm=871b272cb06cae3a9d6718392aa6dbd7c6854f730d564b377e64c66fb208da3a681ec75339cd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">专栏 | 手机端运行卷积神经网络实践：基于TensorFlow和OpenCV实现文档检测功能</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727657&amp;idx=4&amp;sn=a74a473464ab36fcce848612106c9ebc&amp;chksm=871b2097b06ca981fdf3b63495c42dff165e1a29fb895e47f1c87978c252db35597308af994d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 用苹果Core ML实现谷歌移动端神经网络MobileNet</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733805&amp;idx=2&amp;sn=9d94635aab0021e6ff6cb1d7dce53ab1&amp;chksm=871b3893b06cb185a8fc669f9dbec690fa906b13831397b04e1f7b11da3ce70b83f863398a9f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用TensorFlow在安卓设备上实现深度学习推断</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730538&amp;idx=2&amp;sn=7194725505b51df09bc1b97666f33ddb&amp;chksm=871b3454b06cbd42dfe80ff80b799e542633b5cba1caca451502189d5166f1924f0014a2ba1e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 向手机端神经网络进发：MobileNet压缩指南</a></li>
</ul>
<h4 id="硬件-1"><a href="#硬件-1" class="headerlink" title="硬件"></a>硬件</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723604&amp;idx=1&amp;sn=70c6bf533b17b2fc842f5926ec9d35c4&amp;chksm=871b116ab06c987c53e92273e3d18398ac17c1744c5b972b497dfcf47cea8fa81fadf2bf18b8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">成本14,000元，如何自己动手搭建深度学习服务器？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729976&amp;idx=5&amp;sn=1224a97983426a94218e2af68809dc1b&amp;chksm=871b2986b06ca09084c687d27f6aec8c496fdfde4a969323c9a5f697b8e9ca414e5f2fa548a1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 只需1200美元，打造家用型深度学习配置（CPU+GTX 1080）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650727504&amp;idx=3&amp;sn=e70e50e3925afc63d2449ed0a70e5b5a&amp;chksm=871b202eb06ca938b3f0a6573fb2da54aed5e836cece48840c8c72a89cd36794559a7611ee48&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从硬件配置、软件安装到基准测试，1700美元深度学习机器构建指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733409&amp;idx=1&amp;sn=54586bb7afd80cf0fcb546031ec17d04&amp;chksm=871b3f1fb06cb609aff00bbae7ce4a9ad704ab4d055cac0c3d0f25fd6c7f609408e9331bcbeb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从硬件配置到框架选择，请以这种姿势入坑深度学习</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731550&amp;idx=1&amp;sn=0ad49b4f74046456d806655b36659ba8&amp;chksm=871b3060b06cb9761b6016c083413d33ec5333fd520deb1264aca45f469f1125d381376cf973&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">从零开始：深度学习软件环境安装指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731653&amp;idx=1&amp;sn=b29bebb3fc6f69cd27ff826fd1d74f2c&amp;chksm=871b30fbb06cb9ed25474ff7aa39879465182b56356692b9b9bde9f10a313dc92950f385ef75&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">这是一份你们需要的Windows版深度学习软件安装指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724442&amp;idx=4&amp;sn=02fecb6ad48224b4448a927c4b19fcc6&amp;chksm=871b1c24b06c953200c41f2d3ff320018b750e7a96cffad5e46bf08dcd571dcd3b631728f44e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 一步步从零开始：使用PyCharm和SSH搭建远程TensorFlow开发环境</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724485&amp;idx=1&amp;sn=d05d9efe3b066c135d26264f7e8d22a6&amp;chksm=871b1cfbb06c95ed8bbbf573ba8b6fa6e1d518625608a78ce19aa6cd1db9020901cea217ec41&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">实用指南：如何为你的深度学习任务挑选最合适的 GPU?（最新版）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725299&amp;idx=2&amp;sn=e8dad54dfb885789a910f20042e93589&amp;chksm=871b1fcdb06c96dbd1cd19febc37838ebb09737135965f7c3d5297deaa3cb668ee4b2be6025e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 英伟达Titan Xp出现后，如何为深度学习挑选合适的GPU？这里有份性价比指南</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733678&amp;idx=1&amp;sn=fbb22bf76392a49a49545ec371f69474&amp;chksm=871b3810b06cb1069bf35e024863e823da08026bd13a1ae890c4e528a5cfe8d2ef008d6aead6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Titan XP值不值？一文教你如何挑选深度学习GPU</a></li>
</ul>
<h4 id="吃喝玩乐撸撸猫"><a href="#吃喝玩乐撸撸猫" class="headerlink" title="吃喝玩乐撸撸猫"></a>吃喝玩乐撸撸猫</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=3&amp;sn=88f89ee39a145f4bf0c0add7a42fa4ca&amp;chksm=871b114eb06c985809a27507310d1d1394f908c9cd231d3bf0c9180f462d2fedd1a60f505ab6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 你来手绘涂鸦，人工智能生成「猫片」：edges2cats图像转换详解</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728794&amp;idx=2&amp;sn=426052e5cd7d952902b6623e40df16de&amp;chksm=871b2d24b06ca4323d055668db51590703c45966149e0849d1dd92771bc28d2b5e24c1b4ec5d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 萌物生成器：如何使用四种GAN制造猫图</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729957&amp;idx=4&amp;sn=bdeb666588a1e926e2802b2daf3c2836&amp;chksm=871b299bb06ca08db37816a9b8bce1d38ddf957f25f37bd39fb6e9ce2da5c1120373a2a1e888&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">学界 | 宅男的福音：用GAN自动生成二次元萌妹子</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729251&amp;idx=2&amp;sn=286437bff7106ddfb056ba56ee465191&amp;chksm=871b2f5db06ca64b771a8e748535f51e5c3a5f947228fc84f91d5e2da665b2bb900908efe5f8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 如何使用神经网络弹奏出带情感的音乐？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731918&amp;idx=4&amp;sn=a0ae86a539e0d64ac4cf4cf42978a54d&amp;chksm=871b31f0b06cb8e6ddebe71db7dfaa45c31ac8213962c4036d1fd14321417ecf4471fc89b4cf&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">深度 | 人工智能如何帮你找到好歌：探秘Spotify神奇的每周歌单</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725277&amp;idx=3&amp;sn=a0b08a2b34b1d1af93b960339665f781&amp;chksm=871b1fe3b06c96f5b06b69b3cf9b8ef31345f30e65ee7e7b2c36942ae4c3e0b489655e762c9b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">解读 | 艺术家如何借助神经网络进行创作？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735464&amp;idx=3&amp;sn=211899c0c8f2b51f10ce9bf5132f2c82&amp;chksm=871ac716b06d4e00c882c684feb9aa9374c44798f0b30d34c10a5b6c0da6c6af88d276910fa6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 用生成对抗网络给雪人上色，探索人工智能时代的美学</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735191&amp;idx=4&amp;sn=320f57ea1a09591d70a524f323398f49&amp;chksm=871ac629b06d4f3f883b29d3d2fcf1356c4e1d79347289cbdfe0142e637b3c8418fc1bfbea5e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">圣诞快乐——Keras+树莓派：用深度学习识别圣诞老人</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731669&amp;idx=2&amp;sn=d59bb91f70250ca79ca6c349d2a80204&amp;chksm=871b30ebb06cb9fd0e1e0ca2eaba6f3a5a2ec4a6a9d14b3c1dc3b5401e5854156de72242a31d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 摄影爱好者玩编程：利用Python和OpenCV打造专业级长时曝光摄影图</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733162&amp;idx=2&amp;sn=12ea91e0f9aa58aa9a03ede7ace7ff2b&amp;chksm=871b3e14b06cb702aec83e6377f81b86d90aef54df40713c64eb806ae34794972b70c0b45dc9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 基于遗传算法的拼图游戏解决方案</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735815&amp;idx=3&amp;sn=9e8d36ead9ab2ca0d1771f51a255a18f&amp;chksm=871ac0b9b06d49afbcddb7237a8083b22fda6d7419eb32a9c4dcab8ffc79d173c78e935a90d1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | AI玩微信跳一跳的正确姿势：跳一跳Auto-Jump算法详解</a></li>
</ul>
<h4 id="Money-Money-Money"><a href="#Money-Money-Money" class="headerlink" title="Money, Money, Money"></a>Money, Money, Money</h4><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731602&amp;idx=2&amp;sn=8537108d6fdccad8701ce64165513e7d&amp;chksm=871b302cb06cb93aac5939f95da6360c0724bb303a17e5b0bf95eb45044eaeaa8e2ac12a9dfb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 从零开始：如何使用LSTM预测汇率变化趋势</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733162&amp;idx=1&amp;sn=5b642582edb5131d5fe4637c614cd5e7&amp;chksm=871b3e14b06cb70279f864366a3de1742a6044eaad992bdd30a31ba33eeedeec35d112a2018c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">自创数据集，使用TensorFlow预测股票入门</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733548&amp;idx=4&amp;sn=e4783b546c5a00bd4f17245844c120d9&amp;chksm=871b3f92b06cb684ecc39c1327d48d1b86c0fdc5a51c60d5afce42cfc0380e75d590725e90f3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">资源 | 利用深度强化学习框架解决金融投资组合管理问题（附 GitHub 实现）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650733632&amp;idx=1&amp;sn=ccc28937465f5ed4cb8ebb076af1a70e&amp;chksm=871b383eb06cb1289e64726b1dbeabc90bb7dd01bdcdd7bbe5e1a034068b6eb06063d44da48a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">比特币突破8000美元，我们找到了用DL预测虚拟货币价格的方法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735191&amp;idx=3&amp;sn=3da4096e96f16949a08468709bc17437&amp;chksm=871ac629b06d4f3fc63358a1fc6f59c3f77e1235d845d7c4bb4872a60b1e85dbd82165148b7d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何使用深度学习硬件的空余算力自动挖矿</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728678&amp;idx=3&amp;sn=7df9c0cb6abddb724e7e589ad5d0ea96&amp;chksm=871b2c98b06ca58ec4b2461bf3d2be31c40943973242868e98451d623c8d361095c536bff446&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">教程 | 如何用Python和机器学习炒股赚钱？</a></li>
</ul>
<hr>
<h3 id="最流行的神经网络变体综述-链接"><a href="#最流行的神经网络变体综述-链接" class="headerlink" title="最流行的神经网络变体综述 链接"></a>最流行的神经网络变体综述 <a href="http://www.asimovinstitute.org/neural-network-zoo/" target="_blank" rel="noopener">链接</a></h3>]]></content>
      
        <categories>
            
            <category> 资源 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 资源汇总 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习中的模型评价与选择]]></title>
      <url>/2018/02/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
      <content type="html"><![CDATA[<p>介绍机器学习中如何评估、选择模型</p>
<ul>
<li>Holdout方法和正态逼近置信区间</li>
<li>重复Holdout和Bootstrap</li>
<li>交叉验证和超参数优化</li>
<li>结论</li>
</ul>
<a id="more"></a>
<p>节选自机器之心 <a href="https://mp.weixin.qq.com/s/zs9ihUFI-ixP4EgMTvnFBg" target="_blank" rel="noopener">链接</a>，原文还涉及很多偏数学、理论方面的东西<br>英文原文 <a href="https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf" target="_blank" rel="noopener">链接</a></p>
<hr>
<h3 id="机器学习模型的性能估计主要分为以下三步"><a href="#机器学习模型的性能估计主要分为以下三步" class="headerlink" title="机器学习模型的性能估计主要分为以下三步"></a><strong>机器学习模型的性能估计主要分为以下三步</strong></h3><ul>
<li>使用训练集训练模型</li>
<li>用模型预测测试集的分类</li>
<li>计算在测试集上的错误率</li>
</ul>
<h3 id="Holdout方法"><a href="#Holdout方法" class="headerlink" title="Holdout方法"></a><strong>Holdout方法</strong></h3><ul>
<li><strong>Holdout</strong>是最简单的模型评估技术，把数据集随机拆分成训练集和测试集</li>
<li><strong>Resubstitution验证</strong>或<strong>Resubstitution评估</strong>指的是在同一个训练数据集上训练和评估一个模型</li>
<li>随机抽样可能导致训练集和测试集分布不平衡，甚至测试集中可能不包含少数类的样本。因此，可以使用<strong>层次化</strong>的方式划分数据集，保证划分得到的训练集和测试集保持原始比例</li>
<li>在数据量大、类别较平衡的数据集上，非层次化的随机抽样不是一个大问题，但最好还是使用层次化抽样</li>
<li><strong>正态逼近置信区间</strong>：计算模型预测精度或计算误差置信区间。假设预测结果会遵循一个正态分布，然后根据中心极限定理计算单次训练-测试划分的平均值的置信区间。通过正态逼近计算出基于单个测试集的性能估计的不确定性。详细推导见原文</li>
</ul>
<h3 id="重复Holdout和Bootstrap"><a href="#重复Holdout和Bootstrap" class="headerlink" title="重复Holdout和Bootstrap"></a><strong>重复Holdout和Bootstrap</strong></h3><ul>
<li><strong>模型评估的偏差与方差</strong>：将数据集的较多数据作为测试集容易给评估带来悲观偏差。随着测试集样本数量的减少，悲观偏差降低，性能估计的方差增加<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/Model.png"></li>
<li><strong>重复Holdout验证</strong>：多次随机划分训练集和测试集，重复Holdout方法估计模型性能然后取平均值的方法获得更具鲁棒性的评估，又称为蒙特卡洛交叉验证</li>
<li><strong>Bootstrap方法</strong>：从经验分布中采样生成新样本，衡量性能估计的不确定性。如果把Holdout方法理解为不放回采样，那么bootstrap就可以理解为通过有放回重采样产生新数据<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/boot.png"></li>
<li><strong>Leave-one-out Bootstrap（LOOB）方法</strong>：这种方法测试集数据和训练集数据没有重叠<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/boot1.png">
</li>
</ul>
<h3 id="交叉验证和超参数优化"><a href="#交叉验证和超参数优化" class="headerlink" title="交叉验证和超参数优化"></a><strong>交叉验证和超参数优化</strong></h3><ul>
<li><strong>three-way Holdout方法</strong>：将数据集划分为训练、验证和测试集三部分，用于超参数调优<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/超参.png"></li>
<li><strong>K-Fold交叉验证</strong>：数据集中的每个样本都有被测试的机会。与重复holdout方法相比，k-fold交叉验证的测试数据没有重叠，而重复holdout是重复使用样本进行测试<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/K-Fold.png">
<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/K-fold选择.png"></li>
<li><strong>2-fold和留一法（Leave-One-Out）交叉验证</strong>：分别是K-Fold交叉验证中k=2和k=n的特殊情况。留一交叉验证法中，每次迭代中，模型都在其中n-1个样本上进行拟合，然后在剩余的一个样本上进行评估。这种方法对<strong>小数据集</strong>特别有用<img src="/2018/02/16/深度学习/机器学习中的模型评价与选择/2-fold.png"></li>
<li>在计算可行的情况下，留一法交叉验证更值得推荐，近似无偏，但方差大；当数据集很大的时候，出于计算效率的考虑我们就会更倾向于holdout方法（相当于分成2部分，迭代2次即可），<strong>我们在深度学习中使用的就是Holdout方法而不是交叉验证</strong></li>
<li>在k-fold交叉验证中，随着k的增加有如下趋势：<blockquote>
<p>性能估计偏差减小（更准确）<br>性能估计方差增大（更大的变化性）<br>计算成本增加（在拟合过程中训练集更大，需要的迭代次数更多）<br>在k-fold交叉验证中将k的值降到最小（如2或3）也会增加小数据集上模型估计的方差，因为随机抽样变化较大<br>推荐用<strong>10折交叉验证</strong></p>
</blockquote>
</li>
<li><strong>如果我们对数据归一化或进行特征选择，我们通常会在k-fold交叉验证循环中执行这些操作</strong>，即做归一化时不考虑测试集部分的数据，但可能效果不好。关于这一选择可参考<a href="http://www.aaai.org/Papers/Workshops/2007/WS-07-05/WS07-05-007.pdf" target="_blank" rel="noopener">链接</a>。看了以后感觉不是很有所谓，差异不大(“for the greater majority of cases, IN and OUT are not significantly different”)</li>
</ul>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><ul>
<li>当处理的样本量较大时，使用holdout方法进行模型评价非常合适</li>
<li>对于超参数优化，推荐10折交叉验证</li>
<li>对于小样本，留一法交叉验证则是一个不错的选择</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 模型评估 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[深度学习技巧]]></title>
      <url>/2018/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E5%B7%A7/</url>
      <content type="html"><![CDATA[<p>在这里总结一下看到过的各路炼丹技巧</p>
<a id="more"></a>
<h3 id="深度学习的7大实用技巧-链接"><a href="#深度学习的7大实用技巧-链接" class="headerlink" title="深度学习的7大实用技巧* 链接"></a><strong>深度学习的7大实用技巧*</strong> <a href="https://mp.weixin.qq.com/s/geCFcJDvOAw2Jaf2_nWsrg" target="_blank" rel="noopener">链接</a></h3><ul>
<li><strong>数据</strong>：有标签的数据越多，模型的性能越好。<a href="https://arxiv.org/abs/1707.02968" target="_blank" rel="noopener">重温深度学习时代数据不可思议的有效性</a><img src="/2018/02/14/深度学习/深度学习技巧/data.png"></li>
<li><p><strong>优化器</strong>：RMSprop，Adadelta和Adam法都是自适应优化算法，会自动更新学习率。普通的随机梯度下降法需要手动选择学习率和动量参数。</p>
<blockquote>
<p>在实践中，自适应优化器往往比普通的梯度下降法<strong>更快地让模型达到收敛状态</strong>。然而，选择这些优化器的模型<strong>最终性能都不太好</strong>，而普通的梯度下降法通常能够达到更好的收敛最小值，从而获得<strong>更好的模型性能</strong>，但这可能比某些优化程序<strong>需要更多的收敛时间</strong>。此外，随机梯度下降法也更依赖于有效的初始化方法和学习速率衰减指数的设置，这在实践中是很难确定的。如下图，Adam初期效果好，但SGD在训练结束后可以获得更好的全局最小值</p>
<img src="/2018/02/14/深度学习/深度学习技巧/SGD.png">
<p>可以混合使用两类优化器：由Adam优化器过渡到随机梯度下降法来优化模型。在训练的早期阶段，使用Adam优化器来启动模型的训练，这将为模型的训练节省很多参数初始化和微调的时间。一旦模型的性能有所起伏，我们就可以切换到带动量的随机梯度下降法来进一步优化模型，以达到最佳的性能</p>
</blockquote>
</li>
<li><p><strong>处理数据不平衡</strong>：不同类的训练数据数量差异较大，会使得预测结果倾向于数量大的类别。</p>
<blockquote>
<p> 对损失函数使用类别权重：对于数据量小的类别，损失函数中使用较高的权重值。这样对该类的任何错误都将导致非常大的损失值，以此来惩罚错误分类<br>过度抽样：对于小样本类别，重复进行采样<br>欠采样：对于大样本类别，跳过不选择部分数据<br>数据增强：对于小样本类别进行数据增强，生成更多训练样本  </p>
</blockquote>
</li>
<li><strong>迁移学习</strong><img src="/2018/02/14/深度学习/深度学习技巧/transfer.png"></li>
<li><strong>数据增强</strong>：保证数据原始类别标签的同时，对一些原始图像进行非线性的图像变换，来生成/合成新的训练样本。即对图像进行任何操作，改变图像的外观，但不能改变整体的内容。如对于猫的图像，我们可以把图像进行任意的几何变换，只要还是一只猫，那么label就不会变，<strong>但在图像以外的问题上能否直接使用数据增强有待进一步查阅资料</strong><blockquote>
<p>水平或垂直旋转/翻转图像<br>随机改变图像的亮度和颜色<br>随机模糊图像<br>随机裁剪图像</p>
</blockquote>
</li>
<li><strong>集成模型</strong>：对于一个特定的任务，训练多个模型并根据模型的整体性能决定最优的组合方案。具体的实现细节还不太清楚，但模型集成有三种比较典型的方式：<a href="http://blog.csdn.net/google19890102/article/details/46507387" target="_blank" rel="noopener">链接</a>。<strong>下2中有关于集成的几种常见设计</strong><img src="/2018/02/14/深度学习/深度学习技巧/集成.png"></li>
<li><strong>模型剪枝加速</strong>：目的是为了在提高训练速度的同时保持模型的高性能，目前已有许多相关的研究，如<a href="https://arxiv.org/pdf/1704.04861.pdf" target="_blank" rel="noopener">MobileNet</a>等等。核心思想是按照一定标准为神经元进行排序，从而将排名低(即冗余的神经元，对模型贡献不大)的移除模型，也就是把不重要的卷积滤波器丢弃(因为神经元和卷积核一一对应)<blockquote>
<p>一般的剪枝流程如下：Network -&gt; Evaluate Importance of Neurons -&gt; Remove the Least Important Neuron -&gt; Fine-tuning -&gt; Continue Pruning -&gt; Back to Evaluate Importance of Neurons  </p>
</blockquote>
</li>
</ul>
<hr>
<h3 id="知乎专栏"><a href="#知乎专栏" class="headerlink" title="知乎专栏"></a><a href="https://zhuanlan.zhihu.com/easyml" target="_blank" rel="noopener">知乎专栏</a></h3><ul>
<li><strong>参数初始化</strong>：<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Xavier</a>和<a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">He</a>随便选一个，但一定要做<blockquote>
<p>uniform均匀分布初始化：w = np.random.uniform(low=-scale, high=scale, size=[n_in,n_out])</p>
<pre><code>Xavier初始法，适用于普通激活函数(tanh,sigmoid)：scale = np.sqrt(3/n)
He初始化，适用于ReLU：scale = np.sqrt(6/n)
</code></pre><p>normal高斯分布初始化：w = np.random.randn(n_in,n_out) * stdev # stdev为高斯分布的标准差，均值设为0</p>
<pre><code>Xavier初始法，适用于普通激活函数 (tanh,sigmoid)：stdev = np.sqrt(n)
He初始化，适用于ReLU：stdev = np.sqrt(2/n)
</code></pre><p>svd初始化：对RNN有比较好的效果。参考论文：<a href="https://arxiv.org/abs/1312.6120" target="_blank" rel="noopener">https://arxiv.org/abs/1312.6120</a></p>
</blockquote>
</li>
<li><strong>数据预处理</strong><blockquote>
<p>常用：zero-center</p>
<pre><code>X -= np.mean(X, axis = 0) # zero-center
X /= np.std(X, axis = 0) # normalize
</code></pre><p>不常用：白化</p>
</blockquote>
</li>
<li><strong>训练技巧</strong><blockquote>
<ul>
<li>要做<strong>梯度归一化</strong>，即算出来的梯度除以minibatch size</li>
<li><strong>clip c(梯度裁剪)</strong>: 限制最大梯度，其实是value = sqrt(w1^2+w2^2….)。如果value超过了阈值，就算一个衰减系系数，让value的值等于阈值: 5,10,15</li>
<li><strong>Dropout</strong>对小数据防止过拟合有很好的效果，值一般设为0.5。小数据上dropout+sgd效果提升都非常明显。dropout的位置比较有讲究, 对于RNN,建议放到输入-&gt;RNN与RNN-&gt;输出的位置。关于RNN如何用dropout,可以参考<a href="http://arxiv.org/abs/1409.2329" target="_blank" rel="noopener">论文</a></li>
<li><strong>优化器</strong>：同1中所述，SGD收敛慢，但结果好。对于SGD，可以选择从1.0或者0.1的学习率开始，隔一段时间在验证集上检查一下，如果cost没有下降，就对学习率减半。也可以先用ada系列先跑，最后快收敛的时候，更换成sgd继续训练，同样也会有提升。据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好</li>
<li>除了gate之类的地方需要把输出限制成0-1之外，<strong>尽量不要用sigmoid</strong>。可以用tanh或者relu之类的激活函数。sigmoid的问题: 1. sigmoid函数在-4到4的区间里，才有较大的梯度。其他区间的梯度接近0，很容易造成梯度消失问题。2. 如果输入是0均值的，sigmoid函数的输出不是0均值的</li>
<li>rnn的<strong>dim</strong>和<strong>embdding size</strong>，一般从128上下开始调整。<strong>batch size</strong>一般从128左右开始调整，合适最重要，并不是越大越好。关于Batch Size设置的分析可参考这篇<a href="http://blog.csdn.net/ycheng_sjtu/article/details/49804041" target="_blank" rel="noopener">文章</a>。对于batch，建议是把卡塞满的2的n次方</li>
<li><strong>word2vec初始化</strong>，在小数据上不仅可以有效提高收敛速度，也可以可以提高结果</li>
<li>尽量对数据做<strong>shuffle</strong></li>
<li><strong>LSTM的forget gate的bias</strong>，用1.0或者更大的值做初始化可以取得更好的结果，来自这篇<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">论文</a>。实际使用中，不同的任务可能需要尝试不同的值</li>
<li>使用<strong>Batch Normalization</strong>可以提升效果</li>
<li>如果模型包含全连接层（MLP），且输入和输出大小一样，可以考虑<strong>将MLP替换成Highway Network</strong>，对结果有一点提升，建议作为最后提升模型的手段。原理很简单，就是给输出加了一个gate来控制信息的流动，详细介绍请参考<a href="http://arxiv.org/abs/1505.00387" target="_blank" rel="noopener">论文</a></li>
<li><strong>一轮加正则，一轮不加正则</strong>，反复进行</li>
</ul>
</blockquote>
</li>
<li><strong>Ensemble(模型集成)</strong><blockquote>
<p>Ensemble是论文刷结果的终极核武器，一般有以下几种方式：</p>
<ul>
<li>同样的参数，不同的初始化方式</li>
<li>不同的参数，通过cross-validation，选取最好的几组</li>
<li>同样的参数，模型训练的不同阶段，即不同迭代次数的模型</li>
<li>不同的模型，进行线性融合。例如RNN和传统模型</li>
</ul>
</blockquote>
</li>
</ul>
<hr>
<h3 id="知乎回答"><a href="#知乎回答" class="headerlink" title="知乎回答"></a><a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">知乎回答</a></h3><ul>
<li><strong>Relu+Bn</strong>可以满足95%的情况，除非有些特殊情况会用identity，比如回归问题，比如resnet的shortcut支路</li>
<li><strong>Dropout</strong>，分类问题用dropout ，只需要最后一层softmax 前用基本就可以了，能够防止过拟合，可能对accuracy提高不大，但是dropout 前面的那层如果是之后要使用的feature的话，性能会大大提升</li>
<li><strong>数据的shuffle和augmentation</strong>，aug不能瞎加，比如行人识别一般就不会加上下翻转的，因为不会碰到头朝下的异型种</li>
<li><strong>降学习率</strong>，随着网络训练的进行，学习率要逐渐降下来。如果用tensorboard就能发现，在学习率下降的一瞬间，网络会有个巨大的性能提升。同样的fine-tuning也要根据模型的性能设置合适的学习率，比如一个训练的已经非常好的模型你上来就1e-3的学习率，那之前就白训练了，就是说网络性能越好，学习率要越小</li>
<li><strong>tensorboard</strong>，帮助你监视网络的状态，来调整网络参数</li>
<li><strong>随时存档模型，要有validation</strong>。把每个epoch和其对应的validation 结果存下来，可以分析出开始overfitting的时间点，方便下次加载fine-tuning</li>
<li><strong>网络层数</strong>，参数量什么的都不是大问题，在性能不丢的情况下，减到最小。<strong>（不是说网络越深越好？）</strong></li>
<li>对于batch size，建议是把卡塞满的2的n次方</li>
<li>输入减不减mean归一化在有了bn之后已经不那么重要了</li>
<li>卷积核的分解。从最初的5×5分解为两个3×3，到后来的3×3分解为1×3和3×1，再到resnet的1×1，3×3，1×1，再xception的3×3 channel-wise conv+1×1，网络的计算量越来越小，层数越来越多，性能越来越好，这些都是设计网络时可以借鉴的</li>
<li>不同尺寸的feature maps的concat，只用一层的feature map一把梭可能不如concat好，pspnet就是这种思想，这个思想很常用</li>
<li>resnet的shortcut确实会很有用，重点在于shortcut支路一定要是identity，主路是什么conv都无所谓，这是我亲耳听resnet作者所述</li>
<li>针对于metric learning，对feature加个classification 的约束通常可以提高性能加快收敛</li>
</ul>
<hr>
<h3 id="链接和链接"><a href="#链接和链接" class="headerlink" title="链接和链接"></a><a href="https://www.zhihu.com/question/27962483" target="_blank" rel="noopener">链接</a>和<a href="https://www.zhihu.com/question/25097993" target="_blank" rel="noopener">链接</a></h3><hr>
<p>Loss曲线：如果loss趋于平稳，但是没有降到足够低，随着learning rate的进一步降低，loss还可能继续减小。把test(validation)的accurcy也放在同一张图中，查看何时过拟合，参看<a href="https://www.linuxidc.com/Linux/2016-11/136774p19.htm" target="_blank" rel="noopener">链接</a>。loss波动大的，考虑减小lr</p>
]]></content>
      
        <categories>
            
            <category> 深度学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 炼丹技巧 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[六大聚类算法]]></title>
      <url>/2018/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%85%AD%E5%A4%A7%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>介绍六类主流的聚类算法，并总结了相应的优缺点</p>
<ul>
<li>K-Means</li>
<li>均值漂移聚类</li>
<li>基于密度的聚类方法（DBSCAN）</li>
<li>用高斯混合模型（GMM）的最大期望（EM）聚类</li>
<li>凝聚层次聚类</li>
<li>图团体检测</li>
</ul>
<a id="more"></a>
<p>原文来自机器之心 <a href="https://mp.weixin.qq.com/s/_5A3DuVyN6aE9n5OEc19kA" target="_blank" rel="noopener">链接</a><br>序号写成”.”格式全部崩了。。把分隔符去掉又显得太挤了。。。以后找到办法了再回来改TAT</p>
<h3 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a><strong>K-Means</strong></h3> <img src="/2018/02/12/深度学习/六大聚类算法/K-Means.png">
<ul>
<li>优点：速度快，O(N)</li>
<li>缺点：类别数需要事先人为估计，无法通过算法来确定类别数；结果有可能不可重复</li>
<li>变种：K-Medians，每次用中值向量而不是均值来作为中心。对异常值不敏感，对大数据集速度慢，因为需要做排序</li>
</ul>
<hr>
<h3 id="均值漂移聚类"><a href="#均值漂移聚类" class="headerlink" title="均值漂移聚类"></a><strong>均值漂移聚类</strong></h3><ul>
<li>算法：随机选择n个中心点，有n个半径为r的圆形滑动窗口，同时开始迭代。每次迭代时，滑动窗口的中心点都不断移向窗口内所有点的均值点，也就是<strong>移向点密度更大的区域</strong>，直到收敛(点密度无法再增加)。收敛时，若多个窗口发生重叠时，保留点数最多的那个窗口。这样就可以得到类别数以及每个类的中心位置。其他各个点属于哪一类则取决于迭代过程中该点在哪一类的窗口中的次数最多<img src="/2018/02/12/深度学习/六大聚类算法/Meanshift.png"></li>
<li>优点：类别数量由算法自动获得；聚类中心朝最大点密度聚集的事实也是非常令人满意的</li>
<li>缺点：窗口大小/半径「r」的选择可能是不重要的</li>
</ul>
<hr>
<h3 id="基于密度的聚类方法（DBSCAN）"><a href="#基于密度的聚类方法（DBSCAN）" class="headerlink" title="基于密度的聚类方法（DBSCAN）"></a><strong>基于密度的聚类方法（DBSCAN）</strong></h3><ul>
<li>算法：每次从一个未被访问过的数据点开始，若该点的邻域(ε 距离内的所有点都是邻域点)内点的数量大于参数minPoints，则该点为一个新类的第一个点，否则该点就是噪声点。若该点成为了一个新类的第一个点，则该点邻域内的所有点也成为了该类的一部分，同时以这些新点再去找它们邻域中的点并加到该类中来，直到收敛。收敛后，在未被访问过的点中再找一个重新开始之前的步骤<img src="/2018/02/12/深度学习/六大聚类算法/DBSCAN.png"></li>
<li>优点：不需要人为确定类别数；能够辨别噪声；能很好地找到任意大小和任意形状的类</li>
<li>缺点：当簇的密度不同时，它的表现不如其他聚类算法(因为密度不同，参数ε和minPoints的设置也需要不一样，难以估计)</li>
</ul>
<hr>
<h3 id="用高斯混合模型（GMM）的最大期望（EM）聚类"><a href="#用高斯混合模型（GMM）的最大期望（EM）聚类" class="headerlink" title="用高斯混合模型（GMM）的最大期望（EM）聚类"></a><strong>用高斯混合模型（GMM）的最大期望（EM）聚类</strong></h3><ul>
<li>K-Means中假设数据点的分布是圆形的(其分类原理是离哪个中心点更近就认为是哪一类)，限制较大。GMM中假设数据点是高斯分布的，意味着类可以是各种类型的形状(二维中为椭圆，因为x和y方向各自有标准差)。于是，任务就变成了<strong>使用EM来找到每个类别的高斯函数</strong>。下图是典型的K-Means不适用的情况：<img src="/2018/02/12/深度学习/六大聚类算法/EM.png"></li>
<li>算法：和K-Means一样，先选择类别数量，并随机初始化高斯分布参数。随后计算每个数据点属于一个特定类的概率(一个点越靠近高斯的中心，它就越可能属于该类)。基于这些概率，计算一组新的高斯分布参数使得类内数据点的概率最大化。其中，新参数是由数据点位置的加权和得到，权重就是之前提到的概率。重复之前的操作直到收敛<img src="/2018/02/12/深度学习/六大聚类算法/EM2.png"></li>
<li>优点：类形状任意(K-Means其实是GMM的一个特殊情况，即所有维度的协方差均接近0)；由于GMM使用概率，因此每个数据点可以属于很多类，且对于每个类都有一个相应的概率</li>
</ul>
<hr>
<h3 id="凝聚层次聚类"><a href="#凝聚层次聚类" class="headerlink" title="凝聚层次聚类"></a><strong>凝聚层次聚类</strong></h3><ul>
<li>层次聚类分为自上而下和自下而上。对于自下而上，每个数据点都是单独的一个类，随后<strong>不断合并两个类</strong>，直到所有类最后都合并成一个包含所有数据点的类。自下而上层次聚类又被称为凝聚式层次聚类(HAC)。<img src="/2018/02/12/深度学习/六大聚类算法/HAC.png"></li>
<li>算法：一开始有N个数据点，也就是N个类。随后自行定义一种距离度量标准如平均距离等，每次迭代时选择将两个距离最近的类合并在一起，直到只剩下一个类。我们只需要选择何时停止合并，就可以选择最终需要多少个类</li>
<li>优点：不需要指定类个数，我们可以自由选择看起来最好的类个数；对距离度量标准不敏感；</li>
<li>缺点：效率低，O(N^2)</li>
</ul>
<hr>
<h3 id="图团体检测（Graph-Community-Detection）"><a href="#图团体检测（Graph-Community-Detection）" class="headerlink" title="图团体检测（Graph Community Detection）"></a>图团体检测（Graph Community Detection）</h3><ul>
<li>当我们的数据可以被表示为一个网络或图（graph）时，我们可以使用图团体检测方法完成聚类。聚类的质量由<strong>模块性分数</strong>进行评估，模块性越高，该网络聚类成不同团体的程度就越好。因此通过最优化方法寻找最大模块性就能发现聚类该网络的最佳方法。<img src="/2018/02/12/深度学习/六大聚类算法/Graph.png"></li>
<li>模块性可以使用以下公式进行计算：<img src="/2018/02/12/深度学习/六大聚类算法/Graph1.png"></li>
<li>其中L代表网络中边的数量，k_i和k_j是指每个顶点的degree，它可以通过将每一行和每一列的项加起来而得到。两者相乘再除以2L表示当该网络是随机分配的时候顶点i和j之间的预期边数。括号中的项表示了该网络的真实结构和随机组合时的预期结构之间的差。当A_ij==1且(k_i*k_j)/2L很小时，其返回的值最高。即当在定点i和j之间存在一个「非预期」的边时，得到的值更高。最后的δc_i, c_j是克罗内克δ函数（Kronecker-delta function）。</li>
<li>优点：在典型的结构化数据中和现实网状数据都有非常好的性能</li>
<li>缺点：会忽略一些小的集群，且只适用于结构化的图模型</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 无监督学习 </tag>
            
            <tag> 聚类 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[cs231n学习笔记]]></title>
      <url>/2018/02/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cs231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>把cs231n 2017年的课程重新刷一遍，记录相关的笔记</p>
<ul>
<li><a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">cs231n课程主页</a></li>
<li><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">cs231n课程大纲</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv" target="_blank" rel="noopener">cs231n课程视频</a></li>
</ul>
<a id="more"></a>
<h1 id="Lecture-2-Image-Classification"><a href="#Lecture-2-Image-Classification" class="headerlink" title="Lecture 2 Image Classification"></a>Lecture 2 Image Classification</h1><h2 id="课程资源"><a href="#课程资源" class="headerlink" title="课程资源"></a>课程资源</h2><h3 id="Course-Materials"><a href="#Course-Materials" class="headerlink" title="Course Materials"></a>Course Materials</h3><ul>
<li><a href="http://cs231n.github.io/python-numpy-tutorial/" target="_blank" rel="noopener">python/numpy tutorial</a></li>
<li><a href="http://cs231n.github.io/classification/" target="_blank" rel="noopener">image classification notes</a></li>
</ul>
<h3 id="Course-Materials-翻译"><a href="#Course-Materials-翻译" class="headerlink" title="Course Materials 翻译"></a>Course Materials 翻译</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit" target="_blank" rel="noopener">Python Numpy教程</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit" target="_blank" rel="noopener">图像分类笔记</a></li>
</ul>
<h2 id="课程笔记"><a href="#课程笔记" class="headerlink" title="课程笔记"></a>课程笔记</h2><h3 id="Python-Numpy"><a href="#Python-Numpy" class="headerlink" title="Python Numpy"></a>Python Numpy</h3><h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><ul>
<li>python –version        # 查看Python版本</li>
<li>Python没有x++和x—的操作符</li>
<li><strong>布尔逻辑</strong>：and；or；not；!=(xor)</li>
<li><strong>字符串</strong>：<a href="http://link.zhihu.com/?target=https%3A//docs.python.org/2/library/stdtypes.html%23string-methods" target="_blank" rel="noopener">文档</a><ul>
<li>hw = ‘hello’ + ‘ ‘ + ‘world’  </li>
<li>hw = ‘%s %s %d’ % (hello, world, 12)  </li>
<li>print(s.capitalize())        # 把第一个字母变大写，其余小写  </li>
<li>print(s.upper())          # 全部大写  </li>
<li>print(s.rjust(7))          # 右对齐，最左端不足补空格  </li>
<li>print(s.center(7))        # 居中对齐  </li>
<li>print(s.replace(‘l’, ‘(ell)’))    # 替换  </li>
<li>print(‘  world ‘.strip())    # 去掉空格</li>
</ul>
</li>
<li><p><strong>容器</strong>：<a href="https://docs.python.org/2/tutorial/datastructures.html#more-on-lists" target="_blank" rel="noopener">文档</a></p>
<ul>
<li><strong>列表Lists</strong>：Python中的数组，但是列表长度可变，能包含不同类型元素<pre><code>xs = [3, 1, 2]   # 创建一个列表
print xs, xs[2]  # 输出：&quot;[3, 1, 2] 2&quot;
print xs[-1]     # 即xs[2]
xs[2] = &apos;foo&apos;    # 列表可以容纳不同类型的元素
print xs         # 输出：&quot;[3, 1, &apos;foo&apos;]&quot;
xs.append(&apos;bar&apos;) # 向列表末尾中加元素
print xs         # 输出：&quot;[3, 1, &apos;foo&apos;, &apos;bar&apos;]&quot;
x = xs.pop()     # 移除最后列表最后一个元素，并返回该元素
print x, xs      # 输出：&quot;bar [3, 1, &apos;foo&apos;]&quot;
xs = xs + [&quot;fig&quot;, &quot;melon&quot;]    # 添加元素可以直接&quot;+&quot;或用append
my_list_copy = my_list    # list在变量中存的是引用，这样赋值的话两个变量对应的是同一片内存地址
my_list_copy = list(my_list)
my_list_copy = my_list[:]    # 以上两种是复制列表中的值而不是引用
</code></pre></li>
<li>切片Slicing：用于获取列表中的元素，语法list[start_index: end_index: step]<pre><code>nums = range(5)    # range是一个内置函数，创建一个列表，包含0到5的integer
print nums         # 输出：&quot;[0, 1, 2, 3, 4]&quot;
print nums[2:4]    # 获得一个索引从2到4（不包括4）的切片; 输出：&quot;[2, 3]&quot;
print nums[2:]     # 获得一个索引从2到末尾的切片; 输出：&quot;[2, 3, 4]&quot;
print nums[:2]     # 获得一个索引从开头到2（不包括2）的切片; 输出：&quot;[0, 1]&quot;
print nums[:]      # 获得一个索引全部元素的切片; 输出：&quot;[0, 1, 2, 3, 4]&quot;
print nums[:-1]    # 切片的索引也可以是负数; 输出：&quot;[0, 1, 2, 3]&quot;
nums[2:4] = [8, 9] # 把一个列表赋值给一个切片
print nums         # 输出：&quot;[0, 1, 8, 8, 4]&quot;
</code></pre></li>
<li><p>循环Loops</p>
<pre><code>animals = [&apos;cat&apos;, &apos;dog&apos;, &apos;monkey&apos;]
for animal in animals:
    print animal
# 输出：&quot;cat&quot;, &quot;dog&quot;, &quot;monkey&quot;, 一个一行

animals = [&apos;cat&apos;, &apos;dog&apos;, &apos;monkey&apos;]
for idx, animal in enumerate(animals):
    print &apos;#%d: %s&apos; % (idx + 1, animal)
# 输出：&quot;#1: cat&quot;, &quot;#2: dog&quot;, &quot;#3: monkey&quot;, 一个一行
</code></pre></li>
<li>列表推导List comprehensions：避免通过循环等操作去对列表元素赋值<pre><code>nums = [0, 1, 2, 3, 4]
even_squares = [x ** 2 for x in nums if x % 2 == 0]
print even_squares  
# 输出：&quot;[0, 4, 16]&quot;
</code></pre></li>
<li><strong>字典Dictionaries</strong>：<a href="https://docs.python.org/2/library/stdtypes.html#dict" target="_blank" rel="noopener">文档</a><pre><code>d = {&apos;cat&apos;: &apos;cute&apos;, &apos;dog&apos;: &apos;furry&apos;}  # 创建字典
print d[&apos;cat&apos;]       # 输出：&quot;cute&quot;
print &apos;cat&apos; in d     # 检测字典中是否有&apos;cat&apos;的索引; 输出：&quot;True&quot;
d[&apos;fish&apos;] = &apos;wet&apos;    # 在字典中添加一个条目
print d[&apos;fish&apos;]      # 输出：&quot;wet&quot;
# print d[&apos;monkey&apos;]  # KeyError: &apos;monkey&apos; not a key of d
print d.get(&apos;monkey&apos;, &apos;N/A&apos;)  # Get an element with a default; 输出：&quot;N/A&quot;
print d.get(&apos;fish&apos;, &apos;N/A&apos;)    # Get an element with a default; 输出：&quot;wet&quot;
del d[&apos;fish&apos;]        # 把&apos;fish&apos;:&apos;wet&apos;条目从字典中去掉
print d.get(&apos;fish&apos;, &apos;N/A&apos;) # 字典中没有fish这个索引了; 输出：&quot;N/A&quot;
</code></pre></li>
<li><p>循环Loops</p>
<pre><code>d = {&apos;person&apos;: 2, &apos;cat&apos;: 4, &apos;spider&apos;: 8}
for animal in d:
    legs = d[animal]
    print &apos;A %s has %d legs&apos; % (animal, legs)
# 输出：&quot;A person has 2 legs&quot;, &quot;A spider has 8 legs&quot;, &quot;A cat has 4 legs&quot;

d = {&apos;person&apos;: 2, &apos;cat&apos;: 4, &apos;spider&apos;: 8}
for animal, legs in d.iteritems():
    print &apos;A %s has %d legs&apos; % (animal, legs)
# 输出：&quot;A person has 2 legs&quot;, &quot;A spider has 8 legs&quot;, &quot;A cat has 4 legs&quot;
</code></pre></li>
<li>字典推导Dictionary comprehensions：与列表类似<pre><code>nums = [0, 1, 2, 3, 4]
even_num_to_square = {x: x ** 2 for x in nums if x % 2 == 0}
print even_num_to_square  
# 输出：&quot;{0: 0, 2: 4, 4: 16}&quot;
</code></pre></li>
<li><strong>集合Sets</strong>：<a href="https://docs.python.org/2/library/sets.html#set-objects" target="_blank" rel="noopener">文档</a>        <pre><code>animals = {&apos;cat&apos;, &apos;dog&apos;} # 创建集合
print &apos;cat&apos; in animals   # 检测集合中是否有&apos;cat&apos;; 输出：&quot;True&quot;
print &apos;fish&apos; in animals  # 输出：&quot;False&quot;
animals.add(&apos;fish&apos;)      # 往集合里加&apos;fish&apos;
print &apos;fish&apos; in animals  # 输出：&quot;True&quot;
print len(animals)       # 集合元素数量; 输出：&quot;3&quot;
animals.add(&apos;cat&apos;)       # 往集合中添加已有的元素，什么都不会做
print len(animals)       # 输出：&quot;3&quot;
animals.remove(&apos;cat&apos;)    # 从集合中移除&apos;cat&apos;
print len(animals)       # 输出：&quot;2&quot;
</code></pre></li>
<li><strong>元组Tuples</strong>：<a href="https://docs.python.org/2/tutorial/datastructures.html#tuples-and-sequences" target="_blank" rel="noopener">文档</a><pre><code>d = {(x, x + 1): x for x in range(10)}  # Create a dictionary with tuple keys
print d
t = (5, 6)       # Create a tuple
print type(t)    # Prints &quot;&lt;type &apos;tuple&apos;&gt;&quot;
print d[t]       # Prints &quot;5&quot;
print d[(1, 2)]  # Prints &quot;1&quot;
# 可以作为字典的索引，也可以作为集合的元素
</code></pre></li>
</ul>
</li>
</ul>
<h4 id="Numpy-文档"><a href="#Numpy-文档" class="headerlink" title="Numpy 文档"></a>Numpy <a href="https://docs.scipy.org/doc/numpy/reference/" target="_blank" rel="noopener">文档</a></h4><ul>
<li>科学计算库</li>
<li>创建数组 <a href="https://docs.scipy.org/doc/numpy/user/basics.creation.html#arrays-creation" target="_blank" rel="noopener">文档</a><pre><code>a = np.array([1, 2, 3])  
b = np.array([[1,2,3],[4,5,6]])
a = np.zeros((2,2))     
                        # Prints &quot;[[ 0.  0.]
                        #          [ 0.  0.]]&quot;
b = np.ones((1,2))    
                        # Prints &quot;[[ 1.  1.]]&quot;
c = np.full((2,2), 7)    
                        # Prints &quot;[[ 7.  7.]
                        #          [ 7.  7.]]&quot;
d = np.eye(2)            
                        # Prints &quot;[[ 1.  0.]
                        #          [ 0.  1.]]&quot;
e = np.random.random((2,2))        
                        # Might print &quot;[[ 0.91940167  0.08143941]
                        #               [ 0.68744134  0.87236687]]&quot;
</code></pre></li>
<li><p>访问数组 <a href="https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html" target="_blank" rel="noopener">文档</a></p>
<ul>
<li><p>切片</p>
<pre><code>a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])
# [[ 1  2  3  4]
#  [ 5  6  7  8]
#  [ 9 10 11 12]]

b = a[:2, 1:3]
# [[2 3]
#  [6 7]]
# 修改b数组也会改变a数组

row_r1 = a[1, :]    # &quot;[5 6 7 8] (4,)&quot;
row_r2 = a[1:2, :]    # &quot;[[5 6 7 8]] (1, 4)&quot;
# row_r1会导致得到的数组比原数组阶数低
</code></pre></li>
<li><p>整形数组</p>
<pre><code>a = np.array([[1,2], [3, 4], [5, 6]])
print a[[0, 1, 2], [0, 1, 0]]        # 与np.array([a[0, 0], a[1, 1], a[2, 0]])等价

a = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])
b = np.array([0, 2, 0, 1])
print a[np.arange(4), b]
# 输出：&quot;[1  6  7 11]&quot;，即a[0, 0]; a[1, 2]; a[2, 0]; a[3, 1]
</code></pre></li>
<li>布尔数组访问<pre><code>a = np.array([[1,2], [3, 4], [5, 6]])
bool_idx = (a &gt; 2) 
                    # Prints &quot;[[False False]
                    #          [ True  True]
                    #          [ True  True]]&quot;
print a[bool_idx]      # Prints &quot;[3 4 5 6]&quot;；等价于a[a &gt; 2]
</code></pre></li>
</ul>
</li>
<li>x.dtype查看数据类型 <a href="https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html" target="_blank" rel="noopener">文档</a></li>
<li><p>数据计算 <a href="https://docs.scipy.org/doc/numpy/reference/routines.math.html" target="_blank" rel="noopener">函数文档</a>；<a href="https://docs.scipy.org/doc/numpy/reference/routines.array-manipulation.html" target="_blank" rel="noopener">数组操作文档</a></p>
<pre><code>x = np.array([[1,2],[3,4]], dtype=np.float64)
y = np.array([[5,6],[7,8]], dtype=np.float64)

print np.add(x, y)
print np.subtract(x, y)
print np.multiply(x, y)        # 逐个相乘，不是矩阵乘法
print np.divide(x, y)
print np.sqrt(x)

v = np.array([9, 10])
w = np.array([11, 12])
print v.dot(w)        # 向量内积；等价于np.dot(v, w)
print x.dot(y)        # 矩阵乘法

print np.sum(x)        # 1+2+3+4=10
print np.sum(x, axis=0)        # 计算每列的sum; &quot;[4, 6]&quot;
print np.sum(x, axis=1)        # 计算每行的sum; &quot;[3, 7]&quot;

print x.True        # 转置
</code></pre></li>
<li><p>广播Broadcasting：让不同大小的矩阵直接在一起进行数学计算 <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html" target="_blank" rel="noopener">文档</a></p>
<pre><code>import numpy as np
x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])
v = np.array([1, 0, 1])
y = x + v  # 使用广播把v加到x的每一行中
print y  
# &quot;[[ 2  2  4]
#   [ 5  5  7]
#   [ 8  8 10]
#   [11 11 13]]&quot;
</code></pre><p> <strong>广播规则</strong></p>
<ol>
<li>如果数组的秩不同，使用1来将秩较小的数组进行扩展，直到两个数组的尺寸的长度都一样。</li>
<li>如果两个数组在某个维度上的长度是一样的，或者其中一个数组在该维度上长度为1，那么我们就说这两个数组在该维度上是相容的。</li>
<li>如果两个数组在所有维度上都是相容的，他们就能使用广播。</li>
<li>如果两个输入数组的尺寸不同，那么注意其中较大的那个尺寸。因为广播之后，两个数组的尺寸将和那个较大的尺寸一样。</li>
<li>在任何一个维度上，如果一个数组的长度为1，另一个数组长度大于1，那么在该维度上，就好像是对第一个数组进行了复制。</li>
</ol>
</li>
<li><p>广播例子</p>
<pre><code>import numpy as np

v = np.array([1,2,3])  # v has shape (3,)
w = np.array([4,5])    # w has shape (2,)
print np.reshape(v, (3, 1)) * w        # 矩阵乘法
# [[ 4  5]
#  [ 8 10]
#  [12 15]]
# 首先v变成(3,1)，而w是(2,)，即(1,2)，两者广播运算后，维度为(3,2)

x = np.array([[1,2,3], [4,5,6]])
print x + v
# [[2 4 6]
#  [5 7 9]]
# x是(2,3)，v是(3,)/(1,3)，广播后为(2,3)

print (x.T + w).T
# [[ 5  6  7]
#  [ 9 10 11]]
# x.T为(3,2)，w为(1,2)，相加后为(3,2)，再转置得到(2,3)

print x + np.reshape(w, (2, 1))
# 和上面的表达式等价，把w变形后可以直接广播相加

print x * 2
# [[ 2  4  6]
#  [ 8 10 12]]
# 对矩阵乘一个常数        
</code></pre></li>
</ul>
<h4 id="Scipy-文档"><a href="#Scipy-文档" class="headerlink" title="Scipy 文档"></a>Scipy <a href="https://docs.scipy.org/doc/scipy/reference/" target="_blank" rel="noopener">文档</a></h4><ul>
<li><p>图像操作</p>
<pre><code>from scipy.misc import imread, imsave, imresize

# Read an JPEG image into a numpy array
img = imread(&apos;assets/cat.jpg&apos;)
print img.dtype, img.shape  # Prints &quot;uint8 (400, 248, 3)&quot;

# We can tint the image by scaling each of the color channels
# by a different scalar constant. The image has shape (400, 248, 3);
# we multiply it by the array [1, 0.95, 0.9] of shape (3,);
# numpy broadcasting means that this leaves the red channel unchanged,
# and multiplies the green and blue channels by 0.95 and 0.9
# respectively.
img_tinted = img * [1, 0.95, 0.9]

# Resize the tinted image to be 300 by 300 pixels.
img_tinted = imresize(img_tinted, (300, 300))

# Write the tinted image back to disk
imsave(&apos;assets/cat_tinted.jpg&apos;, img_tinted)
</code></pre></li>
<li><p>Matlab文件读写(scipy.io.loadmat/scipy.io.savemat) <a href="http://link.zhihu.com/?target=http%3A//docs.scipy.org/doc/scipy/reference/io.html" target="_blank" rel="noopener">文档</a></p>
</li>
<li><p>点之间的距离 <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html" target="_blank" rel="noopener">文档</a></p>
<pre><code>import numpy as np
from scipy.spatial.distance import pdist, squareform

# Create the following array where each row is a point in 2D space:
# [[0 1]
#  [1 0]
#  [2 0]]
x = np.array([[0, 1], [1, 0], [2, 0]])
print x

# Compute the Euclidean distance between all rows of x.
# d[i, j] is the Euclidean distance between x[i, :] and x[j, :],
# and d is the following array:
# [[ 0.          1.41421356  2.23606798]
#  [ 1.41421356  0.          1.        ]
#  [ 2.23606798  1.          0.        ]]
d = squareform(pdist(x, &apos;euclidean&apos;))
print d
</code></pre></li>
</ul>
<h4 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h4><ul>
<li><p>作图库</p>
<pre><code># [plot文档](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot)
import numpy as np
import matplotlib.pyplot as plt

# Compute the x and y coordinates for points on a sine curve
x = np.arange(0, 3 * np.pi, 0.1)
y_sin = np.sin(x)
y_cos = np.cos(x)

# Plot the points using matplotlib
plt.plot(x, y_sin)
plt.plot(x, y_cos)
plt.xlabel(&apos;x axis label&apos;)
plt.ylabel(&apos;y axis label&apos;)
plt.title(&apos;Sine and Cosine&apos;)
plt.legend([&apos;Sine&apos;, &apos;Cosine&apos;])
plt.show()
</code></pre> <img src="/2018/02/11/深度学习/cs231n学习笔记/作图.png">
<pre><code># 使用subplot在一张图中画多幅图；[subplot文档](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplot)
import numpy as np
import matplotlib.pyplot as plt

# Compute the x and y coordinates for points on sine and cosine curves
x = np.arange(0, 3 * np.pi, 0.1)
y_sin = np.sin(x)
y_cos = np.cos(x)

# Set up a subplot grid that has height 2 and width 1,
# and set the first such subplot as active.
plt.subplot(2, 1, 1)

# Make the first plot
plt.plot(x, y_sin)
plt.title(&apos;Sine&apos;)

# Set the second subplot as active, and make the second plot.
plt.subplot(2, 1, 2)
plt.plot(x, y_cos)
plt.title(&apos;Cosine&apos;)

# Show the figure.
plt.show()
</code></pre> <img src="/2018/02/11/深度学习/cs231n学习笔记/作图2.png">
<pre><code># 绘制双Y轴曲线图
x = np.arange(0., np.e, 0.01)
y1 = np.exp(-x)
y2 = np.log(x)

fig = plt.figure()

ax1 = fig.add_subplot(111)
ax1.plot(x, y1)
ax1.set_ylabel(&apos;Y values for exp(-x)&apos;)
ax1.set_title(&quot;Double Y axis&quot;)

ax2 = ax1.twinx()  # this is the important function
ax2.plot(x, y2, &apos;r&apos;)
ax2.set_xlim([0, np.e])
ax2.set_ylabel(&apos;Y values for ln(x)&apos;)
ax2.set_xlabel(&apos;Same X for both exp(-x) and ln(x)&apos;)

plt.show()
</code></pre> <img src="/2018/02/11/深度学习/cs231n学习笔记/作图3.png">
<pre><code># 图像读入与显示(imread/imwrite)
import numpy as np
from scipy.misc import imread, imresize
import matplotlib.pyplot as plt

img = imread(&apos;assets/cat.jpg&apos;)
img_tinted = img * [1, 0.95, 0.9]

# Show the original image
plt.subplot(1, 2, 1)
plt.imshow(img)

# Show the tinted image
plt.subplot(1, 2, 2)

# A slight gotcha with imshow is that it might give strange results
# if presented with data that is not uint8. To work around this, we
# explicitly cast the image to uint8 before displaying it.
plt.imshow(np.uint8(img_tinted))
plt.show()
</code></pre></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 深度学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 公开课 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Pytorch学习]]></title>
      <url>/2018/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Pytorch%E5%AD%A6%E4%B9%A0/</url>
      <content type="html"><![CDATA[<p>记录一下Pytorch学习过程以及踩过的一些坑</p>
<ul>
<li><a href="http://pytorch.org/docs/master/" target="_blank" rel="noopener">Pytorch官方文档</a></li>
<li><a href="http://pytorch.org/tutorials/" target="_blank" rel="noopener">Pytorch官方教程</a></li>
<li><a href="https://pytorch-cn.readthedocs.io/zh/latest/" target="_blank" rel="noopener">中文文档</a></li>
</ul>
<a id="more"></a>
<p>由于教程中有太多的代码了，因此这里就只记录看过的内容的索引，方便以后自己写代码的时候回来找</p>
<h3 id="60分钟教程-链接"><a href="#60分钟教程-链接" class="headerlink" title="60分钟教程 链接"></a>60分钟教程 <a href="http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html#" target="_blank" rel="noopener">链接</a></h3><h4 id="What-is-Pytorch"><a href="#What-is-Pytorch" class="headerlink" title="What is Pytorch"></a>What is Pytorch</h4><ul>
<li>介绍Tensors</li>
<li>对于Tensor的操作<blockquote>
<p>view改变Tensor维度</p>
</blockquote>
</li>
<li>Tensor和Numpy的相互转化<blockquote>
<p>Torch的Tensor和Numpy数组使用的是同一块内存空间，改变其中一个也会影响另一个（指的是Numpy数组的内容是用a.numpy()赋值给b的情况）</p>
</blockquote>
</li>
<li>把Tensor移到GPU</li>
</ul>
<h4 id="Autograd-automatic-differentiation（用于反向传播）"><a href="#Autograd-automatic-differentiation（用于反向传播）" class="headerlink" title="Autograd: automatic differentiation（用于反向传播）"></a>Autograd: automatic differentiation（用于反向传播）</h4><ul>
<li>Variable<blockquote>
<p>Variable是核心类，包含Tensor并支持在Tensor上的一切操作。记录了一系列操作<br>.data访问数据；.grad访问梯度(如x.grad访问的是目标函数对于x的梯度)；.grad_fn涉及创建该变量的函数(如b=a+2，那么b.grad_fn就是a+2这个函数)，若变量是人为直接定义的，那.grad_fn就是None</p>
</blockquote>
</li>
<li>Gradients<blockquote>
<p>If you want to compute the derivatives, you can call .backward() on a Variable. If Variable is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to backward(), however if it has more elements, you need to specify a grad_output argument that is a tensor of matching shape.<br>上面那段话在教程中相关的例子：</p>
<pre><code>out.backward() # is equivalent to doing out.backward(torch.Tensor([1.0]))

gradients = torch.FloatTensor([0.1, 1.0, 0.0001])
y.backward(gradients)
# 相当于求得的梯度中，不同维度的值会乘上0.1/1.0/0.0001
</code></pre></blockquote>
</li>
</ul>
<h4 id="Neural-Networks（搭建网络）"><a href="#Neural-Networks（搭建网络）" class="headerlink" title="Neural Networks（搭建网络）"></a>Neural Networks（搭建网络）</h4><ul>
<li>Define the network<blockquote>
<p>只需要定义forward，backward会自动计算<br>获取参数：params = list(net.parameters())；访问参数值：net.conv1.weight/bias<br>零初始化梯度：net.zero_grad</p>
</blockquote>
</li>
<li>Loss Function &amp; Backprop<blockquote>
<p>查看梯度信息（图）：loss.grad_fn / loss.grad_fn.next_functions[0][0] (print输出以后是MseLossBackward object at 0x7fe4c18539e8)<br>查看梯度值：net.conv1.bias.grad</p>
</blockquote>
</li>
<li>Update the weights<blockquote>
<p>不用手动实现weight的更新，直接调用torch.optim中的优化算法SGD、Adam等<br>softmax包含在CrossEntropyLoss里面了</p>
</blockquote>
</li>
<li>使用param_groups访问优化器中的参数，如学习率(optimizer.param_groups[‘lr’])等 <a href="http://blog.csdn.net/u012436149/article/details/70666068" target="_blank" rel="noopener">链接</a></li>
</ul>
<h4 id="Training-a-classifier（完整的一个训练例子）"><a href="#Training-a-classifier（完整的一个训练例子）" class="headerlink" title="Training a classifier（完整的一个训练例子）"></a>Training a classifier（完整的一个训练例子）</h4><ul>
<li>What about data?<blockquote>
<p>把数据利用各种库导入到numpy array，再转化到torch的Tensor<br>对于computer vision，Pytorch有一个torchvision库，里面有针对ImageNet、mnist等数据集的dataloader和data transformer</p>
</blockquote>
</li>
</ul>
<h4 id="Data-Parallelism（多GPU并行计算）"><a href="#Data-Parallelism（多GPU并行计算）" class="headerlink" title="Data Parallelism（多GPU并行计算）"></a>Data Parallelism（多GPU并行计算）</h4><hr>
<h3 id="Data-Loading-and-Processing-Tutorial-链接"><a href="#Data-Loading-and-Processing-Tutorial-链接" class="headerlink" title="Data Loading and Processing Tutorial 链接"></a>Data Loading and Processing Tutorial <a href="http://pytorch.org/tutorials/beginner/data_loading_tutorial.html" target="_blank" rel="noopener">链接</a></h3><h4 id="Dataset-class"><a href="#Dataset-class" class="headerlink" title="Dataset class"></a>Dataset class</h4><ul>
<li>必须继承Dataset(torch.utils.data.Dataset)</li>
<li>必须覆盖__len__和__getitem__两个方法，getitem的使用方式就是a[i]；len的使用方式是len(dataset)</li>
<li>给的example的数据集有一个csv和一堆图片，csv中有图片的名称。建议构造函数(__init__)中只读csv文件(相当于索引)，具体对图片的读取放到__getitem__中，按需要读取    </li>
</ul>
<h4 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h4><ul>
<li>dataset中transform参数可选，根据需求可以自己写一些变换，如改变图像大小、data augmentation等</li>
<li>tsfm = Transform(params)</li>
<li>transformed_sample = tsfm(sample)</li>
</ul>
<h4 id="Iterating-through-the-dataset"><a href="#Iterating-through-the-dataset" class="headerlink" title="Iterating through the dataset"></a>Iterating through the dataset</h4><ul>
<li>torch.utils.data.DataLoader是一个迭代器，提供batching the data、shuffling the data、load the data in parallel功能</li>
</ul>
<hr>
<h3 id="Transfer-Learning-tutorial-链接"><a href="#Transfer-Learning-tutorial-链接" class="headerlink" title="Transfer Learning tutorial 链接"></a>Transfer Learning tutorial <a href="http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" target="_blank" rel="noopener">链接</a></h3><ul>
<li>Finetuning the convnet：先在ImageNet上训练，再在自己的数据集上对该模型进行微调</li>
<li>ConvNet as fixed feature extractor：把FC层之前的都当作一个固定的特征提取器，只调整最后几层全连接层</li>
<li>划分了train和val集</li>
<li>若不要更新，则.requires_grad = False</li>
</ul>
<hr>
<h3 id="Visualization-链接"><a href="#Visualization-链接" class="headerlink" title="Visualization 链接"></a>Visualization <a href="http://www.pytorchtutorial.com/using-visdom-for-visualization-in-pytorch/" target="_blank" rel="noopener">链接</a></h3><hr>
<h3 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h3><ul>
<li>x.view(-1, 8)是改变x的维度，如原来x是16*1，有16个元素，使用view(-1, 8)后为了保证还是16个元素，-1那一维就是16/8=2</li>
<li>torch.nn只支持mini-batches，即所有的图像数据格式必须是batch * channel * height * width，因为nn.Conv2d的输入需要是这样的，如果是FC，那么可能不需要channel那一维。但batch维必须要有，如果只有一个batch，那就用input = input.unsqueeze(0)添加batch维</li>
<li>训练的循环里，要把Tensor转换成Variable之后再送进网络，即inputs = Variable(inputs)</li>
<li>若要用GPU训练，需要net.cuda()以及inputs = Variable(inputs.cuda())，即把网络和输入输出都放到GPU当中</li>
<li>似乎把numpy转成Tensor后，还要指定是FloatTensor，即input = input.type(torch.FloatTensor)</li>
<li>numpy的图像矩阵储存格式是H * W * C，而Tensor是C * H * W，转换的时候要image = image.transpose((2, 0, 1))</li>
<li>conv1D卷积核的输入维度是Batch_size * Channels * H * W；Linear全连接的输入维度是Batch_size * 维度</li>
<li>label是从0开始计数，注意自己的dataset中的label值</li>
<li>pytorch的CrossEntropyLoss不含正则项，且是平均loss，求总loss的时候还要乘上batch_size（手算验证过）</li>
<li>用matplotlib绘制曲线时，注意x和y都需要是numpy的，不然就np.array(loss)[x]</li>
</ul>
<hr>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ul>
<li>若数据集太小，小于Batch_size，有没有办法能一次把数据集读2遍？好像dataloader不支持</li>
</ul>
<hr>
<h3 id="优质资源"><a href="#优质资源" class="headerlink" title="优质资源"></a>优质资源</h3><ul>
<li>关于参数初始化和Finetune <a href="http://blog.csdn.net/u012759136/article/details/65634477" target="_blank" rel="noopener">链接</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 深度学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Welcome to my blog]]></title>
      <url>/2018/02/09/%E9%9A%8F%E7%AC%94/Welcome-to-my-blog/</url>
      <content type="html"><![CDATA[<p>一直想搞个博客，但是一直懒得搞，拖延癌晚期/(ㄒoㄒ)/~~。。之前搞过一个jekyll的，这次想了想还是换hexo了</p>
<a id="more"></a>
<h3 id="搭建细节"><a href="#搭建细节" class="headerlink" title="搭建细节"></a>搭建细节</h3><p>主要参考了<a href="http://blog.csdn.net/gdutxiaoxu/article/details/53576018" target="_blank" rel="noopener">http://blog.csdn.net/gdutxiaoxu/article/details/53576018</a></p>
<p>大致流程如下：</p>
<ul>
<li>安装node.js</li>
<li>本地安装Hexo</li>
<li>配置Hexo</li>
<li>把Hexo和Github Page联系</li>
</ul>
<p>随后就是换主题、搞一下私人定制的事情啦，接下来几天慢慢看看官方文档，把这个博客做的好看一点o(<em>￣▽￣</em>)ブ</p>
<hr>
<h3 id="2018-02-10-update"><a href="#2018-02-10-update" class="headerlink" title="2018-02-10 update"></a>2018-02-10 update</h3><p>新添站内搜索功能、生成站点地图功能，参考<a href="https://www.ezlippi.com/blog/2017/02/hexo-search.html" target="_blank" rel="noopener">https://www.ezlippi.com/blog/2017/02/hexo-search.html</a><br>**删除安装的插件直接npm unistall 插件名即可<br>根据官方文档通过修改_config.yml添加了一系列功能</p>
<hr>
<h3 id="2018-02-12-update"><a href="#2018-02-12-update" class="headerlink" title="2018-02-12 update"></a>2018-02-12 update</h3><p>在博文中添加图片，参考<a href="https://www.jianshu.com/p/cf0628478a4e" target="_blank" rel="noopener">链接</a><br>在博文中的写法：<br>Markdown中写注释，参考<a href="https://www.jianshu.com/p/9be87e7e15bf" target="_blank" rel="noopener">链接</a></p>
<hr>
<p>待添加：评论功能(next继承来必力)；<a href="http://blog.csdn.net/qq_33699981/article/details/72716951" target="_blank" rel="noopener">http://blog.csdn.net/qq_33699981/article/details/72716951</a><br>To be continued…</p>
]]></content>
      
        <categories>
            
            <category> 随笔 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
